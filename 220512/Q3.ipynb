{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee5f577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0983bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "data = fetch_rcv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd3e830c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': <804414x47236 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 60915113 stored elements in Compressed Sparse Row format>,\n",
       " 'target': <804414x103 sparse matrix of type '<class 'numpy.uint8'>'\n",
       " \twith 2606875 stored elements in Compressed Sparse Row format>,\n",
       " 'sample_id': array([  2286,   2287,   2288, ..., 810594, 810595, 810596], dtype=uint32),\n",
       " 'target_names': array(['C11', 'C12', 'C13', 'C14', 'C15', 'C151', 'C1511', 'C152', 'C16',\n",
       "        'C17', 'C171', 'C172', 'C173', 'C174', 'C18', 'C181', 'C182',\n",
       "        'C183', 'C21', 'C22', 'C23', 'C24', 'C31', 'C311', 'C312', 'C313',\n",
       "        'C32', 'C33', 'C331', 'C34', 'C41', 'C411', 'C42', 'CCAT', 'E11',\n",
       "        'E12', 'E121', 'E13', 'E131', 'E132', 'E14', 'E141', 'E142',\n",
       "        'E143', 'E21', 'E211', 'E212', 'E31', 'E311', 'E312', 'E313',\n",
       "        'E41', 'E411', 'E51', 'E511', 'E512', 'E513', 'E61', 'E71', 'ECAT',\n",
       "        'G15', 'G151', 'G152', 'G153', 'G154', 'G155', 'G156', 'G157',\n",
       "        'G158', 'G159', 'GCAT', 'GCRIM', 'GDEF', 'GDIP', 'GDIS', 'GENT',\n",
       "        'GENV', 'GFAS', 'GHEA', 'GJOB', 'GMIL', 'GOBIT', 'GODD', 'GPOL',\n",
       "        'GPRO', 'GREL', 'GSCI', 'GSPO', 'GTOUR', 'GVIO', 'GVOTE', 'GWEA',\n",
       "        'GWELF', 'M11', 'M12', 'M13', 'M131', 'M132', 'M14', 'M141',\n",
       "        'M142', 'M143', 'MCAT'], dtype=object),\n",
       " 'DESCR': \".. _rcv1_dataset:\\n\\nRCV1 dataset\\n------------\\n\\nReuters Corpus Volume I (RCV1) is an archive of over 800,000 manually \\ncategorized newswire stories made available by Reuters, Ltd. for research \\npurposes. The dataset is extensively described in [1]_.\\n\\n**Data Set Characteristics:**\\n\\n    ==============     =====================\\n    Classes                              103\\n    Samples total                     804414\\n    Dimensionality                     47236\\n    Features           real, between 0 and 1\\n    ==============     =====================\\n\\n:func:`sklearn.datasets.fetch_rcv1` will load the following \\nversion: RCV1-v2, vectors, full sets, topics multilabels::\\n\\n    >>> from sklearn.datasets import fetch_rcv1\\n    >>> rcv1 = fetch_rcv1()\\n\\nIt returns a dictionary-like object, with the following attributes:\\n\\n``data``:\\nThe feature matrix is a scipy CSR sparse matrix, with 804414 samples and\\n47236 features. Non-zero values contains cosine-normalized, log TF-IDF vectors.\\nA nearly chronological split is proposed in [1]_: The first 23149 samples are\\nthe training set. The last 781265 samples are the testing set. This follows \\nthe official LYRL2004 chronological split. The array has 0.16% of non zero \\nvalues::\\n\\n    >>> rcv1.data.shape\\n    (804414, 47236)\\n\\n``target``:\\nThe target values are stored in a scipy CSR sparse matrix, with 804414 samples \\nand 103 categories. Each sample has a value of 1 in its categories, and 0 in \\nothers. The array has 3.15% of non zero values::\\n\\n    >>> rcv1.target.shape\\n    (804414, 103)\\n\\n``sample_id``:\\nEach sample can be identified by its ID, ranging (with gaps) from 2286 \\nto 810596::\\n\\n    >>> rcv1.sample_id[:3]\\n    array([2286, 2287, 2288], dtype=uint32)\\n\\n``target_names``:\\nThe target values are the topics of each sample. Each sample belongs to at \\nleast one topic, and to up to 17 topics. There are 103 topics, each \\nrepresented by a string. Their corpus frequencies span five orders of \\nmagnitude, from 5 occurrences for 'GMIL', to 381327 for 'CCAT'::\\n\\n    >>> rcv1.target_names[:3].tolist()  # doctest: +SKIP\\n    ['E11', 'ECAT', 'M11']\\n\\nThe dataset will be downloaded from the `rcv1 homepage`_ if necessary.\\nThe compressed size is about 656 MB.\\n\\n.. _rcv1 homepage: http://jmlr.csail.mit.edu/papers/volume5/lewis04a/\\n\\n\\n.. topic:: References\\n\\n    .. [1] Lewis, D. D., Yang, Y., Rose, T. G., & Li, F. (2004). \\n           RCV1: A new benchmark collection for text categorization research. \\n           The Journal of Machine Learning Research, 5, 361-397.\\n\"}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70c443cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'sample_id', 'target_names', 'DESCR'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e4cc6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data.data[:10000,:10000]\n",
    "Y_data = data.target[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2eb5c166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 10000), (10000, 103))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape, Y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4b3cc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7500, 10000), (7500, 103))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x,tt_x,t_y,tt_y = train_test_split(X_data,Y_data,random_state=1)\n",
    "t_x.shape, t_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8acbc74b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:850 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:840 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:833 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:791 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:180 squeeze_or_expand_dimensions\n        y_true, y_pred = remove_squeezable_dimensions(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:110 remove_squeezable_dimensions\n        labels = ops.convert_to_tensor_v2_with_dispatch(labels)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1430 convert_to_tensor_v2_with_dispatch\n        return convert_to_tensor_v2(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1436 convert_to_tensor_v2\n        return convert_to_tensor(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:551 make_tensor_proto\n        raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=uint8), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27588/2568193033.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m103\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mhy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtt_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m                 _r=1):\n\u001b[0;32m   1177\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 763\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    764\u001b[0m             *args, **kwds))\n\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3049\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3050\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3051\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3444\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3279\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 999\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    984\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:850 train_function  *\n        return step_function(self, iterator)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:840 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:833 run_step  **\n        outputs = model.train_step(data)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:791 train_step\n        loss = self.compiled_loss(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:155 __call__\n        losses = call_fn(y_true, y_pred)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\losses.py:256 call  **\n        y_pred, y_true = losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:180 squeeze_or_expand_dimensions\n        y_true, y_pred = remove_squeezable_dimensions(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:110 remove_squeezable_dimensions\n        labels = ops.convert_to_tensor_v2_with_dispatch(labels)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1430 convert_to_tensor_v2_with_dispatch\n        return convert_to_tensor_v2(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1436 convert_to_tensor_v2\n        return convert_to_tensor(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163 wrapped\n        return func(*args, **kwargs)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:339 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:264 constant\n        return _constant_impl(value, dtype, shape, name, verify_shape=False,\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:281 _constant_impl\n        tensor_util.make_tensor_proto(\n    C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:551 make_tensor_proto\n        raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\n    TypeError: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"DeserializeSparse_1:0\", shape=(None, 2), dtype=int64), values=Tensor(\"DeserializeSparse_1:1\", shape=(None,), dtype=uint8), dense_shape=Tensor(\"stack_1:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.\n"
     ]
    }
   ],
   "source": [
    "# m = Sequential()\n",
    "# m.add(Dense(103, input_dim = 10000,activation = 'softmax'))\n",
    "# m.compile(optimizer='adam',loss = 'categorical_crossentropy'\n",
    "#           ,metrics=['accuracy'])\n",
    "# hy = m.fit(t_x,t_y,epochs=1,validation_data=(tt_x,tt_y))\n",
    "\n",
    "\n",
    "# m = Sequential()\n",
    "# m.add(Dense(1024,input_shape = (10000,),activation='relu'))\n",
    "# m.add(Dropout(0.5))\n",
    "# m.add(Dense(512,activation='relu'))\n",
    "# m.add(Dropout(0.5))\n",
    "# m.add(Dense(103,activation='softmax'))\n",
    "# m.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "# hy = m.fit(t_x,t_y,epochs=1,validation_data=(tt_x, tt_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6d48c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = range(1,len(hy.history['accuracy'])+1)\n",
    "plt.plot(ec,hy.history['loss'])\n",
    "plt.plot(ec,hy.history['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
