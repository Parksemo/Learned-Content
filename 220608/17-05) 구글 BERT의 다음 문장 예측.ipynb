{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74825a11",
   "metadata": {},
   "source": [
    "# 1. 다음 문장 예측 모델과 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde6dfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFBertForNextSentencePrediction\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2144121",
   "metadata": {},
   "source": [
    "TFBertForNextSentencePrediction.from_pretrained('BERT 모델 이름')을 넣으면 [MASK]라고 되어있는 단어를 맞추기 위한 마스크드 언어 모델링을 위한 구조로 BERT를 로드합니다. \n",
    "다시 말해서 BERT를 마스크드 언어 모델 형태로 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fatty-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c37524",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForNextSentencePrediction.\n",
      "\n",
      "All the layers of TFBertForNextSentencePrediction were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForNextSentencePrediction for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b94db7ab7843a19020b46bd1c40ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af6cbbca411415fa834ef6a8da2664c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63d3feedc37d4f0e97238a6810b0bcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = TFBertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54442875",
   "metadata": {},
   "source": [
    "# 2. BERT의 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5315d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"pizza is eaten with the use of a knife and fork. In casual settings, however, it is cut into wedges to be eaten while held in the hand.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c720cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac36628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  101  1999  3304  1010 10733  2366  1999  5337 10906  1010  2107  2004\n",
      "   2012  1037  4825  1010  2003  3591  4895 14540  6610  2094  1012   102\n",
      "  10733  2003  8828  2007  1996  2224  1997  1037  5442  1998  9292  1012\n",
      "   1999 10017 10906  1010  2174  1010  2009  2003  3013  2046 17632  2015\n",
      "   2000  2022  8828  2096  2218  1999  1996  2192  1012   102]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea2f7eaf",
   "metadata": {},
   "source": [
    "여기서 주의할 점은 여기서 101과 102는 특별 토큰이라는 점입니다. \n",
    "실제로 해당 토크나이저의 [CLS] 토큰과 [SEP] 토큰의 번호를 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa27ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] : 101\n",
      "[SEP] : 102\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.cls_token, ':', tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, ':' , tokenizer.sep_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89756fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] in italy, pizza served in formal settings, such as at a restaurant, is presented unsliced. [SEP] pizza is eaten with the use of a knife and fork. in casual settings, however, it is cut into wedges to be eaten while held in the hand. [SEP]\n"
     ]
    }
   ],
   "source": [
    "# 위의 정수 인코딩 결과를 다시 디코딩해보면 현재 입력의 구성을 확인할 수 있습니다.\n",
    "print(tokenizer.decode(encoding['input_ids'][0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3a0ff2a",
   "metadata": {},
   "source": [
    "BERT에서 두 개의 문장이 입력으로 들어갈 경우에는 맨 앞에는 [CLS] 토큰이 존재하고, 첫번째 문장이 끝나면 [SEP] 토큰, 그리고 두번째 문장이 종료되었을 때 다시 추가적으로 [SEP] 토큰이 추가됩니다. \n",
    "토크나이저로 변환된 결과에서 token_type_ids를 통해서 문장을 구분하는 세그먼트 인코딩 결과를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dd72f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]], shape=(1, 58), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(encoding['token_type_ids'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "51c848ed",
   "metadata": {},
   "source": [
    "0이 연속적으로 등장하다가 어느 순간부터 1이 연속적으로 등장하는데, 이는 [CLS] 토큰의 위치부터 첫번째 문장이 끝나고나서 등장한 [SEP] 토큰까지의 위치에는 0이 등장하고, 다음 두번째 문장부터는 1이 등장하는 것입니다. \n",
    "token_type_ids에서는 0과 1로 두 개의 문장을 구분하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bb610",
   "metadata": {},
   "source": [
    "# 3. 다음 문장 예측하기"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d4bdda4",
   "metadata": {},
   "source": [
    "이제 TFBertForNextSentencePrediction를 통해서 다음 문장을 예측해봅시다. \n",
    "모델에 입력을 넣으면, 해당 모델은 소프트맥스 함수를 지나기 전의 값인 logits을 리턴합니다. \n",
    "해당 값을 소프트맥스 함수를 통과시킨 후에 각 레이블에 대한 확률값을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32410f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[9.9999714e-01 2.8381858e-06]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "probs = softmax(logits)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d3fe128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [0]\n"
     ]
    }
   ],
   "source": [
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2bd756f",
   "metadata": {},
   "source": [
    "최종 예측 레이블은 0입니다. \n",
    "이는 BERT가 다음 문장 예측을 학습했을 당시에 실질적으로 이어지는 두 개의 문장의 레이블은 0, 이어지지 않는 두 개의 문장의 경우에는 레이블을 1로 두고서 이진 분류로 학습을 하였기 때문입니다. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "27edbaaa",
   "metadata": {},
   "source": [
    "이번에는 이어지지 않는 두 개의 문장으로 테스트해봅시다. 전체적인 과정은 이전과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b69f5130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 예측 레이블 : [1]\n"
     ]
    }
   ],
   "source": [
    "# 상관없는 두 개의 문장\n",
    "prompt = \"In Italy, pizza served in formal settings, such as at a restaurant, is presented unsliced.\"\n",
    "next_sentence = \"The sky is blue due to the shorter wavelength of blue light.\"\n",
    "encoding = tokenizer(prompt, next_sentence, return_tensors='tf')\n",
    "\n",
    "logits = model(encoding['input_ids'], token_type_ids=encoding['token_type_ids'])[0]\n",
    "\n",
    "softmax = tf.keras.layers.Softmax()\n",
    "probs = softmax(logits)\n",
    "print('최종 예측 레이블 :', tf.math.argmax(probs, axis=-1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf45eddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daed4542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
