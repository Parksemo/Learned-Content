{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# seed 값 설정\n",
    "seed = 0\n",
    "numpy.random.seed(seed)\n",
    "tf.random.set_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv(\"housing.csv\", delim_whitespace=True, header=None)\n",
    "dataset = df.values\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "X = dataset[:, 0:13]\n",
    "Y = dataset[:, 13]\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델 선언\n",
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim=13, activation='relu'))  # 입력층\n",
    "                                                       # 은닉층1\n",
    "model.add(Dense(25, activation='relu'))    \n",
    "model.add(Dense(15, activation='relu'))            \n",
    "model.add(Dense(6, activation='relu'))                 # \n",
    "model.add(Dense(1))                                    # 출력층\n",
    "# 선형 회귀는 마지막에 참과 거짓을 구분할 필요가 없음. 출력층에 활성화 함수를 지정할 필요도 없음\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam', \n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 폴더 만들기\n",
    "MODEL_DIR = './model/'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.mkdir(MODEL_DIR)\n",
    "\n",
    "modelpath = \"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "\n",
    "# 모델 업데이트 및 저장\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_mse', verbose=1, save_best_only=True)\n",
    "\n",
    "# 학습 자동 중단 설정\n",
    "early_stopping_callback = EarlyStopping(monitor='val_mse', patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "8/8 [==============================] - 1s 39ms/step - loss: 339.4776 - mse: 339.4776 - val_loss: 168.2521 - val_mse: 168.2521\n",
      "\n",
      "Epoch 00001: val_mse improved from inf to 168.25214, saving model to ./model\\01-168.2521.hdf5\n",
      "Epoch 2/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 90.6869 - mse: 90.6869 - val_loss: 100.6497 - val_mse: 100.6497\n",
      "\n",
      "Epoch 00002: val_mse improved from 168.25214 to 100.64969, saving model to ./model\\02-100.6497.hdf5\n",
      "Epoch 3/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 83.5105 - mse: 83.5105 - val_loss: 82.3979 - val_mse: 82.3979\n",
      "\n",
      "Epoch 00003: val_mse improved from 100.64969 to 82.39790, saving model to ./model\\03-82.3979.hdf5\n",
      "Epoch 4/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 72.5968 - mse: 72.5968 - val_loss: 71.6018 - val_mse: 71.6018\n",
      "\n",
      "Epoch 00004: val_mse improved from 82.39790 to 71.60178, saving model to ./model\\04-71.6018.hdf5\n",
      "Epoch 5/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 65.5530 - mse: 65.5530 - val_loss: 72.0216 - val_mse: 72.0216\n",
      "\n",
      "Epoch 00005: val_mse did not improve from 71.60178\n",
      "Epoch 6/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 65.4829 - mse: 65.4829 - val_loss: 74.7827 - val_mse: 74.7827\n",
      "\n",
      "Epoch 00006: val_mse did not improve from 71.60178\n",
      "Epoch 7/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 64.8968 - mse: 64.8968 - val_loss: 71.0450 - val_mse: 71.0450\n",
      "\n",
      "Epoch 00007: val_mse improved from 71.60178 to 71.04504, saving model to ./model\\07-71.0450.hdf5\n",
      "Epoch 8/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 62.6293 - mse: 62.6293 - val_loss: 70.6503 - val_mse: 70.6503\n",
      "\n",
      "Epoch 00008: val_mse improved from 71.04504 to 70.65028, saving model to ./model\\08-70.6503.hdf5\n",
      "Epoch 9/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 63.2196 - mse: 63.2196 - val_loss: 67.8574 - val_mse: 67.8574\n",
      "\n",
      "Epoch 00009: val_mse improved from 70.65028 to 67.85741, saving model to ./model\\09-67.8574.hdf5\n",
      "Epoch 10/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 61.2942 - mse: 61.2942 - val_loss: 70.8413 - val_mse: 70.8413\n",
      "\n",
      "Epoch 00010: val_mse did not improve from 67.85741\n",
      "Epoch 11/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 61.4654 - mse: 61.4654 - val_loss: 69.4215 - val_mse: 69.4215\n",
      "\n",
      "Epoch 00011: val_mse did not improve from 67.85741\n",
      "Epoch 12/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 60.5786 - mse: 60.5786 - val_loss: 69.1660 - val_mse: 69.1660\n",
      "\n",
      "Epoch 00012: val_mse did not improve from 67.85741\n",
      "Epoch 13/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 60.6203 - mse: 60.6203 - val_loss: 66.5345 - val_mse: 66.5345\n",
      "\n",
      "Epoch 00013: val_mse improved from 67.85741 to 66.53447, saving model to ./model\\13-66.5345.hdf5\n",
      "Epoch 14/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 59.6984 - mse: 59.6984 - val_loss: 67.7161 - val_mse: 67.7161\n",
      "\n",
      "Epoch 00014: val_mse did not improve from 66.53447\n",
      "Epoch 15/5000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 58.7554 - mse: 58.7554 - val_loss: 66.6253 - val_mse: 66.6253\n",
      "\n",
      "Epoch 00015: val_mse did not improve from 66.53447\n",
      "Epoch 16/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 59.1427 - mse: 59.1427 - val_loss: 66.6650 - val_mse: 66.6650\n",
      "\n",
      "Epoch 00016: val_mse did not improve from 66.53447\n",
      "Epoch 17/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 59.3361 - mse: 59.3361 - val_loss: 66.3615 - val_mse: 66.3615\n",
      "\n",
      "Epoch 00017: val_mse improved from 66.53447 to 66.36147, saving model to ./model\\17-66.3615.hdf5\n",
      "Epoch 18/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 58.3133 - mse: 58.3133 - val_loss: 64.9842 - val_mse: 64.9842\n",
      "\n",
      "Epoch 00018: val_mse improved from 66.36147 to 64.98424, saving model to ./model\\18-64.9842.hdf5\n",
      "Epoch 19/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 57.3822 - mse: 57.3822 - val_loss: 66.0343 - val_mse: 66.0343\n",
      "\n",
      "Epoch 00019: val_mse did not improve from 64.98424\n",
      "Epoch 20/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 58.4796 - mse: 58.4796 - val_loss: 63.8135 - val_mse: 63.8135\n",
      "\n",
      "Epoch 00020: val_mse improved from 64.98424 to 63.81349, saving model to ./model\\20-63.8135.hdf5\n",
      "Epoch 21/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 58.2962 - mse: 58.2962 - val_loss: 63.8335 - val_mse: 63.8335\n",
      "\n",
      "Epoch 00021: val_mse did not improve from 63.81349\n",
      "Epoch 22/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 56.0735 - mse: 56.0735 - val_loss: 63.0359 - val_mse: 63.0359\n",
      "\n",
      "Epoch 00022: val_mse improved from 63.81349 to 63.03587, saving model to ./model\\22-63.0359.hdf5\n",
      "Epoch 23/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 56.9732 - mse: 56.9732 - val_loss: 70.5916 - val_mse: 70.5916\n",
      "\n",
      "Epoch 00023: val_mse did not improve from 63.03587\n",
      "Epoch 24/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 60.1477 - mse: 60.1477 - val_loss: 64.0471 - val_mse: 64.0471\n",
      "\n",
      "Epoch 00024: val_mse did not improve from 63.03587\n",
      "Epoch 25/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 57.2783 - mse: 57.2783 - val_loss: 64.4750 - val_mse: 64.4750\n",
      "\n",
      "Epoch 00025: val_mse did not improve from 63.03587\n",
      "Epoch 26/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 54.4717 - mse: 54.4717 - val_loss: 61.0875 - val_mse: 61.0875\n",
      "\n",
      "Epoch 00026: val_mse improved from 63.03587 to 61.08751, saving model to ./model\\26-61.0875.hdf5\n",
      "Epoch 27/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 54.0021 - mse: 54.0021 - val_loss: 60.9922 - val_mse: 60.9922\n",
      "\n",
      "Epoch 00027: val_mse improved from 61.08751 to 60.99222, saving model to ./model\\27-60.9922.hdf5\n",
      "Epoch 28/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 53.4411 - mse: 53.4411 - val_loss: 60.0872 - val_mse: 60.0872\n",
      "\n",
      "Epoch 00028: val_mse improved from 60.99222 to 60.08717, saving model to ./model\\28-60.0872.hdf5\n",
      "Epoch 29/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 53.6210 - mse: 53.6210 - val_loss: 60.5958 - val_mse: 60.5958\n",
      "\n",
      "Epoch 00029: val_mse did not improve from 60.08717\n",
      "Epoch 30/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 52.9230 - mse: 52.9230 - val_loss: 59.1499 - val_mse: 59.1499\n",
      "\n",
      "Epoch 00030: val_mse improved from 60.08717 to 59.14989, saving model to ./model\\30-59.1499.hdf5\n",
      "Epoch 31/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 52.3557 - mse: 52.3557 - val_loss: 58.9273 - val_mse: 58.9273\n",
      "\n",
      "Epoch 00031: val_mse improved from 59.14989 to 58.92729, saving model to ./model\\31-58.9273.hdf5\n",
      "Epoch 32/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 51.7929 - mse: 51.7929 - val_loss: 59.3514 - val_mse: 59.3514\n",
      "\n",
      "Epoch 00032: val_mse did not improve from 58.92729\n",
      "Epoch 33/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 51.1967 - mse: 51.1967 - val_loss: 59.1971 - val_mse: 59.1971\n",
      "\n",
      "Epoch 00033: val_mse did not improve from 58.92729\n",
      "Epoch 34/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 50.9477 - mse: 50.9477 - val_loss: 57.8461 - val_mse: 57.8461\n",
      "\n",
      "Epoch 00034: val_mse improved from 58.92729 to 57.84605, saving model to ./model\\34-57.8461.hdf5\n",
      "Epoch 35/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 50.2006 - mse: 50.2006 - val_loss: 57.2332 - val_mse: 57.2332\n",
      "\n",
      "Epoch 00035: val_mse improved from 57.84605 to 57.23322, saving model to ./model\\35-57.2332.hdf5\n",
      "Epoch 36/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 49.3867 - mse: 49.3867 - val_loss: 56.3325 - val_mse: 56.3325\n",
      "\n",
      "Epoch 00036: val_mse improved from 57.23322 to 56.33247, saving model to ./model\\36-56.3325.hdf5\n",
      "Epoch 37/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 49.8827 - mse: 49.8827 - val_loss: 56.0508 - val_mse: 56.0508\n",
      "\n",
      "Epoch 00037: val_mse improved from 56.33247 to 56.05079, saving model to ./model\\37-56.0508.hdf5\n",
      "Epoch 38/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 48.8547 - mse: 48.8547 - val_loss: 56.5904 - val_mse: 56.5904\n",
      "\n",
      "Epoch 00038: val_mse did not improve from 56.05079\n",
      "Epoch 39/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 48.1470 - mse: 48.1470 - val_loss: 54.7709 - val_mse: 54.7709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00039: val_mse improved from 56.05079 to 54.77090, saving model to ./model\\39-54.7709.hdf5\n",
      "Epoch 40/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 48.1160 - mse: 48.1160 - val_loss: 56.6634 - val_mse: 56.6634\n",
      "\n",
      "Epoch 00040: val_mse did not improve from 54.77090\n",
      "Epoch 41/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.8914 - mse: 47.8914 - val_loss: 53.3043 - val_mse: 53.3043\n",
      "\n",
      "Epoch 00041: val_mse improved from 54.77090 to 53.30428, saving model to ./model\\41-53.3043.hdf5\n",
      "Epoch 42/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 47.0770 - mse: 47.0770 - val_loss: 53.5172 - val_mse: 53.5172\n",
      "\n",
      "Epoch 00042: val_mse did not improve from 53.30428\n",
      "Epoch 43/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 45.9975 - mse: 45.9975 - val_loss: 53.9349 - val_mse: 53.9349\n",
      "\n",
      "Epoch 00043: val_mse did not improve from 53.30428\n",
      "Epoch 44/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.2546 - mse: 45.2546 - val_loss: 52.2465 - val_mse: 52.2465\n",
      "\n",
      "Epoch 00044: val_mse improved from 53.30428 to 52.24653, saving model to ./model\\44-52.2465.hdf5\n",
      "Epoch 45/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 45.1519 - mse: 45.1519 - val_loss: 57.8401 - val_mse: 57.8401\n",
      "\n",
      "Epoch 00045: val_mse did not improve from 52.24653\n",
      "Epoch 46/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 45.1845 - mse: 45.1845 - val_loss: 51.8150 - val_mse: 51.8150\n",
      "\n",
      "Epoch 00046: val_mse improved from 52.24653 to 51.81498, saving model to ./model\\46-51.8150.hdf5\n",
      "Epoch 47/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 44.7323 - mse: 44.7323 - val_loss: 50.8621 - val_mse: 50.8621\n",
      "\n",
      "Epoch 00047: val_mse improved from 51.81498 to 50.86208, saving model to ./model\\47-50.8621.hdf5\n",
      "Epoch 48/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.2510 - mse: 43.2510 - val_loss: 49.8043 - val_mse: 49.8043\n",
      "\n",
      "Epoch 00048: val_mse improved from 50.86208 to 49.80433, saving model to ./model\\48-49.8043.hdf5\n",
      "Epoch 49/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 43.6405 - mse: 43.6405 - val_loss: 49.0812 - val_mse: 49.0812\n",
      "\n",
      "Epoch 00049: val_mse improved from 49.80433 to 49.08125, saving model to ./model\\49-49.0812.hdf5\n",
      "Epoch 50/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 42.0694 - mse: 42.0694 - val_loss: 49.2758 - val_mse: 49.2758\n",
      "\n",
      "Epoch 00050: val_mse did not improve from 49.08125\n",
      "Epoch 51/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.3339 - mse: 41.3339 - val_loss: 48.4541 - val_mse: 48.4541\n",
      "\n",
      "Epoch 00051: val_mse improved from 49.08125 to 48.45414, saving model to ./model\\51-48.4541.hdf5\n",
      "Epoch 52/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 41.2223 - mse: 41.2223 - val_loss: 49.4654 - val_mse: 49.4654\n",
      "\n",
      "Epoch 00052: val_mse did not improve from 48.45414\n",
      "Epoch 53/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 41.9647 - mse: 41.9647 - val_loss: 54.1103 - val_mse: 54.1103\n",
      "\n",
      "Epoch 00053: val_mse did not improve from 48.45414\n",
      "Epoch 54/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 44.6905 - mse: 44.6905 - val_loss: 61.1796 - val_mse: 61.1796\n",
      "\n",
      "Epoch 00054: val_mse did not improve from 48.45414\n",
      "Epoch 55/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 48.2277 - mse: 48.2277 - val_loss: 49.2175 - val_mse: 49.2175\n",
      "\n",
      "Epoch 00055: val_mse did not improve from 48.45414\n",
      "Epoch 56/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 44.6626 - mse: 44.6626 - val_loss: 63.0691 - val_mse: 63.0691\n",
      "\n",
      "Epoch 00056: val_mse did not improve from 48.45414\n",
      "Epoch 57/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 49.4710 - mse: 49.4710 - val_loss: 46.4309 - val_mse: 46.4309\n",
      "\n",
      "Epoch 00057: val_mse improved from 48.45414 to 46.43093, saving model to ./model\\57-46.4309.hdf5\n",
      "Epoch 58/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 44.6514 - mse: 44.6514 - val_loss: 50.5028 - val_mse: 50.5028\n",
      "\n",
      "Epoch 00058: val_mse did not improve from 46.43093\n",
      "Epoch 59/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 42.7902 - mse: 42.7902 - val_loss: 51.4281 - val_mse: 51.4281\n",
      "\n",
      "Epoch 00059: val_mse did not improve from 46.43093\n",
      "Epoch 60/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 40.0162 - mse: 40.0162 - val_loss: 46.3007 - val_mse: 46.3007\n",
      "\n",
      "Epoch 00060: val_mse improved from 46.43093 to 46.30075, saving model to ./model\\60-46.3007.hdf5\n",
      "Epoch 61/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 37.8991 - mse: 37.8991 - val_loss: 44.2868 - val_mse: 44.2868\n",
      "\n",
      "Epoch 00061: val_mse improved from 46.30075 to 44.28676, saving model to ./model\\61-44.2868.hdf5\n",
      "Epoch 62/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 39.5406 - mse: 39.5406 - val_loss: 43.3287 - val_mse: 43.3287\n",
      "\n",
      "Epoch 00062: val_mse improved from 44.28676 to 43.32873, saving model to ./model\\62-43.3287.hdf5\n",
      "Epoch 63/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 38.0520 - mse: 38.0520 - val_loss: 43.0952 - val_mse: 43.0952\n",
      "\n",
      "Epoch 00063: val_mse improved from 43.32873 to 43.09523, saving model to ./model\\63-43.0952.hdf5\n",
      "Epoch 64/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 35.8793 - mse: 35.8793 - val_loss: 43.0107 - val_mse: 43.0107\n",
      "\n",
      "Epoch 00064: val_mse improved from 43.09523 to 43.01066, saving model to ./model\\64-43.0107.hdf5\n",
      "Epoch 65/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36.0628 - mse: 36.0628 - val_loss: 43.3837 - val_mse: 43.3837\n",
      "\n",
      "Epoch 00065: val_mse did not improve from 43.01066\n",
      "Epoch 66/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35.3748 - mse: 35.3748 - val_loss: 42.6750 - val_mse: 42.6750\n",
      "\n",
      "Epoch 00066: val_mse improved from 43.01066 to 42.67500, saving model to ./model\\66-42.6750.hdf5\n",
      "Epoch 67/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 36.1633 - mse: 36.1633 - val_loss: 48.9676 - val_mse: 48.9676\n",
      "\n",
      "Epoch 00067: val_mse did not improve from 42.67500\n",
      "Epoch 68/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 37.8732 - mse: 37.8732 - val_loss: 43.0580 - val_mse: 43.0580\n",
      "\n",
      "Epoch 00068: val_mse did not improve from 42.67500\n",
      "Epoch 69/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 35.7072 - mse: 35.7072 - val_loss: 41.7812 - val_mse: 41.7812\n",
      "\n",
      "Epoch 00069: val_mse improved from 42.67500 to 41.78118, saving model to ./model\\69-41.7812.hdf5\n",
      "Epoch 70/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 35.1870 - mse: 35.1870 - val_loss: 41.4953 - val_mse: 41.4953\n",
      "\n",
      "Epoch 00070: val_mse improved from 41.78118 to 41.49526, saving model to ./model\\70-41.4953.hdf5\n",
      "Epoch 71/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 35.4992 - mse: 35.4992 - val_loss: 41.1600 - val_mse: 41.1600\n",
      "\n",
      "Epoch 00071: val_mse improved from 41.49526 to 41.16003, saving model to ./model\\71-41.1600.hdf5\n",
      "Epoch 72/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 33.3480 - mse: 33.3480 - val_loss: 39.3649 - val_mse: 39.3649\n",
      "\n",
      "Epoch 00072: val_mse improved from 41.16003 to 39.36485, saving model to ./model\\72-39.3649.hdf5\n",
      "Epoch 73/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 32.7181 - mse: 32.7181 - val_loss: 39.3585 - val_mse: 39.3585\n",
      "\n",
      "Epoch 00073: val_mse improved from 39.36485 to 39.35846, saving model to ./model\\73-39.3585.hdf5\n",
      "Epoch 74/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 32.9775 - mse: 32.9775 - val_loss: 38.9637 - val_mse: 38.9637\n",
      "\n",
      "Epoch 00074: val_mse improved from 39.35846 to 38.96373, saving model to ./model\\74-38.9637.hdf5\n",
      "Epoch 75/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 32.8940 - mse: 32.8940 - val_loss: 40.9356 - val_mse: 40.9356\n",
      "\n",
      "Epoch 00075: val_mse did not improve from 38.96373\n",
      "Epoch 76/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 35.2599 - mse: 35.2599 - val_loss: 38.4655 - val_mse: 38.4655\n",
      "\n",
      "Epoch 00076: val_mse improved from 38.96373 to 38.46549, saving model to ./model\\76-38.4655.hdf5\n",
      "Epoch 77/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 32.5448 - mse: 32.5448 - val_loss: 41.0314 - val_mse: 41.0314\n",
      "\n",
      "Epoch 00077: val_mse did not improve from 38.46549\n",
      "Epoch 78/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 30.4208 - mse: 30.4208 - val_loss: 38.3691 - val_mse: 38.3691\n",
      "\n",
      "Epoch 00078: val_mse improved from 38.46549 to 38.36909, saving model to ./model\\78-38.3691.hdf5\n",
      "Epoch 79/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 32.3228 - mse: 32.3228 - val_loss: 38.4501 - val_mse: 38.4501\n",
      "\n",
      "Epoch 00079: val_mse did not improve from 38.36909\n",
      "Epoch 80/5000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 30.7332 - mse: 30.7332 - val_loss: 38.7487 - val_mse: 38.7487\n",
      "\n",
      "Epoch 00080: val_mse did not improve from 38.36909\n",
      "Epoch 81/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 30.2164 - mse: 30.2164 - val_loss: 40.0802 - val_mse: 40.0802\n",
      "\n",
      "Epoch 00081: val_mse did not improve from 38.36909\n",
      "Epoch 82/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 33.2748 - mse: 33.2748 - val_loss: 39.6051 - val_mse: 39.6051\n",
      "\n",
      "Epoch 00082: val_mse did not improve from 38.36909\n",
      "Epoch 83/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 33.3752 - mse: 33.3752 - val_loss: 38.4584 - val_mse: 38.4584\n",
      "\n",
      "Epoch 00083: val_mse did not improve from 38.36909\n",
      "Epoch 84/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 32.7645 - mse: 32.7645 - val_loss: 47.7521 - val_mse: 47.7521\n",
      "\n",
      "Epoch 00084: val_mse did not improve from 38.36909\n",
      "Epoch 85/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 31.7024 - mse: 31.7024 - val_loss: 36.5597 - val_mse: 36.5597\n",
      "\n",
      "Epoch 00085: val_mse improved from 38.36909 to 36.55967, saving model to ./model\\85-36.5597.hdf5\n",
      "Epoch 86/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 29.7553 - mse: 29.7553 - val_loss: 37.4526 - val_mse: 37.4526\n",
      "\n",
      "Epoch 00086: val_mse did not improve from 36.55967\n",
      "Epoch 87/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 29.1135 - mse: 29.1135 - val_loss: 39.6879 - val_mse: 39.6879\n",
      "\n",
      "Epoch 00087: val_mse did not improve from 36.55967\n",
      "Epoch 88/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 28.0154 - mse: 28.0154 - val_loss: 36.9132 - val_mse: 36.9132\n",
      "\n",
      "Epoch 00088: val_mse did not improve from 36.55967\n",
      "Epoch 89/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 28.9184 - mse: 28.9184 - val_loss: 36.7304 - val_mse: 36.7304\n",
      "\n",
      "Epoch 00089: val_mse did not improve from 36.55967\n",
      "Epoch 90/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 27.8524 - mse: 27.8524 - val_loss: 41.0862 - val_mse: 41.0862\n",
      "\n",
      "Epoch 00090: val_mse did not improve from 36.55967\n",
      "Epoch 91/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 29.7803 - mse: 29.7803 - val_loss: 35.2246 - val_mse: 35.2246\n",
      "\n",
      "Epoch 00091: val_mse improved from 36.55967 to 35.22463, saving model to ./model\\91-35.2246.hdf5\n",
      "Epoch 92/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 28.8273 - mse: 28.8273 - val_loss: 35.2226 - val_mse: 35.2226\n",
      "\n",
      "Epoch 00092: val_mse improved from 35.22463 to 35.22259, saving model to ./model\\92-35.2226.hdf5\n",
      "Epoch 93/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 29.6376 - mse: 29.6376 - val_loss: 38.0275 - val_mse: 38.0275\n",
      "\n",
      "Epoch 00093: val_mse did not improve from 35.22259\n",
      "Epoch 94/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.8199 - mse: 27.8199 - val_loss: 36.5699 - val_mse: 36.5699\n",
      "\n",
      "Epoch 00094: val_mse did not improve from 35.22259\n",
      "Epoch 95/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 30.2636 - mse: 30.2636 - val_loss: 35.7384 - val_mse: 35.7384\n",
      "\n",
      "Epoch 00095: val_mse did not improve from 35.22259\n",
      "Epoch 96/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 25.9159 - mse: 25.9159 - val_loss: 38.0514 - val_mse: 38.0514\n",
      "\n",
      "Epoch 00096: val_mse did not improve from 35.22259\n",
      "Epoch 97/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26.7136 - mse: 26.7136 - val_loss: 34.9248 - val_mse: 34.9248\n",
      "\n",
      "Epoch 00097: val_mse improved from 35.22259 to 34.92479, saving model to ./model\\97-34.9248.hdf5\n",
      "Epoch 98/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27.3978 - mse: 27.3978 - val_loss: 35.6940 - val_mse: 35.6940\n",
      "\n",
      "Epoch 00098: val_mse did not improve from 34.92479\n",
      "Epoch 99/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.5446 - mse: 27.5446 - val_loss: 35.5221 - val_mse: 35.5221\n",
      "\n",
      "Epoch 00099: val_mse did not improve from 34.92479\n",
      "Epoch 100/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.3188 - mse: 27.3188 - val_loss: 34.0702 - val_mse: 34.0702\n",
      "\n",
      "Epoch 00100: val_mse improved from 34.92479 to 34.07021, saving model to ./model\\100-34.0702.hdf5\n",
      "Epoch 101/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.5212 - mse: 25.5212 - val_loss: 33.9052 - val_mse: 33.9052\n",
      "\n",
      "Epoch 00101: val_mse improved from 34.07021 to 33.90517, saving model to ./model\\101-33.9052.hdf5\n",
      "Epoch 102/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26.2133 - mse: 26.2133 - val_loss: 33.8787 - val_mse: 33.8787\n",
      "\n",
      "Epoch 00102: val_mse improved from 33.90517 to 33.87867, saving model to ./model\\102-33.8787.hdf5\n",
      "Epoch 103/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.8883 - mse: 24.8883 - val_loss: 33.4036 - val_mse: 33.4036\n",
      "\n",
      "Epoch 00103: val_mse improved from 33.87867 to 33.40359, saving model to ./model\\103-33.4036.hdf5\n",
      "Epoch 104/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 26.9436 - mse: 26.9436 - val_loss: 40.9711 - val_mse: 40.9711\n",
      "\n",
      "Epoch 00104: val_mse did not improve from 33.40359\n",
      "Epoch 105/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 31.7586 - mse: 31.7586 - val_loss: 33.7998 - val_mse: 33.7998\n",
      "\n",
      "Epoch 00105: val_mse did not improve from 33.40359\n",
      "Epoch 106/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.5142 - mse: 27.5142 - val_loss: 45.2017 - val_mse: 45.2017\n",
      "\n",
      "Epoch 00106: val_mse did not improve from 33.40359\n",
      "Epoch 107/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.7663 - mse: 27.7663 - val_loss: 33.5069 - val_mse: 33.5069\n",
      "\n",
      "Epoch 00107: val_mse did not improve from 33.40359\n",
      "Epoch 108/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.9551 - mse: 27.9551 - val_loss: 39.3752 - val_mse: 39.3752\n",
      "\n",
      "Epoch 00108: val_mse did not improve from 33.40359\n",
      "Epoch 109/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.1312 - mse: 27.1312 - val_loss: 36.7777 - val_mse: 36.7777\n",
      "\n",
      "Epoch 00109: val_mse did not improve from 33.40359\n",
      "Epoch 110/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 27.7134 - mse: 27.7134 - val_loss: 36.2034 - val_mse: 36.2034\n",
      "\n",
      "Epoch 00110: val_mse did not improve from 33.40359\n",
      "Epoch 111/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 27.9651 - mse: 27.9651 - val_loss: 51.5489 - val_mse: 51.5489\n",
      "\n",
      "Epoch 00111: val_mse did not improve from 33.40359\n",
      "Epoch 112/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 33.6527 - mse: 33.6527 - val_loss: 33.7250 - val_mse: 33.7250\n",
      "\n",
      "Epoch 00112: val_mse did not improve from 33.40359\n",
      "Epoch 113/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 30.4688 - mse: 30.4688 - val_loss: 40.1421 - val_mse: 40.1421\n",
      "\n",
      "Epoch 00113: val_mse did not improve from 33.40359\n",
      "Epoch 114/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 25.1344 - mse: 25.1344 - val_loss: 32.5418 - val_mse: 32.5418\n",
      "\n",
      "Epoch 00114: val_mse improved from 33.40359 to 32.54177, saving model to ./model\\114-32.5418.hdf5\n",
      "Epoch 115/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 28.3981 - mse: 28.3981 - val_loss: 36.9699 - val_mse: 36.9699\n",
      "\n",
      "Epoch 00115: val_mse did not improve from 32.54177\n",
      "Epoch 116/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 24.8629 - mse: 24.8629 - val_loss: 38.3071 - val_mse: 38.3071\n",
      "\n",
      "Epoch 00116: val_mse did not improve from 32.54177\n",
      "Epoch 117/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26.9814 - mse: 26.9814 - val_loss: 34.5523 - val_mse: 34.5523\n",
      "\n",
      "Epoch 00117: val_mse did not improve from 32.54177\n",
      "Epoch 118/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.3557 - mse: 25.3557 - val_loss: 32.6918 - val_mse: 32.6918\n",
      "\n",
      "Epoch 00118: val_mse did not improve from 32.54177\n",
      "Epoch 119/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 25.3295 - mse: 25.3295 - val_loss: 34.2525 - val_mse: 34.2525\n",
      "\n",
      "Epoch 00119: val_mse did not improve from 32.54177\n",
      "Epoch 120/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 30.1785 - mse: 30.1785 - val_loss: 35.6934 - val_mse: 35.6934\n",
      "\n",
      "Epoch 00120: val_mse did not improve from 32.54177\n",
      "Epoch 121/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.6017 - mse: 24.6017 - val_loss: 34.2415 - val_mse: 34.2415\n",
      "\n",
      "Epoch 00121: val_mse did not improve from 32.54177\n",
      "Epoch 122/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.0921 - mse: 25.0921 - val_loss: 31.8830 - val_mse: 31.8830\n",
      "\n",
      "Epoch 00122: val_mse improved from 32.54177 to 31.88302, saving model to ./model\\122-31.8830.hdf5\n",
      "Epoch 123/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23.4475 - mse: 23.4475 - val_loss: 39.8388 - val_mse: 39.8388\n",
      "\n",
      "Epoch 00123: val_mse did not improve from 31.88302\n",
      "Epoch 124/5000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23.8756 - mse: 23.8756 - val_loss: 31.6035 - val_mse: 31.6035\n",
      "\n",
      "Epoch 00124: val_mse improved from 31.88302 to 31.60348, saving model to ./model\\124-31.6035.hdf5\n",
      "Epoch 125/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 25.1024 - mse: 25.1024 - val_loss: 35.3613 - val_mse: 35.3613\n",
      "\n",
      "Epoch 00125: val_mse did not improve from 31.60348\n",
      "Epoch 126/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.0236 - mse: 24.0236 - val_loss: 32.0610 - val_mse: 32.0610\n",
      "\n",
      "Epoch 00126: val_mse did not improve from 31.60348\n",
      "Epoch 127/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 22.9084 - mse: 22.9084 - val_loss: 32.9976 - val_mse: 32.9976\n",
      "\n",
      "Epoch 00127: val_mse did not improve from 31.60348\n",
      "Epoch 128/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.7549 - mse: 23.7549 - val_loss: 32.2692 - val_mse: 32.2692\n",
      "\n",
      "Epoch 00128: val_mse did not improve from 31.60348\n",
      "Epoch 129/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 22.0398 - mse: 22.0398 - val_loss: 32.3230 - val_mse: 32.3230\n",
      "\n",
      "Epoch 00129: val_mse did not improve from 31.60348\n",
      "Epoch 130/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.2341 - mse: 22.2341 - val_loss: 32.0729 - val_mse: 32.0729\n",
      "\n",
      "Epoch 00130: val_mse did not improve from 31.60348\n",
      "Epoch 131/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.1745 - mse: 22.1745 - val_loss: 33.3620 - val_mse: 33.3620\n",
      "\n",
      "Epoch 00131: val_mse did not improve from 31.60348\n",
      "Epoch 132/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.2643 - mse: 22.2643 - val_loss: 32.0219 - val_mse: 32.0219\n",
      "\n",
      "Epoch 00132: val_mse did not improve from 31.60348\n",
      "Epoch 133/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23.3818 - mse: 23.3818 - val_loss: 37.6398 - val_mse: 37.6398\n",
      "\n",
      "Epoch 00133: val_mse did not improve from 31.60348\n",
      "Epoch 134/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.8818 - mse: 22.8818 - val_loss: 32.2324 - val_mse: 32.2324\n",
      "\n",
      "Epoch 00134: val_mse did not improve from 31.60348\n",
      "Epoch 135/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 21.9031 - mse: 21.9031 - val_loss: 32.1280 - val_mse: 32.1280\n",
      "\n",
      "Epoch 00135: val_mse did not improve from 31.60348\n",
      "Epoch 136/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.3774 - mse: 22.3774 - val_loss: 33.9327 - val_mse: 33.9327\n",
      "\n",
      "Epoch 00136: val_mse did not improve from 31.60348\n",
      "Epoch 137/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.0607 - mse: 23.0607 - val_loss: 35.0009 - val_mse: 35.0009\n",
      "\n",
      "Epoch 00137: val_mse did not improve from 31.60348\n",
      "Epoch 138/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 22.5010 - mse: 22.5010 - val_loss: 31.5195 - val_mse: 31.5195\n",
      "\n",
      "Epoch 00138: val_mse improved from 31.60348 to 31.51946, saving model to ./model\\138-31.5195.hdf5\n",
      "Epoch 139/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.8709 - mse: 22.8709 - val_loss: 33.5883 - val_mse: 33.5883\n",
      "\n",
      "Epoch 00139: val_mse did not improve from 31.51946\n",
      "Epoch 140/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 25.2364 - mse: 25.2364 - val_loss: 31.3186 - val_mse: 31.3186\n",
      "\n",
      "Epoch 00140: val_mse improved from 31.51946 to 31.31859, saving model to ./model\\140-31.3186.hdf5\n",
      "Epoch 141/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.8236 - mse: 20.8236 - val_loss: 35.7829 - val_mse: 35.7829\n",
      "\n",
      "Epoch 00141: val_mse did not improve from 31.31859\n",
      "Epoch 142/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 24.6641 - mse: 24.6641 - val_loss: 32.3008 - val_mse: 32.3008\n",
      "\n",
      "Epoch 00142: val_mse did not improve from 31.31859\n",
      "Epoch 143/5000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 22.6096 - mse: 22.6096 - val_loss: 31.7901 - val_mse: 31.7901\n",
      "\n",
      "Epoch 00143: val_mse did not improve from 31.31859\n",
      "Epoch 144/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 20.9547 - mse: 20.9547 - val_loss: 31.9196 - val_mse: 31.9196\n",
      "\n",
      "Epoch 00144: val_mse did not improve from 31.31859\n",
      "Epoch 145/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 21.4440 - mse: 21.4440 - val_loss: 31.8708 - val_mse: 31.8708\n",
      "\n",
      "Epoch 00145: val_mse did not improve from 31.31859\n",
      "Epoch 146/5000\n",
      "8/8 [==============================] - ETA: 0s - loss: 37.4482 - mse: 37.448 - 0s 7ms/step - loss: 21.5174 - mse: 21.5174 - val_loss: 37.0732 - val_mse: 37.0732\n",
      "\n",
      "Epoch 00146: val_mse did not improve from 31.31859\n",
      "Epoch 147/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 25.0011 - mse: 25.0011 - val_loss: 33.1919 - val_mse: 33.1919\n",
      "\n",
      "Epoch 00147: val_mse did not improve from 31.31859\n",
      "Epoch 148/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 26.1441 - mse: 26.1441 - val_loss: 36.1877 - val_mse: 36.1877\n",
      "\n",
      "Epoch 00148: val_mse did not improve from 31.31859\n",
      "Epoch 149/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 23.9540 - mse: 23.9540 - val_loss: 35.2115 - val_mse: 35.2115\n",
      "\n",
      "Epoch 00149: val_mse did not improve from 31.31859\n",
      "Epoch 150/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.6848 - mse: 22.6848 - val_loss: 32.0463 - val_mse: 32.0463\n",
      "\n",
      "Epoch 00150: val_mse did not improve from 31.31859\n",
      "Epoch 151/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.7979 - mse: 20.7979 - val_loss: 31.2909 - val_mse: 31.2909\n",
      "\n",
      "Epoch 00151: val_mse improved from 31.31859 to 31.29088, saving model to ./model\\151-31.2909.hdf5\n",
      "Epoch 152/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 20.4078 - mse: 20.4078 - val_loss: 42.1951 - val_mse: 42.1951\n",
      "\n",
      "Epoch 00152: val_mse did not improve from 31.29088\n",
      "Epoch 153/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.8582 - mse: 21.8582 - val_loss: 32.0455 - val_mse: 32.0455\n",
      "\n",
      "Epoch 00153: val_mse did not improve from 31.29088\n",
      "Epoch 154/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 20.9278 - mse: 20.9278 - val_loss: 33.2816 - val_mse: 33.2816\n",
      "\n",
      "Epoch 00154: val_mse did not improve from 31.29088\n",
      "Epoch 155/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22.7811 - mse: 22.7811 - val_loss: 30.5940 - val_mse: 30.5940\n",
      "\n",
      "Epoch 00155: val_mse improved from 31.29088 to 30.59398, saving model to ./model\\155-30.5940.hdf5\n",
      "Epoch 156/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 30.1254 - mse: 30.1254 - val_loss: 44.0753 - val_mse: 44.0753\n",
      "\n",
      "Epoch 00156: val_mse did not improve from 30.59398\n",
      "Epoch 157/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 27.2816 - mse: 27.2816 - val_loss: 39.6589 - val_mse: 39.6589\n",
      "\n",
      "Epoch 00157: val_mse did not improve from 30.59398\n",
      "Epoch 158/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 26.3199 - mse: 26.3199 - val_loss: 36.7675 - val_mse: 36.7675\n",
      "\n",
      "Epoch 00158: val_mse did not improve from 30.59398\n",
      "Epoch 159/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.1909 - mse: 21.1909 - val_loss: 30.6178 - val_mse: 30.6178\n",
      "\n",
      "Epoch 00159: val_mse did not improve from 30.59398\n",
      "Epoch 160/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.7394 - mse: 20.7394 - val_loss: 35.2811 - val_mse: 35.2811\n",
      "\n",
      "Epoch 00160: val_mse did not improve from 30.59398\n",
      "Epoch 161/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 21.2276 - mse: 21.2276 - val_loss: 31.2804 - val_mse: 31.2804\n",
      "\n",
      "Epoch 00161: val_mse did not improve from 30.59398\n",
      "Epoch 162/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20.2534 - mse: 20.2534 - val_loss: 31.4294 - val_mse: 31.4294\n",
      "\n",
      "Epoch 00162: val_mse did not improve from 30.59398\n",
      "Epoch 163/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20.4814 - mse: 20.4814 - val_loss: 34.6086 - val_mse: 34.6086\n",
      "\n",
      "Epoch 00163: val_mse did not improve from 30.59398\n",
      "Epoch 164/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21.6493 - mse: 21.6493 - val_loss: 31.9085 - val_mse: 31.9085\n",
      "\n",
      "Epoch 00164: val_mse did not improve from 30.59398\n",
      "Epoch 165/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.7530 - mse: 21.7530 - val_loss: 30.7826 - val_mse: 30.7826\n",
      "\n",
      "Epoch 00165: val_mse did not improve from 30.59398\n",
      "Epoch 166/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.1338 - mse: 20.1338 - val_loss: 33.5075 - val_mse: 33.5075\n",
      "\n",
      "Epoch 00166: val_mse did not improve from 30.59398\n",
      "Epoch 167/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 22.2189 - mse: 22.2189 - val_loss: 34.5235 - val_mse: 34.5235\n",
      "\n",
      "Epoch 00167: val_mse did not improve from 30.59398\n",
      "Epoch 168/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.5658 - mse: 20.5658 - val_loss: 31.0847 - val_mse: 31.0847\n",
      "\n",
      "Epoch 00168: val_mse did not improve from 30.59398\n",
      "Epoch 169/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.0484 - mse: 20.0484 - val_loss: 33.3914 - val_mse: 33.3914\n",
      "\n",
      "Epoch 00169: val_mse did not improve from 30.59398\n",
      "Epoch 170/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 23.6746 - mse: 23.6746 - val_loss: 38.1984 - val_mse: 38.1984\n",
      "\n",
      "Epoch 00170: val_mse did not improve from 30.59398\n",
      "Epoch 171/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 24.3181 - mse: 24.3181 - val_loss: 31.1669 - val_mse: 31.1669\n",
      "\n",
      "Epoch 00171: val_mse did not improve from 30.59398\n",
      "Epoch 172/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.2119 - mse: 21.2119 - val_loss: 31.8402 - val_mse: 31.8402\n",
      "\n",
      "Epoch 00172: val_mse did not improve from 30.59398\n",
      "Epoch 173/5000\n",
      "8/8 [==============================] - ETA: 0s - loss: 14.6569 - mse: 14.656 - 0s 5ms/step - loss: 19.7271 - mse: 19.7271 - val_loss: 30.4485 - val_mse: 30.4485\n",
      "\n",
      "Epoch 00173: val_mse improved from 30.59398 to 30.44851, saving model to ./model\\173-30.4485.hdf5\n",
      "Epoch 174/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 21.1552 - mse: 21.1552 - val_loss: 33.2342 - val_mse: 33.2342\n",
      "\n",
      "Epoch 00174: val_mse did not improve from 30.44851\n",
      "Epoch 175/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.2660 - mse: 20.2660 - val_loss: 31.5295 - val_mse: 31.5295\n",
      "\n",
      "Epoch 00175: val_mse did not improve from 30.44851\n",
      "Epoch 176/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.7211 - mse: 19.7211 - val_loss: 30.4213 - val_mse: 30.4213\n",
      "\n",
      "Epoch 00176: val_mse improved from 30.44851 to 30.42134, saving model to ./model\\176-30.4213.hdf5\n",
      "Epoch 177/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.4617 - mse: 19.4617 - val_loss: 37.8645 - val_mse: 37.8645\n",
      "\n",
      "Epoch 00177: val_mse did not improve from 30.42134\n",
      "Epoch 178/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 20.7564 - mse: 20.7564 - val_loss: 31.4472 - val_mse: 31.4472\n",
      "\n",
      "Epoch 00178: val_mse did not improve from 30.42134\n",
      "Epoch 179/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.6257 - mse: 20.6257 - val_loss: 32.1471 - val_mse: 32.1471\n",
      "\n",
      "Epoch 00179: val_mse did not improve from 30.42134\n",
      "Epoch 180/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 20.0496 - mse: 20.0496 - val_loss: 31.5619 - val_mse: 31.5619\n",
      "\n",
      "Epoch 00180: val_mse did not improve from 30.42134\n",
      "Epoch 181/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.1734 - mse: 20.1734 - val_loss: 30.5635 - val_mse: 30.5635\n",
      "\n",
      "Epoch 00181: val_mse did not improve from 30.42134\n",
      "Epoch 182/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 20.7627 - mse: 20.7627 - val_loss: 32.8134 - val_mse: 32.8134\n",
      "\n",
      "Epoch 00182: val_mse did not improve from 30.42134\n",
      "Epoch 183/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.2357 - mse: 19.2357 - val_loss: 33.7641 - val_mse: 33.7641\n",
      "\n",
      "Epoch 00183: val_mse did not improve from 30.42134\n",
      "Epoch 184/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 21.3988 - mse: 21.3988 - val_loss: 31.6783 - val_mse: 31.6783\n",
      "\n",
      "Epoch 00184: val_mse did not improve from 30.42134\n",
      "Epoch 185/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.5197 - mse: 19.5197 - val_loss: 29.9703 - val_mse: 29.9703\n",
      "\n",
      "Epoch 00185: val_mse improved from 30.42134 to 29.97029, saving model to ./model\\185-29.9703.hdf5\n",
      "Epoch 186/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.6181 - mse: 19.6181 - val_loss: 31.4758 - val_mse: 31.4758\n",
      "\n",
      "Epoch 00186: val_mse did not improve from 29.97029\n",
      "Epoch 187/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.5212 - mse: 19.5212 - val_loss: 30.1859 - val_mse: 30.1859\n",
      "\n",
      "Epoch 00187: val_mse did not improve from 29.97029\n",
      "Epoch 188/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.0169 - mse: 20.0169 - val_loss: 29.9348 - val_mse: 29.9348\n",
      "\n",
      "Epoch 00188: val_mse improved from 29.97029 to 29.93481, saving model to ./model\\188-29.9348.hdf5\n",
      "Epoch 189/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 20.3536 - mse: 20.3536 - val_loss: 30.5518 - val_mse: 30.5518\n",
      "\n",
      "Epoch 00189: val_mse did not improve from 29.93481\n",
      "Epoch 190/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.5977 - mse: 19.5977 - val_loss: 32.4019 - val_mse: 32.4019\n",
      "\n",
      "Epoch 00190: val_mse did not improve from 29.93481\n",
      "Epoch 191/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.9783 - mse: 18.9783 - val_loss: 29.9534 - val_mse: 29.9534\n",
      "\n",
      "Epoch 00191: val_mse did not improve from 29.93481\n",
      "Epoch 192/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.7486 - mse: 18.7486 - val_loss: 30.6086 - val_mse: 30.6086\n",
      "\n",
      "Epoch 00192: val_mse did not improve from 29.93481\n",
      "Epoch 193/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 22.2687 - mse: 22.2687 - val_loss: 30.8044 - val_mse: 30.8044\n",
      "\n",
      "Epoch 00193: val_mse did not improve from 29.93481\n",
      "Epoch 194/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.0442 - mse: 20.0442 - val_loss: 35.4855 - val_mse: 35.4855\n",
      "\n",
      "Epoch 00194: val_mse did not improve from 29.93481\n",
      "Epoch 195/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 23.4261 - mse: 23.4261 - val_loss: 41.5082 - val_mse: 41.5082\n",
      "\n",
      "Epoch 00195: val_mse did not improve from 29.93481\n",
      "Epoch 196/5000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 25.1000 - mse: 25.1000 - val_loss: 30.2660 - val_mse: 30.2660\n",
      "\n",
      "Epoch 00196: val_mse did not improve from 29.93481\n",
      "Epoch 197/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 25.2414 - mse: 25.2414 - val_loss: 32.7150 - val_mse: 32.7150\n",
      "\n",
      "Epoch 00197: val_mse did not improve from 29.93481\n",
      "Epoch 198/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 22.0669 - mse: 22.0669 - val_loss: 36.1333 - val_mse: 36.1333\n",
      "\n",
      "Epoch 00198: val_mse did not improve from 29.93481\n",
      "Epoch 199/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.2222 - mse: 20.2222 - val_loss: 31.7806 - val_mse: 31.7806\n",
      "\n",
      "Epoch 00199: val_mse did not improve from 29.93481\n",
      "Epoch 200/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 21.3097 - mse: 21.3097 - val_loss: 31.0953 - val_mse: 31.0953\n",
      "\n",
      "Epoch 00200: val_mse did not improve from 29.93481\n",
      "Epoch 201/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 20.4407 - mse: 20.4407 - val_loss: 34.4247 - val_mse: 34.4247\n",
      "\n",
      "Epoch 00201: val_mse did not improve from 29.93481\n",
      "Epoch 202/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.9489 - mse: 23.9489 - val_loss: 37.0924 - val_mse: 37.0924\n",
      "\n",
      "Epoch 00202: val_mse did not improve from 29.93481\n",
      "Epoch 203/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 25.8832 - mse: 25.8832 - val_loss: 34.7911 - val_mse: 34.7911\n",
      "\n",
      "Epoch 00203: val_mse did not improve from 29.93481\n",
      "Epoch 204/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 23.9043 - mse: 23.9043 - val_loss: 33.3966 - val_mse: 33.3966\n",
      "\n",
      "Epoch 00204: val_mse did not improve from 29.93481\n",
      "Epoch 205/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.3265 - mse: 19.3265 - val_loss: 32.1278 - val_mse: 32.1278\n",
      "\n",
      "Epoch 00205: val_mse did not improve from 29.93481\n",
      "Epoch 206/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.6620 - mse: 19.6620 - val_loss: 32.1176 - val_mse: 32.1176\n",
      "\n",
      "Epoch 00206: val_mse did not improve from 29.93481\n",
      "Epoch 207/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.1892 - mse: 19.1892 - val_loss: 31.0732 - val_mse: 31.0732\n",
      "\n",
      "Epoch 00207: val_mse did not improve from 29.93481\n",
      "Epoch 208/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.5214 - mse: 19.5214 - val_loss: 29.5050 - val_mse: 29.5050\n",
      "\n",
      "Epoch 00208: val_mse improved from 29.93481 to 29.50502, saving model to ./model\\208-29.5050.hdf5\n",
      "Epoch 209/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.8524 - mse: 18.8524 - val_loss: 33.5554 - val_mse: 33.5554\n",
      "\n",
      "Epoch 00209: val_mse did not improve from 29.50502\n",
      "Epoch 210/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.8272 - mse: 19.8272 - val_loss: 29.3199 - val_mse: 29.3199\n",
      "\n",
      "Epoch 00210: val_mse improved from 29.50502 to 29.31988, saving model to ./model\\210-29.3199.hdf5\n",
      "Epoch 211/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.1328 - mse: 18.1328 - val_loss: 29.9078 - val_mse: 29.9078\n",
      "\n",
      "Epoch 00211: val_mse did not improve from 29.31988\n",
      "Epoch 212/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18.0146 - mse: 18.0146 - val_loss: 29.0914 - val_mse: 29.0914\n",
      "\n",
      "Epoch 00212: val_mse improved from 29.31988 to 29.09140, saving model to ./model\\212-29.0914.hdf5\n",
      "Epoch 213/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17.6093 - mse: 17.6093 - val_loss: 29.4862 - val_mse: 29.4862\n",
      "\n",
      "Epoch 00213: val_mse did not improve from 29.09140\n",
      "Epoch 214/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.4160 - mse: 17.4160 - val_loss: 30.9044 - val_mse: 30.9044\n",
      "\n",
      "Epoch 00214: val_mse did not improve from 29.09140\n",
      "Epoch 215/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18.4115 - mse: 18.4115 - val_loss: 29.5147 - val_mse: 29.5147\n",
      "\n",
      "Epoch 00215: val_mse did not improve from 29.09140\n",
      "Epoch 216/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.2024 - mse: 18.2024 - val_loss: 29.0366 - val_mse: 29.0366\n",
      "\n",
      "Epoch 00216: val_mse improved from 29.09140 to 29.03658, saving model to ./model\\216-29.0366.hdf5\n",
      "Epoch 217/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.8858 - mse: 17.8858 - val_loss: 28.9983 - val_mse: 28.9983\n",
      "\n",
      "Epoch 00217: val_mse improved from 29.03658 to 28.99828, saving model to ./model\\217-28.9983.hdf5\n",
      "Epoch 218/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.4958 - mse: 18.4958 - val_loss: 28.7786 - val_mse: 28.7786\n",
      "\n",
      "Epoch 00218: val_mse improved from 28.99828 to 28.77857, saving model to ./model\\218-28.7786.hdf5\n",
      "Epoch 219/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 17.7635 - mse: 17.7635 - val_loss: 30.6366 - val_mse: 30.6366\n",
      "\n",
      "Epoch 00219: val_mse did not improve from 28.77857\n",
      "Epoch 220/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 19.6744 - mse: 19.6744 - val_loss: 31.0001 - val_mse: 31.0001\n",
      "\n",
      "Epoch 00220: val_mse did not improve from 28.77857\n",
      "Epoch 221/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 19.9049 - mse: 19.9049 - val_loss: 29.8216 - val_mse: 29.8216\n",
      "\n",
      "Epoch 00221: val_mse did not improve from 28.77857\n",
      "Epoch 222/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 22.1919 - mse: 22.1919 - val_loss: 37.4081 - val_mse: 37.4081\n",
      "\n",
      "Epoch 00222: val_mse did not improve from 28.77857\n",
      "Epoch 223/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.2713 - mse: 19.2713 - val_loss: 28.6177 - val_mse: 28.6177\n",
      "\n",
      "Epoch 00223: val_mse improved from 28.77857 to 28.61767, saving model to ./model\\223-28.6177.hdf5\n",
      "Epoch 224/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18.4071 - mse: 18.4071 - val_loss: 28.3358 - val_mse: 28.3358\n",
      "\n",
      "Epoch 00224: val_mse improved from 28.61767 to 28.33585, saving model to ./model\\224-28.3358.hdf5\n",
      "Epoch 225/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.8920 - mse: 16.8920 - val_loss: 29.4276 - val_mse: 29.4276\n",
      "\n",
      "Epoch 00225: val_mse did not improve from 28.33585\n",
      "Epoch 226/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.2875 - mse: 17.2875 - val_loss: 27.8467 - val_mse: 27.8467\n",
      "\n",
      "Epoch 00226: val_mse improved from 28.33585 to 27.84666, saving model to ./model\\226-27.8467.hdf5\n",
      "Epoch 227/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.1959 - mse: 17.1959 - val_loss: 30.7377 - val_mse: 30.7377\n",
      "\n",
      "Epoch 00227: val_mse did not improve from 27.84666\n",
      "Epoch 228/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.7814 - mse: 18.7814 - val_loss: 28.1156 - val_mse: 28.1156\n",
      "\n",
      "Epoch 00228: val_mse did not improve from 27.84666\n",
      "Epoch 229/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 17.0373 - mse: 17.0373 - val_loss: 29.1053 - val_mse: 29.1053\n",
      "\n",
      "Epoch 00229: val_mse did not improve from 27.84666\n",
      "Epoch 230/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.2165 - mse: 17.2165 - val_loss: 29.9702 - val_mse: 29.9702\n",
      "\n",
      "Epoch 00230: val_mse did not improve from 27.84666\n",
      "Epoch 231/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 19.2409 - mse: 19.2409 - val_loss: 28.1573 - val_mse: 28.1573\n",
      "\n",
      "Epoch 00231: val_mse did not improve from 27.84666\n",
      "Epoch 232/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.5624 - mse: 16.5624 - val_loss: 28.6840 - val_mse: 28.6840\n",
      "\n",
      "Epoch 00232: val_mse did not improve from 27.84666\n",
      "Epoch 233/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.1692 - mse: 18.1692 - val_loss: 28.6368 - val_mse: 28.6368\n",
      "\n",
      "Epoch 00233: val_mse did not improve from 27.84666\n",
      "Epoch 234/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.6641 - mse: 19.6641 - val_loss: 28.6475 - val_mse: 28.6475\n",
      "\n",
      "Epoch 00234: val_mse did not improve from 27.84666\n",
      "Epoch 235/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 22.3276 - mse: 22.3276 - val_loss: 29.2703 - val_mse: 29.2703\n",
      "\n",
      "Epoch 00235: val_mse did not improve from 27.84666\n",
      "Epoch 236/5000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 18.2992 - mse: 18.2992 - val_loss: 30.2786 - val_mse: 30.2786\n",
      "\n",
      "Epoch 00236: val_mse did not improve from 27.84666\n",
      "Epoch 237/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 19.4493 - mse: 19.4493 - val_loss: 32.0306 - val_mse: 32.0306\n",
      "\n",
      "Epoch 00237: val_mse did not improve from 27.84666\n",
      "Epoch 238/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 19.9809 - mse: 19.9809 - val_loss: 36.1890 - val_mse: 36.1890\n",
      "\n",
      "Epoch 00238: val_mse did not improve from 27.84666\n",
      "Epoch 239/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21.2927 - mse: 21.2927 - val_loss: 28.2843 - val_mse: 28.2843\n",
      "\n",
      "Epoch 00239: val_mse did not improve from 27.84666\n",
      "Epoch 240/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 17.9279 - mse: 17.9279 - val_loss: 27.7527 - val_mse: 27.7527\n",
      "\n",
      "Epoch 00240: val_mse improved from 27.84666 to 27.75266, saving model to ./model\\240-27.7527.hdf5\n",
      "Epoch 241/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 16.7135 - mse: 16.7135 - val_loss: 28.5924 - val_mse: 28.5924\n",
      "\n",
      "Epoch 00241: val_mse did not improve from 27.75266\n",
      "Epoch 242/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.4975 - mse: 17.4975 - val_loss: 29.7009 - val_mse: 29.7009\n",
      "\n",
      "Epoch 00242: val_mse did not improve from 27.75266\n",
      "Epoch 243/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18.1875 - mse: 18.1875 - val_loss: 28.3469 - val_mse: 28.3469\n",
      "\n",
      "Epoch 00243: val_mse did not improve from 27.75266\n",
      "Epoch 244/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 16.8028 - mse: 16.8028 - val_loss: 27.3193 - val_mse: 27.3193\n",
      "\n",
      "Epoch 00244: val_mse improved from 27.75266 to 27.31926, saving model to ./model\\244-27.3193.hdf5\n",
      "Epoch 245/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.3938 - mse: 16.3938 - val_loss: 28.5121 - val_mse: 28.5121\n",
      "\n",
      "Epoch 00245: val_mse did not improve from 27.31926\n",
      "Epoch 246/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17.4780 - mse: 17.4780 - val_loss: 28.6574 - val_mse: 28.6574\n",
      "\n",
      "Epoch 00246: val_mse did not improve from 27.31926\n",
      "Epoch 247/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.3319 - mse: 17.3319 - val_loss: 27.5320 - val_mse: 27.5320\n",
      "\n",
      "Epoch 00247: val_mse did not improve from 27.31926\n",
      "Epoch 248/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.7507 - mse: 16.7507 - val_loss: 28.6285 - val_mse: 28.6285\n",
      "\n",
      "Epoch 00248: val_mse did not improve from 27.31926\n",
      "Epoch 249/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.2734 - mse: 16.2734 - val_loss: 26.8186 - val_mse: 26.8186\n",
      "\n",
      "Epoch 00249: val_mse improved from 27.31926 to 26.81863, saving model to ./model\\249-26.8186.hdf5\n",
      "Epoch 250/5000\n",
      "8/8 [==============================] - ETA: 0s - loss: 11.6270 - mse: 11.627 - 0s 6ms/step - loss: 16.9207 - mse: 16.9207 - val_loss: 29.4228 - val_mse: 29.4228\n",
      "\n",
      "Epoch 00250: val_mse did not improve from 26.81863\n",
      "Epoch 251/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.9687 - mse: 16.9687 - val_loss: 27.1625 - val_mse: 27.1625\n",
      "\n",
      "Epoch 00251: val_mse did not improve from 26.81863\n",
      "Epoch 252/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 17.4118 - mse: 17.4118 - val_loss: 28.6023 - val_mse: 28.6023\n",
      "\n",
      "Epoch 00252: val_mse did not improve from 26.81863\n",
      "Epoch 253/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.8579 - mse: 16.8579 - val_loss: 27.6659 - val_mse: 27.6659\n",
      "\n",
      "Epoch 00253: val_mse did not improve from 26.81863\n",
      "Epoch 254/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.5089 - mse: 16.5089 - val_loss: 27.2281 - val_mse: 27.2281\n",
      "\n",
      "Epoch 00254: val_mse did not improve from 26.81863\n",
      "Epoch 255/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.9794 - mse: 17.9794 - val_loss: 30.4014 - val_mse: 30.4014\n",
      "\n",
      "Epoch 00255: val_mse did not improve from 26.81863\n",
      "Epoch 256/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.4249 - mse: 20.4249 - val_loss: 27.8513 - val_mse: 27.8513\n",
      "\n",
      "Epoch 00256: val_mse did not improve from 26.81863\n",
      "Epoch 257/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.9046 - mse: 19.9046 - val_loss: 30.1091 - val_mse: 30.1091\n",
      "\n",
      "Epoch 00257: val_mse did not improve from 26.81863\n",
      "Epoch 258/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.8634 - mse: 16.8634 - val_loss: 26.3356 - val_mse: 26.3356\n",
      "\n",
      "Epoch 00258: val_mse improved from 26.81863 to 26.33562, saving model to ./model\\258-26.3356.hdf5\n",
      "Epoch 259/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.3657 - mse: 16.3657 - val_loss: 28.4626 - val_mse: 28.4626\n",
      "\n",
      "Epoch 00259: val_mse did not improve from 26.33562\n",
      "Epoch 260/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.5098 - mse: 16.5098 - val_loss: 27.4448 - val_mse: 27.4448\n",
      "\n",
      "Epoch 00260: val_mse did not improve from 26.33562\n",
      "Epoch 261/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.4367 - mse: 16.4367 - val_loss: 26.9197 - val_mse: 26.9197\n",
      "\n",
      "Epoch 00261: val_mse did not improve from 26.33562\n",
      "Epoch 262/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.0020 - mse: 16.0020 - val_loss: 27.1513 - val_mse: 27.1513\n",
      "\n",
      "Epoch 00262: val_mse did not improve from 26.33562\n",
      "Epoch 263/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.8008 - mse: 15.8008 - val_loss: 31.6726 - val_mse: 31.6726\n",
      "\n",
      "Epoch 00263: val_mse did not improve from 26.33562\n",
      "Epoch 264/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.3176 - mse: 18.3176 - val_loss: 27.7224 - val_mse: 27.7224\n",
      "\n",
      "Epoch 00264: val_mse did not improve from 26.33562\n",
      "Epoch 265/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.5120 - mse: 18.5120 - val_loss: 33.5875 - val_mse: 33.5875\n",
      "\n",
      "Epoch 00265: val_mse did not improve from 26.33562\n",
      "Epoch 266/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17.3536 - mse: 17.3536 - val_loss: 25.8963 - val_mse: 25.8963\n",
      "\n",
      "Epoch 00266: val_mse improved from 26.33562 to 25.89627, saving model to ./model\\266-25.8963.hdf5\n",
      "Epoch 267/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.9357 - mse: 15.9357 - val_loss: 28.5398 - val_mse: 28.5398\n",
      "\n",
      "Epoch 00267: val_mse did not improve from 25.89627\n",
      "Epoch 268/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.3615 - mse: 16.3615 - val_loss: 26.8365 - val_mse: 26.8365\n",
      "\n",
      "Epoch 00268: val_mse did not improve from 25.89627\n",
      "Epoch 269/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.9285 - mse: 15.9285 - val_loss: 27.5523 - val_mse: 27.5523\n",
      "\n",
      "Epoch 00269: val_mse did not improve from 25.89627\n",
      "Epoch 270/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.7726 - mse: 15.7726 - val_loss: 25.2420 - val_mse: 25.2420\n",
      "\n",
      "Epoch 00270: val_mse improved from 25.89627 to 25.24203, saving model to ./model\\270-25.2420.hdf5\n",
      "Epoch 271/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 15.9103 - mse: 15.9103 - val_loss: 26.0266 - val_mse: 26.0266\n",
      "\n",
      "Epoch 00271: val_mse did not improve from 25.24203\n",
      "Epoch 272/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 15.2038 - mse: 15.2038 - val_loss: 26.3614 - val_mse: 26.3614\n",
      "\n",
      "Epoch 00272: val_mse did not improve from 25.24203\n",
      "Epoch 273/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 15.1763 - mse: 15.1763 - val_loss: 26.4543 - val_mse: 26.4543\n",
      "\n",
      "Epoch 00273: val_mse did not improve from 25.24203\n",
      "Epoch 274/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 16.0819 - mse: 16.0819 - val_loss: 25.8779 - val_mse: 25.8779\n",
      "\n",
      "Epoch 00274: val_mse did not improve from 25.24203\n",
      "Epoch 275/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 14.9765 - mse: 14.9765 - val_loss: 25.6247 - val_mse: 25.6247\n",
      "\n",
      "Epoch 00275: val_mse did not improve from 25.24203\n",
      "Epoch 276/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.3775 - mse: 15.3775 - val_loss: 26.3635 - val_mse: 26.3635\n",
      "\n",
      "Epoch 00276: val_mse did not improve from 25.24203\n",
      "Epoch 277/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 15.8041 - mse: 15.8041 - val_loss: 26.9016 - val_mse: 26.9016\n",
      "\n",
      "Epoch 00277: val_mse did not improve from 25.24203\n",
      "Epoch 278/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.1073 - mse: 16.1073 - val_loss: 26.1960 - val_mse: 26.1960\n",
      "\n",
      "Epoch 00278: val_mse did not improve from 25.24203\n",
      "Epoch 279/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.4921 - mse: 16.4921 - val_loss: 30.1508 - val_mse: 30.1508\n",
      "\n",
      "Epoch 00279: val_mse did not improve from 25.24203\n",
      "Epoch 280/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 18.6686 - mse: 18.6686 - val_loss: 37.1517 - val_mse: 37.1517\n",
      "\n",
      "Epoch 00280: val_mse did not improve from 25.24203\n",
      "Epoch 281/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 21.9227 - mse: 21.9227 - val_loss: 32.9580 - val_mse: 32.9580\n",
      "\n",
      "Epoch 00281: val_mse did not improve from 25.24203\n",
      "Epoch 282/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.5456 - mse: 18.5456 - val_loss: 26.6614 - val_mse: 26.6614\n",
      "\n",
      "Epoch 00282: val_mse did not improve from 25.24203\n",
      "Epoch 283/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.7732 - mse: 15.7732 - val_loss: 25.6341 - val_mse: 25.6341\n",
      "\n",
      "Epoch 00283: val_mse did not improve from 25.24203\n",
      "Epoch 284/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.3149 - mse: 15.3149 - val_loss: 26.7513 - val_mse: 26.7513\n",
      "\n",
      "Epoch 00284: val_mse did not improve from 25.24203\n",
      "Epoch 285/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.1813 - mse: 15.1813 - val_loss: 25.3171 - val_mse: 25.3171\n",
      "\n",
      "Epoch 00285: val_mse did not improve from 25.24203\n",
      "Epoch 286/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 15.2027 - mse: 15.2027 - val_loss: 26.5348 - val_mse: 26.5348\n",
      "\n",
      "Epoch 00286: val_mse did not improve from 25.24203\n",
      "Epoch 287/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.3906 - mse: 16.3906 - val_loss: 30.1408 - val_mse: 30.1408\n",
      "\n",
      "Epoch 00287: val_mse did not improve from 25.24203\n",
      "Epoch 288/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.3649 - mse: 16.3649 - val_loss: 27.3493 - val_mse: 27.3493\n",
      "\n",
      "Epoch 00288: val_mse did not improve from 25.24203\n",
      "Epoch 289/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.9911 - mse: 16.9911 - val_loss: 27.6910 - val_mse: 27.6910\n",
      "\n",
      "Epoch 00289: val_mse did not improve from 25.24203\n",
      "Epoch 290/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.3464 - mse: 17.3464 - val_loss: 25.5974 - val_mse: 25.5974\n",
      "\n",
      "Epoch 00290: val_mse did not improve from 25.24203\n",
      "Epoch 291/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.8985 - mse: 15.8985 - val_loss: 29.7926 - val_mse: 29.7926\n",
      "\n",
      "Epoch 00291: val_mse did not improve from 25.24203\n",
      "Epoch 292/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.8252 - mse: 16.8252 - val_loss: 24.9765 - val_mse: 24.9765\n",
      "\n",
      "Epoch 00292: val_mse improved from 25.24203 to 24.97655, saving model to ./model\\292-24.9765.hdf5\n",
      "Epoch 293/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.0440 - mse: 15.0440 - val_loss: 30.4327 - val_mse: 30.4327\n",
      "\n",
      "Epoch 00293: val_mse did not improve from 24.97655\n",
      "Epoch 294/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.7495 - mse: 16.7495 - val_loss: 24.8182 - val_mse: 24.8182\n",
      "\n",
      "Epoch 00294: val_mse improved from 24.97655 to 24.81816, saving model to ./model\\294-24.8182.hdf5\n",
      "Epoch 295/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.5454 - mse: 14.5454 - val_loss: 24.8664 - val_mse: 24.8664\n",
      "\n",
      "Epoch 00295: val_mse did not improve from 24.81816\n",
      "Epoch 296/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.9992 - mse: 14.9992 - val_loss: 25.2475 - val_mse: 25.2475\n",
      "\n",
      "Epoch 00296: val_mse did not improve from 24.81816\n",
      "Epoch 297/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.0461 - mse: 15.0461 - val_loss: 25.5664 - val_mse: 25.5664\n",
      "\n",
      "Epoch 00297: val_mse did not improve from 24.81816\n",
      "Epoch 298/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.7994 - mse: 16.7994 - val_loss: 24.9348 - val_mse: 24.9348\n",
      "\n",
      "Epoch 00298: val_mse did not improve from 24.81816\n",
      "Epoch 299/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17.7909 - mse: 17.7909 - val_loss: 26.5896 - val_mse: 26.5896\n",
      "\n",
      "Epoch 00299: val_mse did not improve from 24.81816\n",
      "Epoch 300/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.6588 - mse: 16.6588 - val_loss: 25.5108 - val_mse: 25.5108\n",
      "\n",
      "Epoch 00300: val_mse did not improve from 24.81816\n",
      "Epoch 301/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.2212 - mse: 15.2212 - val_loss: 25.6490 - val_mse: 25.6490\n",
      "\n",
      "Epoch 00301: val_mse did not improve from 24.81816\n",
      "Epoch 302/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.2351 - mse: 15.2351 - val_loss: 24.8381 - val_mse: 24.8381\n",
      "\n",
      "Epoch 00302: val_mse did not improve from 24.81816\n",
      "Epoch 303/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.1273 - mse: 15.1273 - val_loss: 25.6777 - val_mse: 25.6777\n",
      "\n",
      "Epoch 00303: val_mse did not improve from 24.81816\n",
      "Epoch 304/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.8426 - mse: 14.8426 - val_loss: 25.2894 - val_mse: 25.2894\n",
      "\n",
      "Epoch 00304: val_mse did not improve from 24.81816\n",
      "Epoch 305/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 14.8182 - mse: 14.8182 - val_loss: 24.9104 - val_mse: 24.9104\n",
      "\n",
      "Epoch 00305: val_mse did not improve from 24.81816\n",
      "Epoch 306/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.7510 - mse: 14.7510 - val_loss: 24.4384 - val_mse: 24.4384\n",
      "\n",
      "Epoch 00306: val_mse improved from 24.81816 to 24.43837, saving model to ./model\\306-24.4384.hdf5\n",
      "Epoch 307/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.8260 - mse: 14.8260 - val_loss: 25.3169 - val_mse: 25.3169\n",
      "\n",
      "Epoch 00307: val_mse did not improve from 24.43837\n",
      "Epoch 308/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.3847 - mse: 14.3847 - val_loss: 24.5459 - val_mse: 24.5459\n",
      "\n",
      "Epoch 00308: val_mse did not improve from 24.43837\n",
      "Epoch 309/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.6584 - mse: 14.6584 - val_loss: 24.9550 - val_mse: 24.9550\n",
      "\n",
      "Epoch 00309: val_mse did not improve from 24.43837\n",
      "Epoch 310/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.8970 - mse: 14.8970 - val_loss: 26.3120 - val_mse: 26.3120\n",
      "\n",
      "Epoch 00310: val_mse did not improve from 24.43837\n",
      "Epoch 311/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.3666 - mse: 16.3666 - val_loss: 26.1337 - val_mse: 26.1337\n",
      "\n",
      "Epoch 00311: val_mse did not improve from 24.43837\n",
      "Epoch 312/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.5966 - mse: 15.5966 - val_loss: 24.7060 - val_mse: 24.7060\n",
      "\n",
      "Epoch 00312: val_mse did not improve from 24.43837\n",
      "Epoch 313/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.0549 - mse: 15.0549 - val_loss: 26.6267 - val_mse: 26.6267\n",
      "\n",
      "Epoch 00313: val_mse did not improve from 24.43837\n",
      "Epoch 314/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.0908 - mse: 15.0908 - val_loss: 30.7703 - val_mse: 30.7703\n",
      "\n",
      "Epoch 00314: val_mse did not improve from 24.43837\n",
      "Epoch 315/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 18.2540 - mse: 18.2540 - val_loss: 32.5880 - val_mse: 32.5880\n",
      "\n",
      "Epoch 00315: val_mse did not improve from 24.43837\n",
      "Epoch 316/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 17.4540 - mse: 17.4540 - val_loss: 24.4876 - val_mse: 24.4876\n",
      "\n",
      "Epoch 00316: val_mse did not improve from 24.43837\n",
      "Epoch 317/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18.5028 - mse: 18.5028 - val_loss: 30.1159 - val_mse: 30.1159\n",
      "\n",
      "Epoch 00317: val_mse did not improve from 24.43837\n",
      "Epoch 318/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.3939 - mse: 17.3939 - val_loss: 28.5468 - val_mse: 28.5468\n",
      "\n",
      "Epoch 00318: val_mse did not improve from 24.43837\n",
      "Epoch 319/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.2929 - mse: 18.2929 - val_loss: 26.7622 - val_mse: 26.7622\n",
      "\n",
      "Epoch 00319: val_mse did not improve from 24.43837\n",
      "Epoch 320/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 19.4996 - mse: 19.4996 - val_loss: 25.4042 - val_mse: 25.4042\n",
      "\n",
      "Epoch 00320: val_mse did not improve from 24.43837\n",
      "Epoch 321/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.4449 - mse: 15.4449 - val_loss: 24.2893 - val_mse: 24.2893\n",
      "\n",
      "Epoch 00321: val_mse improved from 24.43837 to 24.28926, saving model to ./model\\321-24.2893.hdf5\n",
      "Epoch 322/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 14.1920 - mse: 14.1920 - val_loss: 25.2637 - val_mse: 25.2637\n",
      "\n",
      "Epoch 00322: val_mse did not improve from 24.28926\n",
      "Epoch 323/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.3698 - mse: 15.3698 - val_loss: 24.8140 - val_mse: 24.8140\n",
      "\n",
      "Epoch 00323: val_mse did not improve from 24.28926\n",
      "Epoch 324/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 14.2244 - mse: 14.2244 - val_loss: 24.0342 - val_mse: 24.0342\n",
      "\n",
      "Epoch 00324: val_mse improved from 24.28926 to 24.03423, saving model to ./model\\324-24.0342.hdf5\n",
      "Epoch 325/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.0057 - mse: 15.0057 - val_loss: 24.2791 - val_mse: 24.2791\n",
      "\n",
      "Epoch 00325: val_mse did not improve from 24.03423\n",
      "Epoch 326/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.2839 - mse: 15.2839 - val_loss: 26.6080 - val_mse: 26.6080\n",
      "\n",
      "Epoch 00326: val_mse did not improve from 24.03423\n",
      "Epoch 327/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 16.7466 - mse: 16.7466 - val_loss: 24.3156 - val_mse: 24.3156\n",
      "\n",
      "Epoch 00327: val_mse did not improve from 24.03423\n",
      "Epoch 328/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 15.0083 - mse: 15.0083 - val_loss: 26.6937 - val_mse: 26.6937\n",
      "\n",
      "Epoch 00328: val_mse did not improve from 24.03423\n",
      "Epoch 329/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.3639 - mse: 15.3639 - val_loss: 23.4999 - val_mse: 23.4999\n",
      "\n",
      "Epoch 00329: val_mse improved from 24.03423 to 23.49988, saving model to ./model\\329-23.4999.hdf5\n",
      "Epoch 330/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.1409 - mse: 14.1409 - val_loss: 24.0367 - val_mse: 24.0367\n",
      "\n",
      "Epoch 00330: val_mse did not improve from 23.49988\n",
      "Epoch 331/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 14.0109 - mse: 14.0109 - val_loss: 23.9280 - val_mse: 23.9280\n",
      "\n",
      "Epoch 00331: val_mse did not improve from 23.49988\n",
      "Epoch 332/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 13.8802 - mse: 13.8802 - val_loss: 23.4121 - val_mse: 23.4121\n",
      "\n",
      "Epoch 00332: val_mse improved from 23.49988 to 23.41206, saving model to ./model\\332-23.4121.hdf5\n",
      "Epoch 333/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.8321 - mse: 13.8321 - val_loss: 24.2257 - val_mse: 24.2257\n",
      "\n",
      "Epoch 00333: val_mse did not improve from 23.41206\n",
      "Epoch 334/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.9752 - mse: 14.9752 - val_loss: 23.8255 - val_mse: 23.8255\n",
      "\n",
      "Epoch 00334: val_mse did not improve from 23.41206\n",
      "Epoch 335/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 14.9541 - mse: 14.9541 - val_loss: 24.3600 - val_mse: 24.3600\n",
      "\n",
      "Epoch 00335: val_mse did not improve from 23.41206\n",
      "Epoch 336/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.6653 - mse: 15.6653 - val_loss: 26.9209 - val_mse: 26.9209\n",
      "\n",
      "Epoch 00336: val_mse did not improve from 23.41206\n",
      "Epoch 337/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.4270 - mse: 16.4270 - val_loss: 24.4910 - val_mse: 24.4910\n",
      "\n",
      "Epoch 00337: val_mse did not improve from 23.41206\n",
      "Epoch 338/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.3600 - mse: 15.3600 - val_loss: 28.2648 - val_mse: 28.2648\n",
      "\n",
      "Epoch 00338: val_mse did not improve from 23.41206\n",
      "Epoch 339/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.6566 - mse: 14.6566 - val_loss: 24.1708 - val_mse: 24.1708\n",
      "\n",
      "Epoch 00339: val_mse did not improve from 23.41206\n",
      "Epoch 340/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.7301 - mse: 13.7301 - val_loss: 24.4644 - val_mse: 24.4644\n",
      "\n",
      "Epoch 00340: val_mse did not improve from 23.41206\n",
      "Epoch 341/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 14.5006 - mse: 14.5006 - val_loss: 23.7257 - val_mse: 23.7257\n",
      "\n",
      "Epoch 00341: val_mse did not improve from 23.41206\n",
      "Epoch 342/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.4962 - mse: 15.4962 - val_loss: 28.5457 - val_mse: 28.5457\n",
      "\n",
      "Epoch 00342: val_mse did not improve from 23.41206\n",
      "Epoch 343/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.8140 - mse: 16.8140 - val_loss: 28.9416 - val_mse: 28.9416\n",
      "\n",
      "Epoch 00343: val_mse did not improve from 23.41206\n",
      "Epoch 344/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.5003 - mse: 16.5003 - val_loss: 28.0292 - val_mse: 28.0292\n",
      "\n",
      "Epoch 00344: val_mse did not improve from 23.41206\n",
      "Epoch 345/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.4584 - mse: 15.4584 - val_loss: 24.0091 - val_mse: 24.0091\n",
      "\n",
      "Epoch 00345: val_mse did not improve from 23.41206\n",
      "Epoch 346/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.5120 - mse: 15.5120 - val_loss: 26.5057 - val_mse: 26.5057\n",
      "\n",
      "Epoch 00346: val_mse did not improve from 23.41206\n",
      "Epoch 347/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.5679 - mse: 14.5679 - val_loss: 24.1079 - val_mse: 24.1079\n",
      "\n",
      "Epoch 00347: val_mse did not improve from 23.41206\n",
      "Epoch 348/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.1027 - mse: 15.1027 - val_loss: 24.5569 - val_mse: 24.5569\n",
      "\n",
      "Epoch 00348: val_mse did not improve from 23.41206\n",
      "Epoch 349/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.7676 - mse: 14.7676 - val_loss: 25.9084 - val_mse: 25.9084\n",
      "\n",
      "Epoch 00349: val_mse did not improve from 23.41206\n",
      "Epoch 350/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.8298 - mse: 14.8298 - val_loss: 23.3252 - val_mse: 23.3252\n",
      "\n",
      "Epoch 00350: val_mse improved from 23.41206 to 23.32518, saving model to ./model\\350-23.3252.hdf5\n",
      "Epoch 351/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.5968 - mse: 14.5968 - val_loss: 26.9934 - val_mse: 26.9934\n",
      "\n",
      "Epoch 00351: val_mse did not improve from 23.32518\n",
      "Epoch 352/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.5943 - mse: 13.5943 - val_loss: 23.5262 - val_mse: 23.5262\n",
      "\n",
      "Epoch 00352: val_mse did not improve from 23.32518\n",
      "Epoch 353/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.2283 - mse: 14.2283 - val_loss: 23.7435 - val_mse: 23.7435\n",
      "\n",
      "Epoch 00353: val_mse did not improve from 23.32518\n",
      "Epoch 354/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.2134 - mse: 14.2134 - val_loss: 23.7112 - val_mse: 23.7112\n",
      "\n",
      "Epoch 00354: val_mse did not improve from 23.32518\n",
      "Epoch 355/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.8807 - mse: 14.8807 - val_loss: 29.1050 - val_mse: 29.1050\n",
      "\n",
      "Epoch 00355: val_mse did not improve from 23.32518\n",
      "Epoch 356/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.1447 - mse: 19.1447 - val_loss: 27.9600 - val_mse: 27.9600\n",
      "\n",
      "Epoch 00356: val_mse did not improve from 23.32518\n",
      "Epoch 357/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.2496 - mse: 17.2496 - val_loss: 24.4946 - val_mse: 24.4946\n",
      "\n",
      "Epoch 00357: val_mse did not improve from 23.32518\n",
      "Epoch 358/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.0026 - mse: 15.0026 - val_loss: 23.9440 - val_mse: 23.9440\n",
      "\n",
      "Epoch 00358: val_mse did not improve from 23.32518\n",
      "Epoch 359/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.5736 - mse: 16.5736 - val_loss: 24.0436 - val_mse: 24.0436\n",
      "\n",
      "Epoch 00359: val_mse did not improve from 23.32518\n",
      "Epoch 360/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 18.6976 - mse: 18.6976 - val_loss: 27.2655 - val_mse: 27.2655\n",
      "\n",
      "Epoch 00360: val_mse did not improve from 23.32518\n",
      "Epoch 361/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 20.7758 - mse: 20.7758 - val_loss: 35.8215 - val_mse: 35.8215\n",
      "\n",
      "Epoch 00361: val_mse did not improve from 23.32518\n",
      "Epoch 362/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 19.3380 - mse: 19.3380 - val_loss: 39.4109 - val_mse: 39.4109\n",
      "\n",
      "Epoch 00362: val_mse did not improve from 23.32518\n",
      "Epoch 363/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 19.9430 - mse: 19.9430 - val_loss: 22.9541 - val_mse: 22.9541\n",
      "\n",
      "Epoch 00363: val_mse improved from 23.32518 to 22.95407, saving model to ./model\\363-22.9541.hdf5\n",
      "Epoch 364/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 18.8764 - mse: 18.8764 - val_loss: 28.9010 - val_mse: 28.9010\n",
      "\n",
      "Epoch 00364: val_mse did not improve from 22.95407\n",
      "Epoch 365/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.1149 - mse: 16.1149 - val_loss: 23.5932 - val_mse: 23.5932\n",
      "\n",
      "Epoch 00365: val_mse did not improve from 22.95407\n",
      "Epoch 366/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.8996 - mse: 14.8996 - val_loss: 26.0994 - val_mse: 26.0994\n",
      "\n",
      "Epoch 00366: val_mse did not improve from 22.95407\n",
      "Epoch 367/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.5655 - mse: 16.5655 - val_loss: 27.6747 - val_mse: 27.6747\n",
      "\n",
      "Epoch 00367: val_mse did not improve from 22.95407\n",
      "Epoch 368/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.5616 - mse: 15.5616 - val_loss: 26.2865 - val_mse: 26.2865\n",
      "\n",
      "Epoch 00368: val_mse did not improve from 22.95407\n",
      "Epoch 369/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.2844 - mse: 18.2844 - val_loss: 23.1089 - val_mse: 23.1089\n",
      "\n",
      "Epoch 00369: val_mse did not improve from 22.95407\n",
      "Epoch 370/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.0513 - mse: 16.0513 - val_loss: 31.6186 - val_mse: 31.6186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00370: val_mse did not improve from 22.95407\n",
      "Epoch 371/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 17.5397 - mse: 17.5397 - val_loss: 26.2996 - val_mse: 26.2996\n",
      "\n",
      "Epoch 00371: val_mse did not improve from 22.95407\n",
      "Epoch 372/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 22.4581 - mse: 22.4581 - val_loss: 25.0593 - val_mse: 25.0593\n",
      "\n",
      "Epoch 00372: val_mse did not improve from 22.95407\n",
      "Epoch 373/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.8801 - mse: 16.8801 - val_loss: 28.4335 - val_mse: 28.4335\n",
      "\n",
      "Epoch 00373: val_mse did not improve from 22.95407\n",
      "Epoch 374/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.9828 - mse: 14.9828 - val_loss: 22.4939 - val_mse: 22.4939\n",
      "\n",
      "Epoch 00374: val_mse improved from 22.95407 to 22.49389, saving model to ./model\\374-22.4939.hdf5\n",
      "Epoch 375/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.2340 - mse: 13.2340 - val_loss: 24.5401 - val_mse: 24.5401\n",
      "\n",
      "Epoch 00375: val_mse did not improve from 22.49389\n",
      "Epoch 376/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 17.2828 - mse: 17.2828 - val_loss: 23.3553 - val_mse: 23.3553\n",
      "\n",
      "Epoch 00376: val_mse did not improve from 22.49389\n",
      "Epoch 377/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.7883 - mse: 13.7883 - val_loss: 24.3752 - val_mse: 24.3752\n",
      "\n",
      "Epoch 00377: val_mse did not improve from 22.49389\n",
      "Epoch 378/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.1561 - mse: 17.1561 - val_loss: 30.3108 - val_mse: 30.3108\n",
      "\n",
      "Epoch 00378: val_mse did not improve from 22.49389\n",
      "Epoch 379/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 16.4466 - mse: 16.4466 - val_loss: 25.3777 - val_mse: 25.3777\n",
      "\n",
      "Epoch 00379: val_mse did not improve from 22.49389\n",
      "Epoch 380/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.8682 - mse: 13.8682 - val_loss: 22.7935 - val_mse: 22.7935\n",
      "\n",
      "Epoch 00380: val_mse did not improve from 22.49389\n",
      "Epoch 381/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 14.5821 - mse: 14.5821 - val_loss: 24.0168 - val_mse: 24.0168\n",
      "\n",
      "Epoch 00381: val_mse did not improve from 22.49389\n",
      "Epoch 382/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.7577 - mse: 13.7577 - val_loss: 24.6958 - val_mse: 24.6958\n",
      "\n",
      "Epoch 00382: val_mse did not improve from 22.49389\n",
      "Epoch 383/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.3025 - mse: 14.3025 - val_loss: 23.9402 - val_mse: 23.9402\n",
      "\n",
      "Epoch 00383: val_mse did not improve from 22.49389\n",
      "Epoch 384/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 13.7786 - mse: 13.7786 - val_loss: 23.3220 - val_mse: 23.3220\n",
      "\n",
      "Epoch 00384: val_mse did not improve from 22.49389\n",
      "Epoch 385/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.2122 - mse: 13.2122 - val_loss: 23.7621 - val_mse: 23.7621\n",
      "\n",
      "Epoch 00385: val_mse did not improve from 22.49389\n",
      "Epoch 386/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.4937 - mse: 13.4937 - val_loss: 24.3248 - val_mse: 24.3248\n",
      "\n",
      "Epoch 00386: val_mse did not improve from 22.49389\n",
      "Epoch 387/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.4841 - mse: 14.4841 - val_loss: 25.6110 - val_mse: 25.6110\n",
      "\n",
      "Epoch 00387: val_mse did not improve from 22.49389\n",
      "Epoch 388/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.3312 - mse: 14.3312 - val_loss: 23.6344 - val_mse: 23.6344\n",
      "\n",
      "Epoch 00388: val_mse did not improve from 22.49389\n",
      "Epoch 389/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 15.9750 - mse: 15.9750 - val_loss: 25.3668 - val_mse: 25.3668\n",
      "\n",
      "Epoch 00389: val_mse did not improve from 22.49389\n",
      "Epoch 390/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.8926 - mse: 16.8926 - val_loss: 40.8066 - val_mse: 40.8066\n",
      "\n",
      "Epoch 00390: val_mse did not improve from 22.49389\n",
      "Epoch 391/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 18.8522 - mse: 18.8522 - val_loss: 21.7914 - val_mse: 21.7914\n",
      "\n",
      "Epoch 00391: val_mse improved from 22.49389 to 21.79141, saving model to ./model\\391-21.7914.hdf5\n",
      "Epoch 392/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.2806 - mse: 15.2806 - val_loss: 24.1186 - val_mse: 24.1186\n",
      "\n",
      "Epoch 00392: val_mse did not improve from 21.79141\n",
      "Epoch 393/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.0141 - mse: 14.0141 - val_loss: 23.8141 - val_mse: 23.8141\n",
      "\n",
      "Epoch 00393: val_mse did not improve from 21.79141\n",
      "Epoch 394/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.5121 - mse: 12.5121 - val_loss: 22.6384 - val_mse: 22.6384\n",
      "\n",
      "Epoch 00394: val_mse did not improve from 21.79141\n",
      "Epoch 395/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.5171 - mse: 13.5171 - val_loss: 22.7138 - val_mse: 22.7138\n",
      "\n",
      "Epoch 00395: val_mse did not improve from 21.79141\n",
      "Epoch 396/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.6569 - mse: 13.6569 - val_loss: 23.3094 - val_mse: 23.3094\n",
      "\n",
      "Epoch 00396: val_mse did not improve from 21.79141\n",
      "Epoch 397/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.1468 - mse: 13.1468 - val_loss: 23.5229 - val_mse: 23.5229\n",
      "\n",
      "Epoch 00397: val_mse did not improve from 21.79141\n",
      "Epoch 398/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.0678 - mse: 14.0678 - val_loss: 22.3639 - val_mse: 22.3639\n",
      "\n",
      "Epoch 00398: val_mse did not improve from 21.79141\n",
      "Epoch 399/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.8573 - mse: 13.8573 - val_loss: 22.9943 - val_mse: 22.9943\n",
      "\n",
      "Epoch 00399: val_mse did not improve from 21.79141\n",
      "Epoch 400/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.1048 - mse: 13.1048 - val_loss: 23.6046 - val_mse: 23.6046\n",
      "\n",
      "Epoch 00400: val_mse did not improve from 21.79141\n",
      "Epoch 401/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.8005 - mse: 16.8005 - val_loss: 29.4806 - val_mse: 29.4806\n",
      "\n",
      "Epoch 00401: val_mse did not improve from 21.79141\n",
      "Epoch 402/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.0551 - mse: 16.0551 - val_loss: 26.4050 - val_mse: 26.4050\n",
      "\n",
      "Epoch 00402: val_mse did not improve from 21.79141\n",
      "Epoch 403/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.8637 - mse: 14.8637 - val_loss: 24.5491 - val_mse: 24.5491\n",
      "\n",
      "Epoch 00403: val_mse did not improve from 21.79141\n",
      "Epoch 404/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.2714 - mse: 13.2714 - val_loss: 22.0628 - val_mse: 22.0628\n",
      "\n",
      "Epoch 00404: val_mse did not improve from 21.79141\n",
      "Epoch 405/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.3932 - mse: 13.3932 - val_loss: 22.5134 - val_mse: 22.5134\n",
      "\n",
      "Epoch 00405: val_mse did not improve from 21.79141\n",
      "Epoch 406/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.1047 - mse: 13.1047 - val_loss: 24.6686 - val_mse: 24.6686\n",
      "\n",
      "Epoch 00406: val_mse did not improve from 21.79141\n",
      "Epoch 407/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.5284 - mse: 13.5284 - val_loss: 23.1479 - val_mse: 23.1479\n",
      "\n",
      "Epoch 00407: val_mse did not improve from 21.79141\n",
      "Epoch 408/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.9866 - mse: 12.9866 - val_loss: 22.3849 - val_mse: 22.3849\n",
      "\n",
      "Epoch 00408: val_mse did not improve from 21.79141\n",
      "Epoch 409/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 14.0624 - mse: 14.0624 - val_loss: 23.9086 - val_mse: 23.9086\n",
      "\n",
      "Epoch 00409: val_mse did not improve from 21.79141\n",
      "Epoch 410/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.0961 - mse: 13.0961 - val_loss: 22.0746 - val_mse: 22.0746\n",
      "\n",
      "Epoch 00410: val_mse did not improve from 21.79141\n",
      "Epoch 411/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.3998 - mse: 13.3998 - val_loss: 23.6051 - val_mse: 23.6051\n",
      "\n",
      "Epoch 00411: val_mse did not improve from 21.79141\n",
      "Epoch 412/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 14.6138 - mse: 14.6138 - val_loss: 22.9757 - val_mse: 22.9757\n",
      "\n",
      "Epoch 00412: val_mse did not improve from 21.79141\n",
      "Epoch 413/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.4480 - mse: 16.4480 - val_loss: 21.8836 - val_mse: 21.8836\n",
      "\n",
      "Epoch 00413: val_mse did not improve from 21.79141\n",
      "Epoch 414/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 5ms/step - loss: 13.0890 - mse: 13.0890 - val_loss: 22.1992 - val_mse: 22.1992\n",
      "\n",
      "Epoch 00414: val_mse did not improve from 21.79141\n",
      "Epoch 415/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.2754 - mse: 13.2754 - val_loss: 22.3986 - val_mse: 22.3986\n",
      "\n",
      "Epoch 00415: val_mse did not improve from 21.79141\n",
      "Epoch 416/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.0705 - mse: 13.0705 - val_loss: 23.6215 - val_mse: 23.6215\n",
      "\n",
      "Epoch 00416: val_mse did not improve from 21.79141\n",
      "Epoch 417/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.9180 - mse: 12.9180 - val_loss: 22.9973 - val_mse: 22.9973\n",
      "\n",
      "Epoch 00417: val_mse did not improve from 21.79141\n",
      "Epoch 418/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.8438 - mse: 12.8438 - val_loss: 23.5417 - val_mse: 23.5417\n",
      "\n",
      "Epoch 00418: val_mse did not improve from 21.79141\n",
      "Epoch 419/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.5948 - mse: 14.5948 - val_loss: 23.7121 - val_mse: 23.7121\n",
      "\n",
      "Epoch 00419: val_mse did not improve from 21.79141\n",
      "Epoch 420/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 15.1855 - mse: 15.1855 - val_loss: 22.4033 - val_mse: 22.4033\n",
      "\n",
      "Epoch 00420: val_mse did not improve from 21.79141\n",
      "Epoch 421/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 17.6987 - mse: 17.6987 - val_loss: 22.5972 - val_mse: 22.5972\n",
      "\n",
      "Epoch 00421: val_mse did not improve from 21.79141\n",
      "Epoch 422/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.1161 - mse: 13.1161 - val_loss: 25.0972 - val_mse: 25.0972\n",
      "\n",
      "Epoch 00422: val_mse did not improve from 21.79141\n",
      "Epoch 423/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 15.1413 - mse: 15.1413 - val_loss: 27.1478 - val_mse: 27.1478\n",
      "\n",
      "Epoch 00423: val_mse did not improve from 21.79141\n",
      "Epoch 424/5000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14.2793 - mse: 14.2793 - val_loss: 22.4350 - val_mse: 22.4350\n",
      "\n",
      "Epoch 00424: val_mse did not improve from 21.79141\n",
      "Epoch 425/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.9056 - mse: 12.9056 - val_loss: 23.1705 - val_mse: 23.1705\n",
      "\n",
      "Epoch 00425: val_mse did not improve from 21.79141\n",
      "Epoch 426/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.8776 - mse: 12.8776 - val_loss: 21.6652 - val_mse: 21.6652\n",
      "\n",
      "Epoch 00426: val_mse improved from 21.79141 to 21.66517, saving model to ./model\\426-21.6652.hdf5\n",
      "Epoch 427/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.0551 - mse: 14.0551 - val_loss: 22.0607 - val_mse: 22.0607\n",
      "\n",
      "Epoch 00427: val_mse did not improve from 21.66517\n",
      "Epoch 428/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.8875 - mse: 14.8875 - val_loss: 21.8675 - val_mse: 21.8675\n",
      "\n",
      "Epoch 00428: val_mse did not improve from 21.66517\n",
      "Epoch 429/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.7168 - mse: 14.7168 - val_loss: 23.5557 - val_mse: 23.5557\n",
      "\n",
      "Epoch 00429: val_mse did not improve from 21.66517\n",
      "Epoch 430/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.9731 - mse: 13.9731 - val_loss: 23.4206 - val_mse: 23.4206\n",
      "\n",
      "Epoch 00430: val_mse did not improve from 21.66517\n",
      "Epoch 431/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.7162 - mse: 14.7162 - val_loss: 24.5570 - val_mse: 24.5570\n",
      "\n",
      "Epoch 00431: val_mse did not improve from 21.66517\n",
      "Epoch 432/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 16.0027 - mse: 16.0027 - val_loss: 25.1058 - val_mse: 25.1058\n",
      "\n",
      "Epoch 00432: val_mse did not improve from 21.66517\n",
      "Epoch 433/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.6743 - mse: 13.6743 - val_loss: 21.9169 - val_mse: 21.9169\n",
      "\n",
      "Epoch 00433: val_mse did not improve from 21.66517\n",
      "Epoch 434/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.5472 - mse: 12.5472 - val_loss: 22.4128 - val_mse: 22.4128\n",
      "\n",
      "Epoch 00434: val_mse did not improve from 21.66517\n",
      "Epoch 435/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.6336 - mse: 12.6336 - val_loss: 22.6589 - val_mse: 22.6589\n",
      "\n",
      "Epoch 00435: val_mse did not improve from 21.66517\n",
      "Epoch 436/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.4674 - mse: 12.4674 - val_loss: 21.3888 - val_mse: 21.3888\n",
      "\n",
      "Epoch 00436: val_mse improved from 21.66517 to 21.38884, saving model to ./model\\436-21.3888.hdf5\n",
      "Epoch 437/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 14.4589 - mse: 14.4589 - val_loss: 21.5446 - val_mse: 21.5446\n",
      "\n",
      "Epoch 00437: val_mse did not improve from 21.38884\n",
      "Epoch 438/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.8686 - mse: 12.8686 - val_loss: 21.7037 - val_mse: 21.7037\n",
      "\n",
      "Epoch 00438: val_mse did not improve from 21.38884\n",
      "Epoch 439/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.2790 - mse: 12.2790 - val_loss: 22.4776 - val_mse: 22.4776\n",
      "\n",
      "Epoch 00439: val_mse did not improve from 21.38884\n",
      "Epoch 440/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.3948 - mse: 12.3948 - val_loss: 20.8960 - val_mse: 20.8960\n",
      "\n",
      "Epoch 00440: val_mse improved from 21.38884 to 20.89597, saving model to ./model\\440-20.8960.hdf5\n",
      "Epoch 441/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.2793 - mse: 13.2793 - val_loss: 21.1131 - val_mse: 21.1131\n",
      "\n",
      "Epoch 00441: val_mse did not improve from 20.89597\n",
      "Epoch 442/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.7633 - mse: 12.7633 - val_loss: 20.4313 - val_mse: 20.4313\n",
      "\n",
      "Epoch 00442: val_mse improved from 20.89597 to 20.43130, saving model to ./model\\442-20.4313.hdf5\n",
      "Epoch 443/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.5028 - mse: 12.5028 - val_loss: 21.3649 - val_mse: 21.3649\n",
      "\n",
      "Epoch 00443: val_mse did not improve from 20.43130\n",
      "Epoch 444/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.2780 - mse: 13.2780 - val_loss: 24.1894 - val_mse: 24.1894\n",
      "\n",
      "Epoch 00444: val_mse did not improve from 20.43130\n",
      "Epoch 445/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.9739 - mse: 13.9739 - val_loss: 20.6775 - val_mse: 20.6775\n",
      "\n",
      "Epoch 00445: val_mse did not improve from 20.43130\n",
      "Epoch 446/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.6860 - mse: 12.6860 - val_loss: 23.2415 - val_mse: 23.2415\n",
      "\n",
      "Epoch 00446: val_mse did not improve from 20.43130\n",
      "Epoch 447/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.6107 - mse: 12.6107 - val_loss: 22.8809 - val_mse: 22.8809\n",
      "\n",
      "Epoch 00447: val_mse did not improve from 20.43130\n",
      "Epoch 448/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.9848 - mse: 13.9848 - val_loss: 21.9458 - val_mse: 21.9458\n",
      "\n",
      "Epoch 00448: val_mse did not improve from 20.43130\n",
      "Epoch 449/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.7189 - mse: 12.7189 - val_loss: 21.1622 - val_mse: 21.1622\n",
      "\n",
      "Epoch 00449: val_mse did not improve from 20.43130\n",
      "Epoch 450/5000\n",
      "8/8 [==============================] - ETA: 0s - loss: 10.9429 - mse: 10.942 - 0s 7ms/step - loss: 12.6754 - mse: 12.6754 - val_loss: 20.2382 - val_mse: 20.2382\n",
      "\n",
      "Epoch 00450: val_mse improved from 20.43130 to 20.23823, saving model to ./model\\450-20.2382.hdf5\n",
      "Epoch 451/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.7890 - mse: 12.7890 - val_loss: 21.3188 - val_mse: 21.3188\n",
      "\n",
      "Epoch 00451: val_mse did not improve from 20.23823\n",
      "Epoch 452/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.1239 - mse: 12.1239 - val_loss: 21.4371 - val_mse: 21.4371\n",
      "\n",
      "Epoch 00452: val_mse did not improve from 20.23823\n",
      "Epoch 453/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.9834 - mse: 12.9834 - val_loss: 24.2583 - val_mse: 24.2583\n",
      "\n",
      "Epoch 00453: val_mse did not improve from 20.23823\n",
      "Epoch 454/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.0322 - mse: 13.0322 - val_loss: 21.2656 - val_mse: 21.2656\n",
      "\n",
      "Epoch 00454: val_mse did not improve from 20.23823\n",
      "Epoch 455/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.5060 - mse: 12.5060 - val_loss: 23.0230 - val_mse: 23.0230\n",
      "\n",
      "Epoch 00455: val_mse did not improve from 20.23823\n",
      "Epoch 456/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 7ms/step - loss: 12.7555 - mse: 12.7555 - val_loss: 24.4379 - val_mse: 24.4379\n",
      "\n",
      "Epoch 00456: val_mse did not improve from 20.23823\n",
      "Epoch 457/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.9895 - mse: 12.9895 - val_loss: 22.4081 - val_mse: 22.4081\n",
      "\n",
      "Epoch 00457: val_mse did not improve from 20.23823\n",
      "Epoch 458/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.1708 - mse: 12.1708 - val_loss: 20.5859 - val_mse: 20.5859\n",
      "\n",
      "Epoch 00458: val_mse did not improve from 20.23823\n",
      "Epoch 459/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.2481 - mse: 12.2481 - val_loss: 20.1707 - val_mse: 20.1707\n",
      "\n",
      "Epoch 00459: val_mse improved from 20.23823 to 20.17067, saving model to ./model\\459-20.1707.hdf5\n",
      "Epoch 460/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.1184 - mse: 12.1184 - val_loss: 22.4787 - val_mse: 22.4787\n",
      "\n",
      "Epoch 00460: val_mse did not improve from 20.17067\n",
      "Epoch 461/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.3990 - mse: 12.3990 - val_loss: 21.0587 - val_mse: 21.0587\n",
      "\n",
      "Epoch 00461: val_mse did not improve from 20.17067\n",
      "Epoch 462/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.9435 - mse: 11.9435 - val_loss: 20.1928 - val_mse: 20.1928\n",
      "\n",
      "Epoch 00462: val_mse did not improve from 20.17067\n",
      "Epoch 463/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.9331 - mse: 11.9331 - val_loss: 20.9480 - val_mse: 20.9480\n",
      "\n",
      "Epoch 00463: val_mse did not improve from 20.17067\n",
      "Epoch 464/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.3208 - mse: 13.3208 - val_loss: 23.5776 - val_mse: 23.5776\n",
      "\n",
      "Epoch 00464: val_mse did not improve from 20.17067\n",
      "Epoch 465/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.6914 - mse: 13.6914 - val_loss: 22.2138 - val_mse: 22.2138\n",
      "\n",
      "Epoch 00465: val_mse did not improve from 20.17067\n",
      "Epoch 466/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.7928 - mse: 12.7928 - val_loss: 20.0985 - val_mse: 20.0985\n",
      "\n",
      "Epoch 00466: val_mse improved from 20.17067 to 20.09847, saving model to ./model\\466-20.0985.hdf5\n",
      "Epoch 467/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.2241 - mse: 12.2241 - val_loss: 20.5330 - val_mse: 20.5330\n",
      "\n",
      "Epoch 00467: val_mse did not improve from 20.09847\n",
      "Epoch 468/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.7579 - mse: 11.7579 - val_loss: 20.0034 - val_mse: 20.0034\n",
      "\n",
      "Epoch 00468: val_mse improved from 20.09847 to 20.00340, saving model to ./model\\468-20.0034.hdf5\n",
      "Epoch 469/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.0080 - mse: 12.0080 - val_loss: 21.3447 - val_mse: 21.3447\n",
      "\n",
      "Epoch 00469: val_mse did not improve from 20.00340\n",
      "Epoch 470/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.0015 - mse: 12.0015 - val_loss: 21.0337 - val_mse: 21.0337\n",
      "\n",
      "Epoch 00470: val_mse did not improve from 20.00340\n",
      "Epoch 471/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 13.6830 - mse: 13.6830 - val_loss: 19.8712 - val_mse: 19.8712\n",
      "\n",
      "Epoch 00471: val_mse improved from 20.00340 to 19.87121, saving model to ./model\\471-19.8712.hdf5\n",
      "Epoch 472/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 16.9971 - mse: 16.9971 - val_loss: 21.9447 - val_mse: 21.9447\n",
      "\n",
      "Epoch 00472: val_mse did not improve from 19.87121\n",
      "Epoch 473/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.6717 - mse: 13.6717 - val_loss: 26.8858 - val_mse: 26.8858\n",
      "\n",
      "Epoch 00473: val_mse did not improve from 19.87121\n",
      "Epoch 474/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.4693 - mse: 13.4693 - val_loss: 20.6728 - val_mse: 20.6728\n",
      "\n",
      "Epoch 00474: val_mse did not improve from 19.87121\n",
      "Epoch 475/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.8649 - mse: 11.8649 - val_loss: 20.3210 - val_mse: 20.3210\n",
      "\n",
      "Epoch 00475: val_mse did not improve from 19.87121\n",
      "Epoch 476/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.2576 - mse: 13.2576 - val_loss: 23.5058 - val_mse: 23.5058\n",
      "\n",
      "Epoch 00476: val_mse did not improve from 19.87121\n",
      "Epoch 477/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.2420 - mse: 13.2420 - val_loss: 21.0771 - val_mse: 21.0771\n",
      "\n",
      "Epoch 00477: val_mse did not improve from 19.87121\n",
      "Epoch 478/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.8921 - mse: 12.8921 - val_loss: 21.6214 - val_mse: 21.6214\n",
      "\n",
      "Epoch 00478: val_mse did not improve from 19.87121\n",
      "Epoch 479/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.9188 - mse: 12.9188 - val_loss: 19.5183 - val_mse: 19.5183\n",
      "\n",
      "Epoch 00479: val_mse improved from 19.87121 to 19.51834, saving model to ./model\\479-19.5183.hdf5\n",
      "Epoch 480/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.4326 - mse: 11.4326 - val_loss: 19.0996 - val_mse: 19.0996\n",
      "\n",
      "Epoch 00480: val_mse improved from 19.51834 to 19.09959, saving model to ./model\\480-19.0996.hdf5\n",
      "Epoch 481/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.5440 - mse: 11.5440 - val_loss: 20.3957 - val_mse: 20.3957\n",
      "\n",
      "Epoch 00481: val_mse did not improve from 19.09959\n",
      "Epoch 482/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.5721 - mse: 12.5721 - val_loss: 25.4072 - val_mse: 25.4072\n",
      "\n",
      "Epoch 00482: val_mse did not improve from 19.09959\n",
      "Epoch 483/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.5618 - mse: 12.5618 - val_loss: 20.1952 - val_mse: 20.1952\n",
      "\n",
      "Epoch 00483: val_mse did not improve from 19.09959\n",
      "Epoch 484/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.2633 - mse: 12.2633 - val_loss: 20.0385 - val_mse: 20.0385\n",
      "\n",
      "Epoch 00484: val_mse did not improve from 19.09959\n",
      "Epoch 485/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.8806 - mse: 11.8806 - val_loss: 19.6488 - val_mse: 19.6488\n",
      "\n",
      "Epoch 00485: val_mse did not improve from 19.09959\n",
      "Epoch 486/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 11.3694 - mse: 11.3694 - val_loss: 22.6522 - val_mse: 22.6522\n",
      "\n",
      "Epoch 00486: val_mse did not improve from 19.09959\n",
      "Epoch 487/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11.6848 - mse: 11.6848 - val_loss: 19.3626 - val_mse: 19.3626\n",
      "\n",
      "Epoch 00487: val_mse did not improve from 19.09959\n",
      "Epoch 488/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 11.9708 - mse: 11.9708 - val_loss: 19.9907 - val_mse: 19.9907\n",
      "\n",
      "Epoch 00488: val_mse did not improve from 19.09959\n",
      "Epoch 489/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 12.9914 - mse: 12.9914 - val_loss: 19.2074 - val_mse: 19.2074\n",
      "\n",
      "Epoch 00489: val_mse did not improve from 19.09959\n",
      "Epoch 490/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 12.0354 - mse: 12.0354 - val_loss: 19.4411 - val_mse: 19.4411\n",
      "\n",
      "Epoch 00490: val_mse did not improve from 19.09959\n",
      "Epoch 491/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.8886 - mse: 10.8886 - val_loss: 20.7583 - val_mse: 20.7583\n",
      "\n",
      "Epoch 00491: val_mse did not improve from 19.09959\n",
      "Epoch 492/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.8890 - mse: 11.8890 - val_loss: 22.8141 - val_mse: 22.8141\n",
      "\n",
      "Epoch 00492: val_mse did not improve from 19.09959\n",
      "Epoch 493/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.1415 - mse: 13.1415 - val_loss: 19.9398 - val_mse: 19.9398\n",
      "\n",
      "Epoch 00493: val_mse did not improve from 19.09959\n",
      "Epoch 494/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 12.2247 - mse: 12.2247 - val_loss: 22.1254 - val_mse: 22.1254\n",
      "\n",
      "Epoch 00494: val_mse did not improve from 19.09959\n",
      "Epoch 495/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 13.2864 - mse: 13.2864 - val_loss: 19.4696 - val_mse: 19.4696\n",
      "\n",
      "Epoch 00495: val_mse did not improve from 19.09959\n",
      "Epoch 496/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 11.8658 - mse: 11.8658 - val_loss: 19.7282 - val_mse: 19.7282\n",
      "\n",
      "Epoch 00496: val_mse did not improve from 19.09959\n",
      "Epoch 497/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11.2832 - mse: 11.2832 - val_loss: 18.9444 - val_mse: 18.9444\n",
      "\n",
      "Epoch 00497: val_mse improved from 19.09959 to 18.94436, saving model to ./model\\497-18.9444.hdf5\n",
      "Epoch 498/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 11.3683 - mse: 11.3683 - val_loss: 19.6409 - val_mse: 19.6409\n",
      "\n",
      "Epoch 00498: val_mse did not improve from 18.94436\n",
      "Epoch 499/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.4445 - mse: 11.4445 - val_loss: 19.8957 - val_mse: 19.8957\n",
      "\n",
      "Epoch 00499: val_mse did not improve from 18.94436\n",
      "Epoch 500/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.1550 - mse: 11.1550 - val_loss: 19.2190 - val_mse: 19.2190\n",
      "\n",
      "Epoch 00500: val_mse did not improve from 18.94436\n",
      "Epoch 501/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.7801 - mse: 12.7801 - val_loss: 20.2359 - val_mse: 20.2359\n",
      "\n",
      "Epoch 00501: val_mse did not improve from 18.94436\n",
      "Epoch 502/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.2424 - mse: 11.2424 - val_loss: 19.1001 - val_mse: 19.1001\n",
      "\n",
      "Epoch 00502: val_mse did not improve from 18.94436\n",
      "Epoch 503/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.3197 - mse: 11.3197 - val_loss: 18.8015 - val_mse: 18.8015\n",
      "\n",
      "Epoch 00503: val_mse improved from 18.94436 to 18.80146, saving model to ./model\\503-18.8015.hdf5\n",
      "Epoch 504/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.4229 - mse: 12.4229 - val_loss: 18.4248 - val_mse: 18.4248\n",
      "\n",
      "Epoch 00504: val_mse improved from 18.80146 to 18.42476, saving model to ./model\\504-18.4248.hdf5\n",
      "Epoch 505/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.1503 - mse: 12.1503 - val_loss: 20.7452 - val_mse: 20.7452\n",
      "\n",
      "Epoch 00505: val_mse did not improve from 18.42476\n",
      "Epoch 506/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11.9083 - mse: 11.9083 - val_loss: 24.1881 - val_mse: 24.1881\n",
      "\n",
      "Epoch 00506: val_mse did not improve from 18.42476\n",
      "Epoch 507/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.6200 - mse: 14.6200 - val_loss: 21.0049 - val_mse: 21.0049\n",
      "\n",
      "Epoch 00507: val_mse did not improve from 18.42476\n",
      "Epoch 508/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.8377 - mse: 11.8377 - val_loss: 18.9146 - val_mse: 18.9146\n",
      "\n",
      "Epoch 00508: val_mse did not improve from 18.42476\n",
      "Epoch 509/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.7943 - mse: 11.7943 - val_loss: 18.7150 - val_mse: 18.7150\n",
      "\n",
      "Epoch 00509: val_mse did not improve from 18.42476\n",
      "Epoch 510/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.1824 - mse: 11.1824 - val_loss: 18.3502 - val_mse: 18.3502\n",
      "\n",
      "Epoch 00510: val_mse improved from 18.42476 to 18.35016, saving model to ./model\\510-18.3502.hdf5\n",
      "Epoch 511/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.2946 - mse: 11.2946 - val_loss: 19.3399 - val_mse: 19.3399\n",
      "\n",
      "Epoch 00511: val_mse did not improve from 18.35016\n",
      "Epoch 512/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.3734 - mse: 11.3734 - val_loss: 19.3042 - val_mse: 19.3042\n",
      "\n",
      "Epoch 00512: val_mse did not improve from 18.35016\n",
      "Epoch 513/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 12.2531 - mse: 12.2531 - val_loss: 21.0749 - val_mse: 21.0749\n",
      "\n",
      "Epoch 00513: val_mse did not improve from 18.35016\n",
      "Epoch 514/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.4997 - mse: 14.4997 - val_loss: 19.0604 - val_mse: 19.0604\n",
      "\n",
      "Epoch 00514: val_mse did not improve from 18.35016\n",
      "Epoch 515/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.0709 - mse: 12.0709 - val_loss: 19.8443 - val_mse: 19.8443\n",
      "\n",
      "Epoch 00515: val_mse did not improve from 18.35016\n",
      "Epoch 516/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.3295 - mse: 11.3295 - val_loss: 19.0812 - val_mse: 19.0812\n",
      "\n",
      "Epoch 00516: val_mse did not improve from 18.35016\n",
      "Epoch 517/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 10.6949 - mse: 10.6949 - val_loss: 17.9204 - val_mse: 17.9204\n",
      "\n",
      "Epoch 00517: val_mse improved from 18.35016 to 17.92035, saving model to ./model\\517-17.9204.hdf5\n",
      "Epoch 518/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.5010 - mse: 10.5010 - val_loss: 18.5097 - val_mse: 18.5097\n",
      "\n",
      "Epoch 00518: val_mse did not improve from 17.92035\n",
      "Epoch 519/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.6290 - mse: 10.6290 - val_loss: 18.1996 - val_mse: 18.1996\n",
      "\n",
      "Epoch 00519: val_mse did not improve from 17.92035\n",
      "Epoch 520/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11.0246 - mse: 11.0246 - val_loss: 19.1539 - val_mse: 19.1539\n",
      "\n",
      "Epoch 00520: val_mse did not improve from 17.92035\n",
      "Epoch 521/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.7905 - mse: 10.7905 - val_loss: 18.6023 - val_mse: 18.6023\n",
      "\n",
      "Epoch 00521: val_mse did not improve from 17.92035\n",
      "Epoch 522/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.5276 - mse: 10.5276 - val_loss: 19.4425 - val_mse: 19.4425\n",
      "\n",
      "Epoch 00522: val_mse did not improve from 17.92035\n",
      "Epoch 523/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.3900 - mse: 11.3900 - val_loss: 18.3582 - val_mse: 18.3582\n",
      "\n",
      "Epoch 00523: val_mse did not improve from 17.92035\n",
      "Epoch 524/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.6085 - mse: 10.6085 - val_loss: 17.3898 - val_mse: 17.3898\n",
      "\n",
      "Epoch 00524: val_mse improved from 17.92035 to 17.38979, saving model to ./model\\524-17.3898.hdf5\n",
      "Epoch 525/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.6175 - mse: 11.6175 - val_loss: 18.7745 - val_mse: 18.7745\n",
      "\n",
      "Epoch 00525: val_mse did not improve from 17.38979\n",
      "Epoch 526/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11.2143 - mse: 11.2143 - val_loss: 17.8618 - val_mse: 17.8618\n",
      "\n",
      "Epoch 00526: val_mse did not improve from 17.38979\n",
      "Epoch 527/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.5772 - mse: 10.5772 - val_loss: 20.6180 - val_mse: 20.6180\n",
      "\n",
      "Epoch 00527: val_mse did not improve from 17.38979\n",
      "Epoch 528/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 10.9621 - mse: 10.9621 - val_loss: 18.1090 - val_mse: 18.1090\n",
      "\n",
      "Epoch 00528: val_mse did not improve from 17.38979\n",
      "Epoch 529/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 10.9651 - mse: 10.9651 - val_loss: 18.2698 - val_mse: 18.2698\n",
      "\n",
      "Epoch 00529: val_mse did not improve from 17.38979\n",
      "Epoch 530/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 10.1542 - mse: 10.1542 - val_loss: 18.2357 - val_mse: 18.2357\n",
      "\n",
      "Epoch 00530: val_mse did not improve from 17.38979\n",
      "Epoch 531/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.5215 - mse: 10.5215 - val_loss: 17.6190 - val_mse: 17.6190\n",
      "\n",
      "Epoch 00531: val_mse did not improve from 17.38979\n",
      "Epoch 532/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.9224 - mse: 10.9224 - val_loss: 21.0279 - val_mse: 21.0279\n",
      "\n",
      "Epoch 00532: val_mse did not improve from 17.38979\n",
      "Epoch 533/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.0739 - mse: 11.0739 - val_loss: 17.5506 - val_mse: 17.5506\n",
      "\n",
      "Epoch 00533: val_mse did not improve from 17.38979\n",
      "Epoch 534/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.9771 - mse: 10.9771 - val_loss: 19.6305 - val_mse: 19.6305\n",
      "\n",
      "Epoch 00534: val_mse did not improve from 17.38979\n",
      "Epoch 535/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.6207 - mse: 10.6207 - val_loss: 20.1709 - val_mse: 20.1709\n",
      "\n",
      "Epoch 00535: val_mse did not improve from 17.38979\n",
      "Epoch 536/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.9589 - mse: 10.9589 - val_loss: 17.4986 - val_mse: 17.4986\n",
      "\n",
      "Epoch 00536: val_mse did not improve from 17.38979\n",
      "Epoch 537/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.4104 - mse: 10.4104 - val_loss: 17.5990 - val_mse: 17.5990\n",
      "\n",
      "Epoch 00537: val_mse did not improve from 17.38979\n",
      "Epoch 538/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.6876 - mse: 10.6876 - val_loss: 18.5744 - val_mse: 18.5744\n",
      "\n",
      "Epoch 00538: val_mse did not improve from 17.38979\n",
      "Epoch 539/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.0669 - mse: 11.0669 - val_loss: 18.0889 - val_mse: 18.0889\n",
      "\n",
      "Epoch 00539: val_mse did not improve from 17.38979\n",
      "Epoch 540/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 10.5994 - mse: 10.5994 - val_loss: 19.6673 - val_mse: 19.6673\n",
      "\n",
      "Epoch 00540: val_mse did not improve from 17.38979\n",
      "Epoch 541/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.6427 - mse: 10.6427 - val_loss: 19.8348 - val_mse: 19.8348\n",
      "\n",
      "Epoch 00541: val_mse did not improve from 17.38979\n",
      "Epoch 542/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.2327 - mse: 11.2327 - val_loss: 20.2674 - val_mse: 20.2674\n",
      "\n",
      "Epoch 00542: val_mse did not improve from 17.38979\n",
      "Epoch 543/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.9969 - mse: 11.9969 - val_loss: 18.1959 - val_mse: 18.1959\n",
      "\n",
      "Epoch 00543: val_mse did not improve from 17.38979\n",
      "Epoch 544/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.5479 - mse: 10.5479 - val_loss: 17.3596 - val_mse: 17.3596\n",
      "\n",
      "Epoch 00544: val_mse improved from 17.38979 to 17.35956, saving model to ./model\\544-17.3596.hdf5\n",
      "Epoch 545/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.1257 - mse: 11.1257 - val_loss: 17.9907 - val_mse: 17.9907\n",
      "\n",
      "Epoch 00545: val_mse did not improve from 17.35956\n",
      "Epoch 546/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.3420 - mse: 10.3420 - val_loss: 17.4888 - val_mse: 17.4888\n",
      "\n",
      "Epoch 00546: val_mse did not improve from 17.35956\n",
      "Epoch 547/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.5672 - mse: 10.5672 - val_loss: 18.5104 - val_mse: 18.5104\n",
      "\n",
      "Epoch 00547: val_mse did not improve from 17.35956\n",
      "Epoch 548/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.2697 - mse: 10.2697 - val_loss: 16.9309 - val_mse: 16.9309\n",
      "\n",
      "Epoch 00548: val_mse improved from 17.35956 to 16.93091, saving model to ./model\\548-16.9309.hdf5\n",
      "Epoch 549/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.8741 - mse: 11.8741 - val_loss: 17.6123 - val_mse: 17.6123\n",
      "\n",
      "Epoch 00549: val_mse did not improve from 16.93091\n",
      "Epoch 550/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.0776 - mse: 10.0776 - val_loss: 17.2037 - val_mse: 17.2037\n",
      "\n",
      "Epoch 00550: val_mse did not improve from 16.93091\n",
      "Epoch 551/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.0997 - mse: 10.0997 - val_loss: 16.7085 - val_mse: 16.7085\n",
      "\n",
      "Epoch 00551: val_mse improved from 16.93091 to 16.70848, saving model to ./model\\551-16.7085.hdf5\n",
      "Epoch 552/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.6892 - mse: 10.6892 - val_loss: 19.7744 - val_mse: 19.7744\n",
      "\n",
      "Epoch 00552: val_mse did not improve from 16.70848\n",
      "Epoch 553/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.9140 - mse: 11.9140 - val_loss: 20.4522 - val_mse: 20.4522\n",
      "\n",
      "Epoch 00553: val_mse did not improve from 16.70848\n",
      "Epoch 554/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 13.4118 - mse: 13.4118 - val_loss: 18.7887 - val_mse: 18.7887\n",
      "\n",
      "Epoch 00554: val_mse did not improve from 16.70848\n",
      "Epoch 555/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.1693 - mse: 11.1693 - val_loss: 17.7845 - val_mse: 17.7845\n",
      "\n",
      "Epoch 00555: val_mse did not improve from 16.70848\n",
      "Epoch 556/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.2445 - mse: 10.2445 - val_loss: 16.7676 - val_mse: 16.7676\n",
      "\n",
      "Epoch 00556: val_mse did not improve from 16.70848\n",
      "Epoch 557/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.3546 - mse: 10.3546 - val_loss: 16.5639 - val_mse: 16.5639\n",
      "\n",
      "Epoch 00557: val_mse improved from 16.70848 to 16.56389, saving model to ./model\\557-16.5639.hdf5\n",
      "Epoch 558/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.2332 - mse: 10.2332 - val_loss: 17.4256 - val_mse: 17.4256\n",
      "\n",
      "Epoch 00558: val_mse did not improve from 16.56389\n",
      "Epoch 559/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.8709 - mse: 9.8709 - val_loss: 17.4504 - val_mse: 17.4504\n",
      "\n",
      "Epoch 00559: val_mse did not improve from 16.56389\n",
      "Epoch 560/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.9594 - mse: 10.9594 - val_loss: 18.1137 - val_mse: 18.1137\n",
      "\n",
      "Epoch 00560: val_mse did not improve from 16.56389\n",
      "Epoch 561/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.1200 - mse: 12.1200 - val_loss: 17.2088 - val_mse: 17.2088\n",
      "\n",
      "Epoch 00561: val_mse did not improve from 16.56389\n",
      "Epoch 562/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.6420 - mse: 10.6420 - val_loss: 17.1277 - val_mse: 17.1277\n",
      "\n",
      "Epoch 00562: val_mse did not improve from 16.56389\n",
      "Epoch 563/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.1614 - mse: 10.1614 - val_loss: 18.4423 - val_mse: 18.4423\n",
      "\n",
      "Epoch 00563: val_mse did not improve from 16.56389\n",
      "Epoch 564/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 12.4823 - mse: 12.4823 - val_loss: 25.2518 - val_mse: 25.2518\n",
      "\n",
      "Epoch 00564: val_mse did not improve from 16.56389\n",
      "Epoch 565/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 14.2657 - mse: 14.2657 - val_loss: 20.2961 - val_mse: 20.2961\n",
      "\n",
      "Epoch 00565: val_mse did not improve from 16.56389\n",
      "Epoch 566/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.9784 - mse: 10.9784 - val_loss: 17.5477 - val_mse: 17.5477\n",
      "\n",
      "Epoch 00566: val_mse did not improve from 16.56389\n",
      "Epoch 567/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.2259 - mse: 10.2259 - val_loss: 17.7976 - val_mse: 17.7976\n",
      "\n",
      "Epoch 00567: val_mse did not improve from 16.56389\n",
      "Epoch 568/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.2240 - mse: 10.2240 - val_loss: 17.2628 - val_mse: 17.2628\n",
      "\n",
      "Epoch 00568: val_mse did not improve from 16.56389\n",
      "Epoch 569/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 10.6632 - mse: 10.6632 - val_loss: 18.0680 - val_mse: 18.0680\n",
      "\n",
      "Epoch 00569: val_mse did not improve from 16.56389\n",
      "Epoch 570/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.9898 - mse: 10.9898 - val_loss: 18.7572 - val_mse: 18.7572\n",
      "\n",
      "Epoch 00570: val_mse did not improve from 16.56389\n",
      "Epoch 571/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.5495 - mse: 10.5495 - val_loss: 17.8976 - val_mse: 17.8976\n",
      "\n",
      "Epoch 00571: val_mse did not improve from 16.56389\n",
      "Epoch 572/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.2415 - mse: 10.2415 - val_loss: 20.1745 - val_mse: 20.1745\n",
      "\n",
      "Epoch 00572: val_mse did not improve from 16.56389\n",
      "Epoch 573/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.0934 - mse: 10.0934 - val_loss: 18.2652 - val_mse: 18.2652\n",
      "\n",
      "Epoch 00573: val_mse did not improve from 16.56389\n",
      "Epoch 574/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7245 - mse: 9.7245 - val_loss: 17.0326 - val_mse: 17.0326\n",
      "\n",
      "Epoch 00574: val_mse did not improve from 16.56389\n",
      "Epoch 575/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.6741 - mse: 9.6741 - val_loss: 17.0606 - val_mse: 17.0606\n",
      "\n",
      "Epoch 00575: val_mse did not improve from 16.56389\n",
      "Epoch 576/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 11.0382 - mse: 11.0382 - val_loss: 22.2504 - val_mse: 22.2504\n",
      "\n",
      "Epoch 00576: val_mse did not improve from 16.56389\n",
      "Epoch 577/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.8470 - mse: 11.8470 - val_loss: 19.9473 - val_mse: 19.9473\n",
      "\n",
      "Epoch 00577: val_mse did not improve from 16.56389\n",
      "Epoch 578/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 13.6600 - mse: 13.6600 - val_loss: 22.1296 - val_mse: 22.1296\n",
      "\n",
      "Epoch 00578: val_mse did not improve from 16.56389\n",
      "Epoch 579/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 12.3058 - mse: 12.3058 - val_loss: 18.8022 - val_mse: 18.8022\n",
      "\n",
      "Epoch 00579: val_mse did not improve from 16.56389\n",
      "Epoch 580/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.5541 - mse: 9.5541 - val_loss: 19.4035 - val_mse: 19.4035\n",
      "\n",
      "Epoch 00580: val_mse did not improve from 16.56389\n",
      "Epoch 581/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 11.3699 - mse: 11.3699 - val_loss: 19.0151 - val_mse: 19.0151\n",
      "\n",
      "Epoch 00581: val_mse did not improve from 16.56389\n",
      "Epoch 582/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 10.4031 - mse: 10.4031 - val_loss: 17.2244 - val_mse: 17.2244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00582: val_mse did not improve from 16.56389\n",
      "Epoch 583/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.9310 - mse: 9.9310 - val_loss: 18.2519 - val_mse: 18.2519\n",
      "\n",
      "Epoch 00583: val_mse did not improve from 16.56389\n",
      "Epoch 584/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.8737 - mse: 10.8737 - val_loss: 22.8245 - val_mse: 22.8245\n",
      "\n",
      "Epoch 00584: val_mse did not improve from 16.56389\n",
      "Epoch 585/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.5961 - mse: 12.5961 - val_loss: 21.2530 - val_mse: 21.2530\n",
      "\n",
      "Epoch 00585: val_mse did not improve from 16.56389\n",
      "Epoch 586/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 13.6109 - mse: 13.6109 - val_loss: 18.9007 - val_mse: 18.9007\n",
      "\n",
      "Epoch 00586: val_mse did not improve from 16.56389\n",
      "Epoch 587/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.1694 - mse: 10.1694 - val_loss: 17.8018 - val_mse: 17.8018\n",
      "\n",
      "Epoch 00587: val_mse did not improve from 16.56389\n",
      "Epoch 588/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.5482 - mse: 9.5482 - val_loss: 19.0483 - val_mse: 19.0483\n",
      "\n",
      "Epoch 00588: val_mse did not improve from 16.56389\n",
      "Epoch 589/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 12.1326 - mse: 12.1326 - val_loss: 19.0578 - val_mse: 19.0578\n",
      "\n",
      "Epoch 00589: val_mse did not improve from 16.56389\n",
      "Epoch 590/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.0424 - mse: 10.0424 - val_loss: 18.7135 - val_mse: 18.7135\n",
      "\n",
      "Epoch 00590: val_mse did not improve from 16.56389\n",
      "Epoch 591/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.4566 - mse: 9.4566 - val_loss: 16.8686 - val_mse: 16.8686\n",
      "\n",
      "Epoch 00591: val_mse did not improve from 16.56389\n",
      "Epoch 592/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.6378 - mse: 9.6378 - val_loss: 17.6145 - val_mse: 17.6145\n",
      "\n",
      "Epoch 00592: val_mse did not improve from 16.56389\n",
      "Epoch 593/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.2177 - mse: 9.2177 - val_loss: 17.3364 - val_mse: 17.3364\n",
      "\n",
      "Epoch 00593: val_mse did not improve from 16.56389\n",
      "Epoch 594/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.4204 - mse: 10.4204 - val_loss: 18.6414 - val_mse: 18.6414\n",
      "\n",
      "Epoch 00594: val_mse did not improve from 16.56389\n",
      "Epoch 595/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.4294 - mse: 10.4294 - val_loss: 16.5210 - val_mse: 16.5210\n",
      "\n",
      "Epoch 00595: val_mse improved from 16.56389 to 16.52098, saving model to ./model\\595-16.5210.hdf5\n",
      "Epoch 596/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.4167 - mse: 9.4167 - val_loss: 16.6552 - val_mse: 16.6552\n",
      "\n",
      "Epoch 00596: val_mse did not improve from 16.52098\n",
      "Epoch 597/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.2181 - mse: 11.2181 - val_loss: 16.1055 - val_mse: 16.1055\n",
      "\n",
      "Epoch 00597: val_mse improved from 16.52098 to 16.10552, saving model to ./model\\597-16.1055.hdf5\n",
      "Epoch 598/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.3092 - mse: 11.3092 - val_loss: 18.2628 - val_mse: 18.2628\n",
      "\n",
      "Epoch 00598: val_mse did not improve from 16.10552\n",
      "Epoch 599/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.9887 - mse: 10.9887 - val_loss: 16.9017 - val_mse: 16.9017\n",
      "\n",
      "Epoch 00599: val_mse did not improve from 16.10552\n",
      "Epoch 600/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.7528 - mse: 10.7528 - val_loss: 17.2438 - val_mse: 17.2438\n",
      "\n",
      "Epoch 00600: val_mse did not improve from 16.10552\n",
      "Epoch 601/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.8553 - mse: 10.8553 - val_loss: 16.3974 - val_mse: 16.3974\n",
      "\n",
      "Epoch 00601: val_mse did not improve from 16.10552\n",
      "Epoch 602/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.3672 - mse: 9.3672 - val_loss: 16.8706 - val_mse: 16.8706\n",
      "\n",
      "Epoch 00602: val_mse did not improve from 16.10552\n",
      "Epoch 603/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.6406 - mse: 9.6406 - val_loss: 16.0500 - val_mse: 16.0500\n",
      "\n",
      "Epoch 00603: val_mse improved from 16.10552 to 16.05000, saving model to ./model\\603-16.0500.hdf5\n",
      "Epoch 604/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.4689 - mse: 10.4689 - val_loss: 16.5735 - val_mse: 16.5735\n",
      "\n",
      "Epoch 00604: val_mse did not improve from 16.05000\n",
      "Epoch 605/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.4825 - mse: 10.4825 - val_loss: 18.8336 - val_mse: 18.8336\n",
      "\n",
      "Epoch 00605: val_mse did not improve from 16.05000\n",
      "Epoch 606/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.8070 - mse: 10.8070 - val_loss: 17.2755 - val_mse: 17.2755\n",
      "\n",
      "Epoch 00606: val_mse did not improve from 16.05000\n",
      "Epoch 607/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.4461 - mse: 9.4461 - val_loss: 20.1552 - val_mse: 20.1552\n",
      "\n",
      "Epoch 00607: val_mse did not improve from 16.05000\n",
      "Epoch 608/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 11.3955 - mse: 11.3955 - val_loss: 19.8764 - val_mse: 19.8764\n",
      "\n",
      "Epoch 00608: val_mse did not improve from 16.05000\n",
      "Epoch 609/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.5863 - mse: 9.5863 - val_loss: 16.3409 - val_mse: 16.3409\n",
      "\n",
      "Epoch 00609: val_mse did not improve from 16.05000\n",
      "Epoch 610/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.9985 - mse: 10.9985 - val_loss: 16.3285 - val_mse: 16.3285\n",
      "\n",
      "Epoch 00610: val_mse did not improve from 16.05000\n",
      "Epoch 611/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.1504 - mse: 11.1504 - val_loss: 16.5872 - val_mse: 16.5872\n",
      "\n",
      "Epoch 00611: val_mse did not improve from 16.05000\n",
      "Epoch 612/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.3920 - mse: 9.3920 - val_loss: 15.7191 - val_mse: 15.7191\n",
      "\n",
      "Epoch 00612: val_mse improved from 16.05000 to 15.71905, saving model to ./model\\612-15.7191.hdf5\n",
      "Epoch 613/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.5932 - mse: 9.5932 - val_loss: 16.2538 - val_mse: 16.2538\n",
      "\n",
      "Epoch 00613: val_mse did not improve from 15.71905\n",
      "Epoch 614/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.2471 - mse: 9.2471 - val_loss: 16.0240 - val_mse: 16.0240\n",
      "\n",
      "Epoch 00614: val_mse did not improve from 15.71905\n",
      "Epoch 615/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.7743 - mse: 9.7743 - val_loss: 17.9163 - val_mse: 17.9163\n",
      "\n",
      "Epoch 00615: val_mse did not improve from 15.71905\n",
      "Epoch 616/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7632 - mse: 9.7632 - val_loss: 18.4129 - val_mse: 18.4129\n",
      "\n",
      "Epoch 00616: val_mse did not improve from 15.71905\n",
      "Epoch 617/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.1184 - mse: 10.1184 - val_loss: 17.5596 - val_mse: 17.5596\n",
      "\n",
      "Epoch 00617: val_mse did not improve from 15.71905\n",
      "Epoch 618/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9759 - mse: 9.9759 - val_loss: 16.3503 - val_mse: 16.3503\n",
      "\n",
      "Epoch 00618: val_mse did not improve from 15.71905\n",
      "Epoch 619/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.3286 - mse: 11.3286 - val_loss: 17.9389 - val_mse: 17.9389\n",
      "\n",
      "Epoch 00619: val_mse did not improve from 15.71905\n",
      "Epoch 620/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.3177 - mse: 10.3177 - val_loss: 15.9458 - val_mse: 15.9458\n",
      "\n",
      "Epoch 00620: val_mse did not improve from 15.71905\n",
      "Epoch 621/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7377 - mse: 9.7377 - val_loss: 16.0430 - val_mse: 16.0430\n",
      "\n",
      "Epoch 00621: val_mse did not improve from 15.71905\n",
      "Epoch 622/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.7854 - mse: 9.7854 - val_loss: 17.7461 - val_mse: 17.7461\n",
      "\n",
      "Epoch 00622: val_mse did not improve from 15.71905\n",
      "Epoch 623/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.3901 - mse: 9.3901 - val_loss: 16.9193 - val_mse: 16.9193\n",
      "\n",
      "Epoch 00623: val_mse did not improve from 15.71905\n",
      "Epoch 624/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.6703 - mse: 9.6703 - val_loss: 16.3538 - val_mse: 16.3538\n",
      "\n",
      "Epoch 00624: val_mse did not improve from 15.71905\n",
      "Epoch 625/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.4056 - mse: 9.4056 - val_loss: 16.3461 - val_mse: 16.3461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00625: val_mse did not improve from 15.71905\n",
      "Epoch 626/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.2928 - mse: 9.2928 - val_loss: 15.2866 - val_mse: 15.2866\n",
      "\n",
      "Epoch 00626: val_mse improved from 15.71905 to 15.28658, saving model to ./model\\626-15.2866.hdf5\n",
      "Epoch 627/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.6209 - mse: 8.6209 - val_loss: 15.7838 - val_mse: 15.7838\n",
      "\n",
      "Epoch 00627: val_mse did not improve from 15.28658\n",
      "Epoch 628/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.5227 - mse: 8.5227 - val_loss: 16.2244 - val_mse: 16.2244\n",
      "\n",
      "Epoch 00628: val_mse did not improve from 15.28658\n",
      "Epoch 629/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.1337 - mse: 9.1337 - val_loss: 15.8592 - val_mse: 15.8592\n",
      "\n",
      "Epoch 00629: val_mse did not improve from 15.28658\n",
      "Epoch 630/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.3207 - mse: 9.3207 - val_loss: 16.5792 - val_mse: 16.5792\n",
      "\n",
      "Epoch 00630: val_mse did not improve from 15.28658\n",
      "Epoch 631/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.8941 - mse: 9.8941 - val_loss: 16.5055 - val_mse: 16.5055\n",
      "\n",
      "Epoch 00631: val_mse did not improve from 15.28658\n",
      "Epoch 632/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7315 - mse: 9.7315 - val_loss: 15.7144 - val_mse: 15.7144\n",
      "\n",
      "Epoch 00632: val_mse did not improve from 15.28658\n",
      "Epoch 633/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.9072 - mse: 8.9072 - val_loss: 17.3030 - val_mse: 17.3030\n",
      "\n",
      "Epoch 00633: val_mse did not improve from 15.28658\n",
      "Epoch 634/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.0812 - mse: 9.0812 - val_loss: 17.1176 - val_mse: 17.1176\n",
      "\n",
      "Epoch 00634: val_mse did not improve from 15.28658\n",
      "Epoch 635/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.7114 - mse: 8.7114 - val_loss: 15.1841 - val_mse: 15.1841\n",
      "\n",
      "Epoch 00635: val_mse improved from 15.28658 to 15.18413, saving model to ./model\\635-15.1841.hdf5\n",
      "Epoch 636/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.3239 - mse: 9.3239 - val_loss: 15.6565 - val_mse: 15.6565\n",
      "\n",
      "Epoch 00636: val_mse did not improve from 15.18413\n",
      "Epoch 637/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.4037 - mse: 9.4037 - val_loss: 15.5368 - val_mse: 15.5368\n",
      "\n",
      "Epoch 00637: val_mse did not improve from 15.18413\n",
      "Epoch 638/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.5842 - mse: 9.5842 - val_loss: 14.9961 - val_mse: 14.9961\n",
      "\n",
      "Epoch 00638: val_mse improved from 15.18413 to 14.99607, saving model to ./model\\638-14.9961.hdf5\n",
      "Epoch 639/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.4706 - mse: 10.4706 - val_loss: 15.7934 - val_mse: 15.7934\n",
      "\n",
      "Epoch 00639: val_mse did not improve from 14.99607\n",
      "Epoch 640/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.5755 - mse: 10.5755 - val_loss: 14.9938 - val_mse: 14.9938\n",
      "\n",
      "Epoch 00640: val_mse improved from 14.99607 to 14.99383, saving model to ./model\\640-14.9938.hdf5\n",
      "Epoch 641/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.8637 - mse: 9.8637 - val_loss: 15.7252 - val_mse: 15.7252\n",
      "\n",
      "Epoch 00641: val_mse did not improve from 14.99383\n",
      "Epoch 642/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.6034 - mse: 9.6034 - val_loss: 14.8844 - val_mse: 14.8844\n",
      "\n",
      "Epoch 00642: val_mse improved from 14.99383 to 14.88443, saving model to ./model\\642-14.8844.hdf5\n",
      "Epoch 643/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.3162 - mse: 8.3162 - val_loss: 15.3792 - val_mse: 15.3792\n",
      "\n",
      "Epoch 00643: val_mse did not improve from 14.88443\n",
      "Epoch 644/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 8.5570 - mse: 8.5570 - val_loss: 15.0983 - val_mse: 15.0983\n",
      "\n",
      "Epoch 00644: val_mse did not improve from 14.88443\n",
      "Epoch 645/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.5117 - mse: 8.5117 - val_loss: 14.6788 - val_mse: 14.6788\n",
      "\n",
      "Epoch 00645: val_mse improved from 14.88443 to 14.67883, saving model to ./model\\645-14.6788.hdf5\n",
      "Epoch 646/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.6283 - mse: 8.6283 - val_loss: 16.0270 - val_mse: 16.0270\n",
      "\n",
      "Epoch 00646: val_mse did not improve from 14.67883\n",
      "Epoch 647/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.7221 - mse: 9.7221 - val_loss: 15.3319 - val_mse: 15.3319\n",
      "\n",
      "Epoch 00647: val_mse did not improve from 14.67883\n",
      "Epoch 648/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.5557 - mse: 8.5557 - val_loss: 16.9560 - val_mse: 16.9560\n",
      "\n",
      "Epoch 00648: val_mse did not improve from 14.67883\n",
      "Epoch 649/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.6248 - mse: 9.6248 - val_loss: 20.0087 - val_mse: 20.0087\n",
      "\n",
      "Epoch 00649: val_mse did not improve from 14.67883\n",
      "Epoch 650/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.6776 - mse: 10.6776 - val_loss: 16.0133 - val_mse: 16.0133\n",
      "\n",
      "Epoch 00650: val_mse did not improve from 14.67883\n",
      "Epoch 651/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.6809 - mse: 10.6809 - val_loss: 16.6796 - val_mse: 16.6796\n",
      "\n",
      "Epoch 00651: val_mse did not improve from 14.67883\n",
      "Epoch 652/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.9698 - mse: 9.9698 - val_loss: 14.2482 - val_mse: 14.2482\n",
      "\n",
      "Epoch 00652: val_mse improved from 14.67883 to 14.24815, saving model to ./model\\652-14.2482.hdf5\n",
      "Epoch 653/5000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 8.6954 - mse: 8.6954 - val_loss: 15.3116 - val_mse: 15.3116\n",
      "\n",
      "Epoch 00653: val_mse did not improve from 14.24815\n",
      "Epoch 654/5000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.1267 - mse: 9.1267 - val_loss: 16.1769 - val_mse: 16.1769\n",
      "\n",
      "Epoch 00654: val_mse did not improve from 14.24815\n",
      "Epoch 655/5000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 9.8495 - mse: 9.8495 - val_loss: 15.9036 - val_mse: 15.9036\n",
      "\n",
      "Epoch 00655: val_mse did not improve from 14.24815\n",
      "Epoch 656/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.2758 - mse: 9.2758 - val_loss: 18.1058 - val_mse: 18.1058\n",
      "\n",
      "Epoch 00656: val_mse did not improve from 14.24815\n",
      "Epoch 657/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.8171 - mse: 9.8171 - val_loss: 14.9922 - val_mse: 14.9922\n",
      "\n",
      "Epoch 00657: val_mse did not improve from 14.24815\n",
      "Epoch 658/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.2833 - mse: 8.2833 - val_loss: 14.4486 - val_mse: 14.4486\n",
      "\n",
      "Epoch 00658: val_mse did not improve from 14.24815\n",
      "Epoch 659/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.5340 - mse: 8.5340 - val_loss: 15.3450 - val_mse: 15.3450\n",
      "\n",
      "Epoch 00659: val_mse did not improve from 14.24815\n",
      "Epoch 660/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.8444 - mse: 7.8444 - val_loss: 16.4664 - val_mse: 16.4664\n",
      "\n",
      "Epoch 00660: val_mse did not improve from 14.24815\n",
      "Epoch 661/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.7682 - mse: 8.7682 - val_loss: 15.5922 - val_mse: 15.5922\n",
      "\n",
      "Epoch 00661: val_mse did not improve from 14.24815\n",
      "Epoch 662/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.7130 - mse: 8.7130 - val_loss: 15.4773 - val_mse: 15.4773\n",
      "\n",
      "Epoch 00662: val_mse did not improve from 14.24815\n",
      "Epoch 663/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.1874 - mse: 8.1874 - val_loss: 15.7349 - val_mse: 15.7349\n",
      "\n",
      "Epoch 00663: val_mse did not improve from 14.24815\n",
      "Epoch 664/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.6056 - mse: 8.6056 - val_loss: 14.4148 - val_mse: 14.4148\n",
      "\n",
      "Epoch 00664: val_mse did not improve from 14.24815\n",
      "Epoch 665/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.6992 - mse: 8.6992 - val_loss: 15.3722 - val_mse: 15.3722\n",
      "\n",
      "Epoch 00665: val_mse did not improve from 14.24815\n",
      "Epoch 666/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.0913 - mse: 8.0913 - val_loss: 14.5785 - val_mse: 14.5785\n",
      "\n",
      "Epoch 00666: val_mse did not improve from 14.24815\n",
      "Epoch 667/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.9381 - mse: 8.9381 - val_loss: 14.7329 - val_mse: 14.7329\n",
      "\n",
      "Epoch 00667: val_mse did not improve from 14.24815\n",
      "Epoch 668/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 8.7261 - mse: 8.7261 - val_loss: 14.8998 - val_mse: 14.8998\n",
      "\n",
      "Epoch 00668: val_mse did not improve from 14.24815\n",
      "Epoch 669/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0832 - mse: 8.0832 - val_loss: 14.7257 - val_mse: 14.7257\n",
      "\n",
      "Epoch 00669: val_mse did not improve from 14.24815\n",
      "Epoch 670/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.6356 - mse: 7.6356 - val_loss: 14.4105 - val_mse: 14.4105\n",
      "\n",
      "Epoch 00670: val_mse did not improve from 14.24815\n",
      "Epoch 671/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.7141 - mse: 8.7141 - val_loss: 14.5268 - val_mse: 14.5268\n",
      "\n",
      "Epoch 00671: val_mse did not improve from 14.24815\n",
      "Epoch 672/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.8808 - mse: 7.8808 - val_loss: 15.7318 - val_mse: 15.7318\n",
      "\n",
      "Epoch 00672: val_mse did not improve from 14.24815\n",
      "Epoch 673/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.6676 - mse: 9.6676 - val_loss: 15.8976 - val_mse: 15.8976\n",
      "\n",
      "Epoch 00673: val_mse did not improve from 14.24815\n",
      "Epoch 674/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.1034 - mse: 9.1034 - val_loss: 13.9846 - val_mse: 13.9846\n",
      "\n",
      "Epoch 00674: val_mse improved from 14.24815 to 13.98462, saving model to ./model\\674-13.9846.hdf5\n",
      "Epoch 675/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.4968 - mse: 8.4968 - val_loss: 14.6034 - val_mse: 14.6034\n",
      "\n",
      "Epoch 00675: val_mse did not improve from 13.98462\n",
      "Epoch 676/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.9712 - mse: 7.9712 - val_loss: 14.7008 - val_mse: 14.7008\n",
      "\n",
      "Epoch 00676: val_mse did not improve from 13.98462\n",
      "Epoch 677/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.9606 - mse: 7.9606 - val_loss: 15.6097 - val_mse: 15.6097\n",
      "\n",
      "Epoch 00677: val_mse did not improve from 13.98462\n",
      "Epoch 678/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.3551 - mse: 8.3551 - val_loss: 15.3992 - val_mse: 15.3992\n",
      "\n",
      "Epoch 00678: val_mse did not improve from 13.98462\n",
      "Epoch 679/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.2688 - mse: 8.2688 - val_loss: 15.5944 - val_mse: 15.5944\n",
      "\n",
      "Epoch 00679: val_mse did not improve from 13.98462\n",
      "Epoch 680/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.3688 - mse: 8.3688 - val_loss: 17.7007 - val_mse: 17.7007\n",
      "\n",
      "Epoch 00680: val_mse did not improve from 13.98462\n",
      "Epoch 681/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.5701 - mse: 8.5701 - val_loss: 15.7475 - val_mse: 15.7475\n",
      "\n",
      "Epoch 00681: val_mse did not improve from 13.98462\n",
      "Epoch 682/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.9140 - mse: 9.9140 - val_loss: 15.4233 - val_mse: 15.4233\n",
      "\n",
      "Epoch 00682: val_mse did not improve from 13.98462\n",
      "Epoch 683/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.5392 - mse: 8.5392 - val_loss: 14.5825 - val_mse: 14.5825\n",
      "\n",
      "Epoch 00683: val_mse did not improve from 13.98462\n",
      "Epoch 684/5000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.4256 - mse: 8.4256 - val_loss: 14.7347 - val_mse: 14.7347\n",
      "\n",
      "Epoch 00684: val_mse did not improve from 13.98462\n",
      "Epoch 685/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.4443 - mse: 9.4443 - val_loss: 14.6378 - val_mse: 14.6378\n",
      "\n",
      "Epoch 00685: val_mse did not improve from 13.98462\n",
      "Epoch 686/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.9065 - mse: 8.9065 - val_loss: 14.7112 - val_mse: 14.7112\n",
      "\n",
      "Epoch 00686: val_mse did not improve from 13.98462\n",
      "Epoch 687/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.7989 - mse: 8.7989 - val_loss: 14.0554 - val_mse: 14.0554\n",
      "\n",
      "Epoch 00687: val_mse did not improve from 13.98462\n",
      "Epoch 688/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.0398 - mse: 10.0398 - val_loss: 15.7981 - val_mse: 15.7981\n",
      "\n",
      "Epoch 00688: val_mse did not improve from 13.98462\n",
      "Epoch 689/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.2729 - mse: 10.2729 - val_loss: 15.0136 - val_mse: 15.0136\n",
      "\n",
      "Epoch 00689: val_mse did not improve from 13.98462\n",
      "Epoch 690/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.6830 - mse: 8.6830 - val_loss: 14.6943 - val_mse: 14.6943\n",
      "\n",
      "Epoch 00690: val_mse did not improve from 13.98462\n",
      "Epoch 691/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.0168 - mse: 8.0168 - val_loss: 16.2526 - val_mse: 16.2526\n",
      "\n",
      "Epoch 00691: val_mse did not improve from 13.98462\n",
      "Epoch 692/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.9329 - mse: 7.9329 - val_loss: 14.6209 - val_mse: 14.6209\n",
      "\n",
      "Epoch 00692: val_mse did not improve from 13.98462\n",
      "Epoch 693/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0812 - mse: 8.0812 - val_loss: 14.2903 - val_mse: 14.2903\n",
      "\n",
      "Epoch 00693: val_mse did not improve from 13.98462\n",
      "Epoch 694/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.6796 - mse: 7.6796 - val_loss: 15.0579 - val_mse: 15.0579\n",
      "\n",
      "Epoch 00694: val_mse did not improve from 13.98462\n",
      "Epoch 695/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.3909 - mse: 8.3909 - val_loss: 14.2280 - val_mse: 14.2280\n",
      "\n",
      "Epoch 00695: val_mse did not improve from 13.98462\n",
      "Epoch 696/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.9169 - mse: 7.9169 - val_loss: 14.8812 - val_mse: 14.8812\n",
      "\n",
      "Epoch 00696: val_mse did not improve from 13.98462\n",
      "Epoch 697/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.6365 - mse: 8.6365 - val_loss: 14.2013 - val_mse: 14.2013\n",
      "\n",
      "Epoch 00697: val_mse did not improve from 13.98462\n",
      "Epoch 698/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.6960 - mse: 7.6960 - val_loss: 14.0671 - val_mse: 14.0671\n",
      "\n",
      "Epoch 00698: val_mse did not improve from 13.98462\n",
      "Epoch 699/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.6443 - mse: 7.6443 - val_loss: 16.5613 - val_mse: 16.5613\n",
      "\n",
      "Epoch 00699: val_mse did not improve from 13.98462\n",
      "Epoch 700/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.7263 - mse: 7.7263 - val_loss: 14.7068 - val_mse: 14.7068\n",
      "\n",
      "Epoch 00700: val_mse did not improve from 13.98462\n",
      "Epoch 701/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.2591 - mse: 8.2591 - val_loss: 14.4217 - val_mse: 14.4217\n",
      "\n",
      "Epoch 00701: val_mse did not improve from 13.98462\n",
      "Epoch 702/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.5654 - mse: 7.5654 - val_loss: 15.1145 - val_mse: 15.1145\n",
      "\n",
      "Epoch 00702: val_mse did not improve from 13.98462\n",
      "Epoch 703/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.1174 - mse: 8.1174 - val_loss: 14.9790 - val_mse: 14.9790\n",
      "\n",
      "Epoch 00703: val_mse did not improve from 13.98462\n",
      "Epoch 704/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.3892 - mse: 8.3892 - val_loss: 14.5483 - val_mse: 14.5483\n",
      "\n",
      "Epoch 00704: val_mse did not improve from 13.98462\n",
      "Epoch 705/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.7034 - mse: 7.7034 - val_loss: 13.9161 - val_mse: 13.9161\n",
      "\n",
      "Epoch 00705: val_mse improved from 13.98462 to 13.91612, saving model to ./model\\705-13.9161.hdf5\n",
      "Epoch 706/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.6820 - mse: 7.6820 - val_loss: 15.0982 - val_mse: 15.0982\n",
      "\n",
      "Epoch 00706: val_mse did not improve from 13.91612\n",
      "Epoch 707/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.5893 - mse: 7.5893 - val_loss: 13.9903 - val_mse: 13.9903\n",
      "\n",
      "Epoch 00707: val_mse did not improve from 13.91612\n",
      "Epoch 708/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.8161 - mse: 7.8161 - val_loss: 14.6985 - val_mse: 14.6985\n",
      "\n",
      "Epoch 00708: val_mse did not improve from 13.91612\n",
      "Epoch 709/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.6778 - mse: 8.6778 - val_loss: 14.9498 - val_mse: 14.9498\n",
      "\n",
      "Epoch 00709: val_mse did not improve from 13.91612\n",
      "Epoch 710/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.0846 - mse: 8.0846 - val_loss: 14.9999 - val_mse: 14.9999\n",
      "\n",
      "Epoch 00710: val_mse did not improve from 13.91612\n",
      "Epoch 711/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.2026 - mse: 9.2026 - val_loss: 16.7501 - val_mse: 16.7501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00711: val_mse did not improve from 13.91612\n",
      "Epoch 712/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.1785 - mse: 10.1785 - val_loss: 14.5889 - val_mse: 14.5889\n",
      "\n",
      "Epoch 00712: val_mse did not improve from 13.91612\n",
      "Epoch 713/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.0693 - mse: 9.0693 - val_loss: 15.6543 - val_mse: 15.6543\n",
      "\n",
      "Epoch 00713: val_mse did not improve from 13.91612\n",
      "Epoch 714/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.2790 - mse: 8.2790 - val_loss: 16.0478 - val_mse: 16.0478\n",
      "\n",
      "Epoch 00714: val_mse did not improve from 13.91612\n",
      "Epoch 715/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.3877 - mse: 9.3877 - val_loss: 15.0314 - val_mse: 15.0314\n",
      "\n",
      "Epoch 00715: val_mse did not improve from 13.91612\n",
      "Epoch 716/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.4163 - mse: 9.4163 - val_loss: 15.4523 - val_mse: 15.4523\n",
      "\n",
      "Epoch 00716: val_mse did not improve from 13.91612\n",
      "Epoch 717/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.5677 - mse: 8.5677 - val_loss: 14.3653 - val_mse: 14.3653\n",
      "\n",
      "Epoch 00717: val_mse did not improve from 13.91612\n",
      "Epoch 718/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.9765 - mse: 8.9765 - val_loss: 19.3534 - val_mse: 19.3534\n",
      "\n",
      "Epoch 00718: val_mse did not improve from 13.91612\n",
      "Epoch 719/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.1869 - mse: 9.1869 - val_loss: 17.9828 - val_mse: 17.9828\n",
      "\n",
      "Epoch 00719: val_mse did not improve from 13.91612\n",
      "Epoch 720/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.5503 - mse: 8.5503 - val_loss: 17.6118 - val_mse: 17.6118\n",
      "\n",
      "Epoch 00720: val_mse did not improve from 13.91612\n",
      "Epoch 721/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.2757 - mse: 8.2757 - val_loss: 15.4550 - val_mse: 15.4550\n",
      "\n",
      "Epoch 00721: val_mse did not improve from 13.91612\n",
      "Epoch 722/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.3072 - mse: 8.3072 - val_loss: 16.8706 - val_mse: 16.8706\n",
      "\n",
      "Epoch 00722: val_mse did not improve from 13.91612\n",
      "Epoch 723/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.6104 - mse: 8.6104 - val_loss: 17.3216 - val_mse: 17.3216\n",
      "\n",
      "Epoch 00723: val_mse did not improve from 13.91612\n",
      "Epoch 724/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.4018 - mse: 8.4018 - val_loss: 14.1620 - val_mse: 14.1620\n",
      "\n",
      "Epoch 00724: val_mse did not improve from 13.91612\n",
      "Epoch 725/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.2472 - mse: 8.2472 - val_loss: 14.4686 - val_mse: 14.4686\n",
      "\n",
      "Epoch 00725: val_mse did not improve from 13.91612\n",
      "Epoch 726/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.8324 - mse: 7.8324 - val_loss: 14.4895 - val_mse: 14.4895\n",
      "\n",
      "Epoch 00726: val_mse did not improve from 13.91612\n",
      "Epoch 727/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.9734 - mse: 7.9734 - val_loss: 14.3078 - val_mse: 14.3078\n",
      "\n",
      "Epoch 00727: val_mse did not improve from 13.91612\n",
      "Epoch 728/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.5257 - mse: 8.5257 - val_loss: 15.0779 - val_mse: 15.0779\n",
      "\n",
      "Epoch 00728: val_mse did not improve from 13.91612\n",
      "Epoch 729/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.7592 - mse: 7.7592 - val_loss: 14.3500 - val_mse: 14.3500\n",
      "\n",
      "Epoch 00729: val_mse did not improve from 13.91612\n",
      "Epoch 730/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.7685 - mse: 7.7685 - val_loss: 14.5451 - val_mse: 14.5451\n",
      "\n",
      "Epoch 00730: val_mse did not improve from 13.91612\n",
      "Epoch 731/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.7937 - mse: 7.7937 - val_loss: 14.5744 - val_mse: 14.5744\n",
      "\n",
      "Epoch 00731: val_mse did not improve from 13.91612\n",
      "Epoch 732/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.2977 - mse: 7.2977 - val_loss: 14.7103 - val_mse: 14.7103\n",
      "\n",
      "Epoch 00732: val_mse did not improve from 13.91612\n",
      "Epoch 733/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.4850 - mse: 8.4850 - val_loss: 15.1910 - val_mse: 15.1910\n",
      "\n",
      "Epoch 00733: val_mse did not improve from 13.91612\n",
      "Epoch 734/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.8433 - mse: 7.8433 - val_loss: 15.4033 - val_mse: 15.4033\n",
      "\n",
      "Epoch 00734: val_mse did not improve from 13.91612\n",
      "Epoch 735/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.7982 - mse: 7.7982 - val_loss: 14.8268 - val_mse: 14.8268\n",
      "\n",
      "Epoch 00735: val_mse did not improve from 13.91612\n",
      "Epoch 736/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.1867 - mse: 8.1867 - val_loss: 13.9197 - val_mse: 13.9197\n",
      "\n",
      "Epoch 00736: val_mse did not improve from 13.91612\n",
      "Epoch 737/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.1873 - mse: 8.1873 - val_loss: 16.3150 - val_mse: 16.3150\n",
      "\n",
      "Epoch 00737: val_mse did not improve from 13.91612\n",
      "Epoch 738/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.4981 - mse: 8.4981 - val_loss: 15.4068 - val_mse: 15.4068\n",
      "\n",
      "Epoch 00738: val_mse did not improve from 13.91612\n",
      "Epoch 739/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.7471 - mse: 8.7471 - val_loss: 13.9728 - val_mse: 13.9728\n",
      "\n",
      "Epoch 00739: val_mse did not improve from 13.91612\n",
      "Epoch 740/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.7119 - mse: 7.7119 - val_loss: 14.6009 - val_mse: 14.6009\n",
      "\n",
      "Epoch 00740: val_mse did not improve from 13.91612\n",
      "Epoch 741/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.1884 - mse: 8.1884 - val_loss: 14.5300 - val_mse: 14.5300\n",
      "\n",
      "Epoch 00741: val_mse did not improve from 13.91612\n",
      "Epoch 742/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.4822 - mse: 8.4822 - val_loss: 14.8370 - val_mse: 14.8370\n",
      "\n",
      "Epoch 00742: val_mse did not improve from 13.91612\n",
      "Epoch 743/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.5709 - mse: 8.5709 - val_loss: 14.7817 - val_mse: 14.7817\n",
      "\n",
      "Epoch 00743: val_mse did not improve from 13.91612\n",
      "Epoch 744/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.0414 - mse: 9.0414 - val_loss: 15.4977 - val_mse: 15.4977\n",
      "\n",
      "Epoch 00744: val_mse did not improve from 13.91612\n",
      "Epoch 745/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.4459 - mse: 8.4459 - val_loss: 17.6422 - val_mse: 17.6422\n",
      "\n",
      "Epoch 00745: val_mse did not improve from 13.91612\n",
      "Epoch 746/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.9497 - mse: 7.9497 - val_loss: 13.8904 - val_mse: 13.8904\n",
      "\n",
      "Epoch 00746: val_mse improved from 13.91612 to 13.89036, saving model to ./model\\746-13.8904.hdf5\n",
      "Epoch 747/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.5353 - mse: 8.5353 - val_loss: 17.7196 - val_mse: 17.7196\n",
      "\n",
      "Epoch 00747: val_mse did not improve from 13.89036\n",
      "Epoch 748/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.9790 - mse: 10.9790 - val_loss: 16.3516 - val_mse: 16.3516\n",
      "\n",
      "Epoch 00748: val_mse did not improve from 13.89036\n",
      "Epoch 749/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 11.3461 - mse: 11.3461 - val_loss: 15.6448 - val_mse: 15.6448\n",
      "\n",
      "Epoch 00749: val_mse did not improve from 13.89036\n",
      "Epoch 750/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.6162 - mse: 9.6162 - val_loss: 14.8520 - val_mse: 14.8520\n",
      "\n",
      "Epoch 00750: val_mse did not improve from 13.89036\n",
      "Epoch 751/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.6106 - mse: 8.6106 - val_loss: 13.5788 - val_mse: 13.5788\n",
      "\n",
      "Epoch 00751: val_mse improved from 13.89036 to 13.57882, saving model to ./model\\751-13.5788.hdf5\n",
      "Epoch 752/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.3973 - mse: 7.3973 - val_loss: 13.9478 - val_mse: 13.9478\n",
      "\n",
      "Epoch 00752: val_mse did not improve from 13.57882\n",
      "Epoch 753/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.3072 - mse: 7.3072 - val_loss: 15.3677 - val_mse: 15.3677\n",
      "\n",
      "Epoch 00753: val_mse did not improve from 13.57882\n",
      "Epoch 754/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.6951 - mse: 7.6951 - val_loss: 15.7553 - val_mse: 15.7553\n",
      "\n",
      "Epoch 00754: val_mse did not improve from 13.57882\n",
      "Epoch 755/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0094 - mse: 8.0094 - val_loss: 14.0027 - val_mse: 14.0027\n",
      "\n",
      "Epoch 00755: val_mse did not improve from 13.57882\n",
      "Epoch 756/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.8442 - mse: 6.8442 - val_loss: 15.8058 - val_mse: 15.8058\n",
      "\n",
      "Epoch 00756: val_mse did not improve from 13.57882\n",
      "Epoch 757/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.5670 - mse: 7.5670 - val_loss: 15.0258 - val_mse: 15.0258\n",
      "\n",
      "Epoch 00757: val_mse did not improve from 13.57882\n",
      "Epoch 758/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.1947 - mse: 7.1947 - val_loss: 14.1592 - val_mse: 14.1592\n",
      "\n",
      "Epoch 00758: val_mse did not improve from 13.57882\n",
      "Epoch 759/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.1597 - mse: 7.1597 - val_loss: 14.1597 - val_mse: 14.1597\n",
      "\n",
      "Epoch 00759: val_mse did not improve from 13.57882\n",
      "Epoch 760/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.8122 - mse: 6.8122 - val_loss: 16.6068 - val_mse: 16.6068\n",
      "\n",
      "Epoch 00760: val_mse did not improve from 13.57882\n",
      "Epoch 761/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0528 - mse: 8.0528 - val_loss: 16.9517 - val_mse: 16.9517\n",
      "\n",
      "Epoch 00761: val_mse did not improve from 13.57882\n",
      "Epoch 762/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.4139 - mse: 7.4139 - val_loss: 14.7999 - val_mse: 14.7999\n",
      "\n",
      "Epoch 00762: val_mse did not improve from 13.57882\n",
      "Epoch 763/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.8825 - mse: 8.8825 - val_loss: 15.2759 - val_mse: 15.2759\n",
      "\n",
      "Epoch 00763: val_mse did not improve from 13.57882\n",
      "Epoch 764/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.9293 - mse: 7.9293 - val_loss: 16.5245 - val_mse: 16.5245\n",
      "\n",
      "Epoch 00764: val_mse did not improve from 13.57882\n",
      "Epoch 765/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.2105 - mse: 8.2105 - val_loss: 17.3151 - val_mse: 17.3151\n",
      "\n",
      "Epoch 00765: val_mse did not improve from 13.57882\n",
      "Epoch 766/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.5539 - mse: 8.5539 - val_loss: 15.3952 - val_mse: 15.3952\n",
      "\n",
      "Epoch 00766: val_mse did not improve from 13.57882\n",
      "Epoch 767/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.9180 - mse: 7.9180 - val_loss: 15.0989 - val_mse: 15.0989\n",
      "\n",
      "Epoch 00767: val_mse did not improve from 13.57882\n",
      "Epoch 768/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.8285 - mse: 7.8285 - val_loss: 15.7276 - val_mse: 15.7276\n",
      "\n",
      "Epoch 00768: val_mse did not improve from 13.57882\n",
      "Epoch 769/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0930 - mse: 8.0930 - val_loss: 13.9468 - val_mse: 13.9468\n",
      "\n",
      "Epoch 00769: val_mse did not improve from 13.57882\n",
      "Epoch 770/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.4557 - mse: 7.4557 - val_loss: 14.0313 - val_mse: 14.0313\n",
      "\n",
      "Epoch 00770: val_mse did not improve from 13.57882\n",
      "Epoch 771/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.2532 - mse: 8.2532 - val_loss: 15.2839 - val_mse: 15.2839\n",
      "\n",
      "Epoch 00771: val_mse did not improve from 13.57882\n",
      "Epoch 772/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.3116 - mse: 8.3116 - val_loss: 14.7180 - val_mse: 14.7180\n",
      "\n",
      "Epoch 00772: val_mse did not improve from 13.57882\n",
      "Epoch 773/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 9.0363 - mse: 9.0363 - val_loss: 16.3527 - val_mse: 16.3527\n",
      "\n",
      "Epoch 00773: val_mse did not improve from 13.57882\n",
      "Epoch 774/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.5879 - mse: 8.5879 - val_loss: 15.8770 - val_mse: 15.8770\n",
      "\n",
      "Epoch 00774: val_mse did not improve from 13.57882\n",
      "Epoch 775/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.2288 - mse: 8.2288 - val_loss: 14.6979 - val_mse: 14.6979\n",
      "\n",
      "Epoch 00775: val_mse did not improve from 13.57882\n",
      "Epoch 776/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.3995 - mse: 7.3995 - val_loss: 16.9473 - val_mse: 16.9473\n",
      "\n",
      "Epoch 00776: val_mse did not improve from 13.57882\n",
      "Epoch 777/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.1733 - mse: 9.1733 - val_loss: 14.8888 - val_mse: 14.8888\n",
      "\n",
      "Epoch 00777: val_mse did not improve from 13.57882\n",
      "Epoch 778/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.5965 - mse: 8.5965 - val_loss: 14.3869 - val_mse: 14.3869\n",
      "\n",
      "Epoch 00778: val_mse did not improve from 13.57882\n",
      "Epoch 779/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.5401 - mse: 8.5401 - val_loss: 19.6951 - val_mse: 19.6951\n",
      "\n",
      "Epoch 00779: val_mse did not improve from 13.57882\n",
      "Epoch 780/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 10.2812 - mse: 10.2812 - val_loss: 17.1614 - val_mse: 17.1614\n",
      "\n",
      "Epoch 00780: val_mse did not improve from 13.57882\n",
      "Epoch 781/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.5564 - mse: 7.5564 - val_loss: 15.9285 - val_mse: 15.9285\n",
      "\n",
      "Epoch 00781: val_mse did not improve from 13.57882\n",
      "Epoch 782/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0226 - mse: 8.0226 - val_loss: 17.2869 - val_mse: 17.2869\n",
      "\n",
      "Epoch 00782: val_mse did not improve from 13.57882\n",
      "Epoch 783/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.2063 - mse: 9.2063 - val_loss: 14.1366 - val_mse: 14.1366\n",
      "\n",
      "Epoch 00783: val_mse did not improve from 13.57882\n",
      "Epoch 784/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.3898 - mse: 8.3898 - val_loss: 14.5037 - val_mse: 14.5037\n",
      "\n",
      "Epoch 00784: val_mse did not improve from 13.57882\n",
      "Epoch 785/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0356 - mse: 8.0356 - val_loss: 15.3698 - val_mse: 15.3698\n",
      "\n",
      "Epoch 00785: val_mse did not improve from 13.57882\n",
      "Epoch 786/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.3782 - mse: 7.3782 - val_loss: 14.5888 - val_mse: 14.5888\n",
      "\n",
      "Epoch 00786: val_mse did not improve from 13.57882\n",
      "Epoch 787/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.4151 - mse: 7.4151 - val_loss: 13.9758 - val_mse: 13.9758\n",
      "\n",
      "Epoch 00787: val_mse did not improve from 13.57882\n",
      "Epoch 788/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.2082 - mse: 7.2082 - val_loss: 14.1423 - val_mse: 14.1423\n",
      "\n",
      "Epoch 00788: val_mse did not improve from 13.57882\n",
      "Epoch 789/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.6113 - mse: 7.6113 - val_loss: 15.6267 - val_mse: 15.6267\n",
      "\n",
      "Epoch 00789: val_mse did not improve from 13.57882\n",
      "Epoch 790/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.8262 - mse: 8.8262 - val_loss: 16.3117 - val_mse: 16.3117\n",
      "\n",
      "Epoch 00790: val_mse did not improve from 13.57882\n",
      "Epoch 791/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.8376 - mse: 8.8376 - val_loss: 14.2747 - val_mse: 14.2747\n",
      "\n",
      "Epoch 00791: val_mse did not improve from 13.57882\n",
      "Epoch 792/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.8730 - mse: 7.8730 - val_loss: 14.7790 - val_mse: 14.7790\n",
      "\n",
      "Epoch 00792: val_mse did not improve from 13.57882\n",
      "Epoch 793/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.2052 - mse: 8.2052 - val_loss: 15.5874 - val_mse: 15.5874\n",
      "\n",
      "Epoch 00793: val_mse did not improve from 13.57882\n",
      "Epoch 794/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.4399 - mse: 8.4399 - val_loss: 18.6547 - val_mse: 18.6547\n",
      "\n",
      "Epoch 00794: val_mse did not improve from 13.57882\n",
      "Epoch 795/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.9344 - mse: 8.9344 - val_loss: 14.4147 - val_mse: 14.4147\n",
      "\n",
      "Epoch 00795: val_mse did not improve from 13.57882\n",
      "Epoch 796/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.2471 - mse: 7.2471 - val_loss: 14.2630 - val_mse: 14.2630\n",
      "\n",
      "Epoch 00796: val_mse did not improve from 13.57882\n",
      "Epoch 797/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.1852 - mse: 7.1852 - val_loss: 14.1594 - val_mse: 14.1594\n",
      "\n",
      "Epoch 00797: val_mse did not improve from 13.57882\n",
      "Epoch 798/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.5327 - mse: 7.5327 - val_loss: 14.1618 - val_mse: 14.1618\n",
      "\n",
      "Epoch 00798: val_mse did not improve from 13.57882\n",
      "Epoch 799/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0171 - mse: 8.0171 - val_loss: 14.2824 - val_mse: 14.2824\n",
      "\n",
      "Epoch 00799: val_mse did not improve from 13.57882\n",
      "Epoch 800/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.8125 - mse: 7.8125 - val_loss: 16.3814 - val_mse: 16.3814\n",
      "\n",
      "Epoch 00800: val_mse did not improve from 13.57882\n",
      "Epoch 801/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.1548 - mse: 7.1548 - val_loss: 13.8253 - val_mse: 13.8253\n",
      "\n",
      "Epoch 00801: val_mse did not improve from 13.57882\n",
      "Epoch 802/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7553 - mse: 6.7553 - val_loss: 14.4952 - val_mse: 14.4952\n",
      "\n",
      "Epoch 00802: val_mse did not improve from 13.57882\n",
      "Epoch 803/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.3344 - mse: 8.3344 - val_loss: 14.5882 - val_mse: 14.5882\n",
      "\n",
      "Epoch 00803: val_mse did not improve from 13.57882\n",
      "Epoch 804/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.9506 - mse: 8.9506 - val_loss: 14.5291 - val_mse: 14.5291\n",
      "\n",
      "Epoch 00804: val_mse did not improve from 13.57882\n",
      "Epoch 805/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.0170 - mse: 8.0170 - val_loss: 14.0121 - val_mse: 14.0121\n",
      "\n",
      "Epoch 00805: val_mse did not improve from 13.57882\n",
      "Epoch 806/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 7.4387 - mse: 7.4387 - val_loss: 14.0897 - val_mse: 14.0897\n",
      "\n",
      "Epoch 00806: val_mse did not improve from 13.57882\n",
      "Epoch 807/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.2101 - mse: 8.2101 - val_loss: 15.2472 - val_mse: 15.2472\n",
      "\n",
      "Epoch 00807: val_mse did not improve from 13.57882\n",
      "Epoch 808/5000\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.7672 - mse: 5.767 - 0s 7ms/step - loss: 7.2904 - mse: 7.2904 - val_loss: 15.0103 - val_mse: 15.0103\n",
      "\n",
      "Epoch 00808: val_mse did not improve from 13.57882\n",
      "Epoch 809/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.6293 - mse: 7.6293 - val_loss: 14.1329 - val_mse: 14.1329\n",
      "\n",
      "Epoch 00809: val_mse did not improve from 13.57882\n",
      "Epoch 810/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.0534 - mse: 7.0534 - val_loss: 14.1716 - val_mse: 14.1716\n",
      "\n",
      "Epoch 00810: val_mse did not improve from 13.57882\n",
      "Epoch 811/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.3086 - mse: 7.3086 - val_loss: 16.6456 - val_mse: 16.6456\n",
      "\n",
      "Epoch 00811: val_mse did not improve from 13.57882\n",
      "Epoch 812/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.6780 - mse: 8.6780 - val_loss: 16.5883 - val_mse: 16.5883\n",
      "\n",
      "Epoch 00812: val_mse did not improve from 13.57882\n",
      "Epoch 813/5000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10.1415 - mse: 10.1415 - val_loss: 17.4662 - val_mse: 17.4662\n",
      "\n",
      "Epoch 00813: val_mse did not improve from 13.57882\n",
      "Epoch 814/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.1266 - mse: 9.1266 - val_loss: 13.7339 - val_mse: 13.7339\n",
      "\n",
      "Epoch 00814: val_mse did not improve from 13.57882\n",
      "Epoch 815/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.5213 - mse: 9.5213 - val_loss: 14.4048 - val_mse: 14.4048\n",
      "\n",
      "Epoch 00815: val_mse did not improve from 13.57882\n",
      "Epoch 816/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 10.3866 - mse: 10.3866 - val_loss: 13.7918 - val_mse: 13.7918\n",
      "\n",
      "Epoch 00816: val_mse did not improve from 13.57882\n",
      "Epoch 817/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.6560 - mse: 8.6560 - val_loss: 14.1328 - val_mse: 14.1328\n",
      "\n",
      "Epoch 00817: val_mse did not improve from 13.57882\n",
      "Epoch 818/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.1320 - mse: 8.1320 - val_loss: 14.5055 - val_mse: 14.5055\n",
      "\n",
      "Epoch 00818: val_mse did not improve from 13.57882\n",
      "Epoch 819/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.7249 - mse: 7.7249 - val_loss: 14.4416 - val_mse: 14.4416\n",
      "\n",
      "Epoch 00819: val_mse did not improve from 13.57882\n",
      "Epoch 820/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.8729 - mse: 7.8729 - val_loss: 15.1405 - val_mse: 15.1405\n",
      "\n",
      "Epoch 00820: val_mse did not improve from 13.57882\n",
      "Epoch 821/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.5120 - mse: 7.5120 - val_loss: 13.7192 - val_mse: 13.7192\n",
      "\n",
      "Epoch 00821: val_mse did not improve from 13.57882\n",
      "Epoch 822/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.8159 - mse: 6.8159 - val_loss: 14.1655 - val_mse: 14.1655\n",
      "\n",
      "Epoch 00822: val_mse did not improve from 13.57882\n",
      "Epoch 823/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.2205 - mse: 7.2205 - val_loss: 15.6609 - val_mse: 15.6609\n",
      "\n",
      "Epoch 00823: val_mse did not improve from 13.57882\n",
      "Epoch 824/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.4611 - mse: 7.4611 - val_loss: 14.6680 - val_mse: 14.6680\n",
      "\n",
      "Epoch 00824: val_mse did not improve from 13.57882\n",
      "Epoch 825/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.0364 - mse: 7.0364 - val_loss: 14.1067 - val_mse: 14.1067\n",
      "\n",
      "Epoch 00825: val_mse did not improve from 13.57882\n",
      "Epoch 826/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 6.9237 - mse: 6.9237 - val_loss: 13.9769 - val_mse: 13.9769\n",
      "\n",
      "Epoch 00826: val_mse did not improve from 13.57882\n",
      "Epoch 827/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.7536 - mse: 6.7536 - val_loss: 14.0923 - val_mse: 14.0923\n",
      "\n",
      "Epoch 00827: val_mse did not improve from 13.57882\n",
      "Epoch 828/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.7465 - mse: 6.7465 - val_loss: 14.0295 - val_mse: 14.0295\n",
      "\n",
      "Epoch 00828: val_mse did not improve from 13.57882\n",
      "Epoch 829/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.4436 - mse: 7.4436 - val_loss: 13.8833 - val_mse: 13.8833\n",
      "\n",
      "Epoch 00829: val_mse did not improve from 13.57882\n",
      "Epoch 830/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7569 - mse: 6.7569 - val_loss: 14.6731 - val_mse: 14.6731\n",
      "\n",
      "Epoch 00830: val_mse did not improve from 13.57882\n",
      "Epoch 831/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.8505 - mse: 6.8505 - val_loss: 13.9423 - val_mse: 13.9423\n",
      "\n",
      "Epoch 00831: val_mse did not improve from 13.57882\n",
      "Epoch 832/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.0252 - mse: 8.0252 - val_loss: 13.7284 - val_mse: 13.7284\n",
      "\n",
      "Epoch 00832: val_mse did not improve from 13.57882\n",
      "Epoch 833/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.6296 - mse: 7.6296 - val_loss: 16.1506 - val_mse: 16.1506\n",
      "\n",
      "Epoch 00833: val_mse did not improve from 13.57882\n",
      "Epoch 834/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 7.6915 - mse: 7.6915 - val_loss: 14.0683 - val_mse: 14.0683\n",
      "\n",
      "Epoch 00834: val_mse did not improve from 13.57882\n",
      "Epoch 835/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 6.7736 - mse: 6.7736 - val_loss: 14.7474 - val_mse: 14.7474\n",
      "\n",
      "Epoch 00835: val_mse did not improve from 13.57882\n",
      "Epoch 836/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.1338 - mse: 8.1338 - val_loss: 15.6554 - val_mse: 15.6554\n",
      "\n",
      "Epoch 00836: val_mse did not improve from 13.57882\n",
      "Epoch 837/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 8.2164 - mse: 8.2164 - val_loss: 15.5040 - val_mse: 15.5040\n",
      "\n",
      "Epoch 00837: val_mse did not improve from 13.57882\n",
      "Epoch 838/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 8.9431 - mse: 8.9431 - val_loss: 14.6485 - val_mse: 14.6485\n",
      "\n",
      "Epoch 00838: val_mse did not improve from 13.57882\n",
      "Epoch 839/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.7659 - mse: 7.7659 - val_loss: 14.0475 - val_mse: 14.0475\n",
      "\n",
      "Epoch 00839: val_mse did not improve from 13.57882\n",
      "Epoch 840/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.8491 - mse: 7.8491 - val_loss: 16.3643 - val_mse: 16.3643\n",
      "\n",
      "Epoch 00840: val_mse did not improve from 13.57882\n",
      "Epoch 841/5000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.0148 - mse: 8.0148 - val_loss: 14.9790 - val_mse: 14.9790\n",
      "\n",
      "Epoch 00841: val_mse did not improve from 13.57882\n",
      "Epoch 842/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.1887 - mse: 7.1887 - val_loss: 13.8929 - val_mse: 13.8929\n",
      "\n",
      "Epoch 00842: val_mse did not improve from 13.57882\n",
      "Epoch 843/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 6ms/step - loss: 6.4417 - mse: 6.4417 - val_loss: 15.1140 - val_mse: 15.1140\n",
      "\n",
      "Epoch 00843: val_mse did not improve from 13.57882\n",
      "Epoch 844/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.1024 - mse: 7.1024 - val_loss: 14.4720 - val_mse: 14.4720\n",
      "\n",
      "Epoch 00844: val_mse did not improve from 13.57882\n",
      "Epoch 845/5000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 6.5937 - mse: 6.5937 - val_loss: 17.6734 - val_mse: 17.6734\n",
      "\n",
      "Epoch 00845: val_mse did not improve from 13.57882\n",
      "Epoch 846/5000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 8.0544 - mse: 8.0544 - val_loss: 19.3221 - val_mse: 19.3221\n",
      "\n",
      "Epoch 00846: val_mse did not improve from 13.57882\n",
      "Epoch 847/5000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.7464 - mse: 9.7464 - val_loss: 20.0128 - val_mse: 20.0128\n",
      "\n",
      "Epoch 00847: val_mse did not improve from 13.57882\n",
      "Epoch 848/5000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 9.4454 - mse: 9.4454 - val_loss: 16.8757 - val_mse: 16.8757\n",
      "\n",
      "Epoch 00848: val_mse did not improve from 13.57882\n",
      "Epoch 849/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 7.1250 - mse: 7.1250 - val_loss: 17.7906 - val_mse: 17.7906\n",
      "\n",
      "Epoch 00849: val_mse did not improve from 13.57882\n",
      "Epoch 850/5000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 9.0600 - mse: 9.0600 - val_loss: 19.7999 - val_mse: 19.7999\n",
      "\n",
      "Epoch 00850: val_mse did not improve from 13.57882\n",
      "Epoch 851/5000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 8.1448 - mse: 8.1448 - val_loss: 17.7630 - val_mse: 17.7630\n",
      "\n",
      "Epoch 00851: val_mse did not improve from 13.57882\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(X_train, Y_train, validation_split=0.33, epochs=5000, batch_size=30, verbose=1, callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격: 22.600, 예상가격: 20.870\n",
      "실제가격: 50.000, 예상가격: 32.587\n",
      "실제가격: 23.000, 예상가격: 23.142\n",
      "실제가격: 8.300, 예상가격: 8.058\n",
      "실제가격: 21.200, 예상가격: 18.024\n",
      "실제가격: 19.900, 예상가격: 18.999\n",
      "실제가격: 20.600, 예상가격: 19.808\n",
      "실제가격: 18.700, 예상가격: 20.322\n",
      "실제가격: 16.100, 예상가격: 17.959\n",
      "실제가격: 18.600, 예상가격: 10.340\n"
     ]
    }
   ],
   "source": [
    "# 예측 값과 실제 값의 비교\n",
    "Y_prediction = model.predict(X_test).flatten()\n",
    "# flatten : 데이터 배열이 몇 차원이든 모두 1차원으로 바꿔 읽기 쉽게 해 주는 함수\n",
    "\n",
    "# 10개 실제값과 예측값 비교\n",
    "for i in range(10):\n",
    "    label = Y_test[i]\n",
    "    prediction = Y_prediction[i]\n",
    "    print(\"실제가격: {:.3f}, 예상가격: {:.3f}\".format(label, prediction))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> 1개 정도를 제외하고는 9개의 집 가격을 어느정도 맞췄다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀 학습 history 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "851"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_acc 에 학습 셋으로 측정한 정확도의 값을 저장\n",
    "y_vmse = history.history['val_mse']\n",
    "y_mse = history.history['mse']\n",
    "\n",
    "# x값을 지정하고 정확도를 파란색으로, 오차를 빨간색으로 표시\n",
    "x_len = numpy.arange(len(y_mse))\n",
    "len(x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x_len, y_vmse, \"o\", c=\"red\", markersize=3, label='val_mse')\n",
    "plt.plot(x_len, y_mse, \"o\", c=\"blue\", markersize=3, label='mse')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylim(0, 70)  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
