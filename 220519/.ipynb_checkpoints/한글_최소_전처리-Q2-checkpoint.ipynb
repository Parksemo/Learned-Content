{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c734942",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8184a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_table('ratings_train.txt')[['document','label']]\n",
    "test_data = pd.read_table('ratings_test.txt')[['document','label']]\n",
    "data=pd.concat((train_data,test_data),axis=0)\n",
    "data = data.rename(columns={'label': 'y', 'document': 'X'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de35309d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class 한글_전처리기:\n",
    "\n",
    "    def __init__(self,data):\n",
    "        data['clean_X'] = data['X']\n",
    "        data['y_name'] = data['y']\n",
    "        data['encoder_y'] = LabelEncoder().fit_transform(data['y'])\n",
    "        data['categorical_y'] = list(to_categorical(data['encoder_y']))\n",
    "        s_w = set(['은', '는', '이', '가', '를', '들', '에게', '의', '을', '도', '으로', '만', '라서', '하다'])\n",
    "        self.data = data\n",
    "        self.s_w = s_w\n",
    "    def ck_m(self):\n",
    "        print(f'결측치 확인:{self.data.isnull().values.any()}')\n",
    "        print(f\"X 중복 확인:{self.data['clean_X'].nunique(),len(self.data['clean_X'])}\\n\"\n",
    "              f\"y 중복 확인:{self.data['y'].nunique(),len(self.data['y'])}\")\n",
    "    def 전처리_결과_출력(self,n=1):\n",
    "        self.data['clean_X'].replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '', inplace=True)\n",
    "        self.data['clean_X'].replace('^ +', '', inplace=True)\n",
    "        self.data['clean_X'].replace('', np.nan, inplace=True)\n",
    "        self.data = self.data.dropna(how='any')\n",
    "        \n",
    "        okt = Okt()\n",
    "        X_data = []\n",
    "        for i in tqdm(self.data['clean_X']):\n",
    "            tk_d = okt.morphs(i)\n",
    "            end_d = [w for w in tk_d if not w in self.s_w]\n",
    "            X_data.append(' '.join(end_d))\n",
    "            \n",
    "        if n == 1:\n",
    "            Y = np.array(self.data['encoder_y'])\n",
    "        else:\n",
    "            Y = to_categorical(self.data['encoder_y'])\n",
    "            \n",
    "        X = np.array(X_data)\n",
    "        x_data, test_x, y_data, test_y = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "        train_x, val_x, train_y, val_y = train_test_split(x_data, y_data, test_size=0.2, random_state=0)\n",
    "        tk = Tokenizer()\n",
    "        tk.fit_on_texts(train_x)\n",
    "        n = len([d for d in sorted(list(tk.word_counts.items()), key=lambda x: x[1]) if d[1] > 4]) + 1\n",
    "        token = Tokenizer(n)\n",
    "        token.fit_on_texts(train_x)\n",
    "        token_train_x = token.texts_to_sequences(train_x)\n",
    "        token_test_x = token.texts_to_sequences(test_x)\n",
    "        token_val_x = token.texts_to_sequences(val_x)\n",
    "        drop_train = [index for index, sentence in enumerate(token_train_x) if len(sentence) < 1]\n",
    "        drop_test = [index for index, sentence in enumerate(token_test_x) if len(sentence) < 1]\n",
    "        drop_val = [index for index, sentence in enumerate(token_val_x) if len(sentence) < 1]\n",
    "        token_train_x = np.delete(token_train_x, drop_train, axis=0)\n",
    "        train_y = np.delete(train_y, drop_train, axis=0)\n",
    "        token_test_x = np.delete(token_test_x, drop_test, axis=0)\n",
    "        test_y = np.delete(test_y, drop_test, axis=0)\n",
    "        token_val_x = np.delete(token_val_x, drop_val, axis=0)\n",
    "        val_y = np.delete(val_y, drop_val, axis=0)\n",
    "        w_l = len(pad_sequences(token_train_x)[0])\n",
    "        train_inputs = pad_sequences(token_train_x, maxlen=w_l)\n",
    "        test_inputs = pad_sequences(token_test_x, maxlen=w_l)\n",
    "        val_inputs = pad_sequences(token_val_x, maxlen=w_l)\n",
    "        train_outputs = train_y\n",
    "        test_outputs = test_y\n",
    "        val_outputs = val_y\n",
    "        return train_inputs, train_outputs, test_inputs, test_outputs, val_inputs, val_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f652bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 확인:True\n",
      "X 중복 확인:(194543, 200000)\n",
      "y 중복 확인:(2, 200000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 199992/199992 [19:13<00:00, 173.35it/s]\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111226, 70) (111226,) (59568, 70) (59568,) (27803, 70) (27803,)\n"
     ]
    }
   ],
   "source": [
    "pr_mc=한글_전처리기(data)\n",
    "pr_mc.ck_m()\n",
    "t_x,t_y,tt_x,tt_y,v_x,v_y=pr_mc.전처리_결과_출력()\n",
    "print(t_x.shape,t_y.shape,tt_x.shape,tt_y.shape,v_x.shape,v_y.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
