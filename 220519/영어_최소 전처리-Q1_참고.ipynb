{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064e6bac",
   "metadata": {},
   "source": [
    "## 자연어 전처리-영어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4399f647",
   "metadata": {},
   "source": [
    "관련 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1244f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer#토큰화\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences#패딩\n",
    "from sklearn.preprocessing import LabelEncoder#정답 숫자화\n",
    "from sklearn.model_selection import train_test_split#데이더 분할\n",
    "from tensorflow.keras.utils import to_categorical#정답을 원_핫 인코딩화\n",
    "import numpy as np#넘파이 \n",
    "from nltk.corpus import stopwords#불용어 메소드\n",
    "from bs4 import BeautifulSoup#마크업 단어를 정리하기 위한 목적\n",
    "import re#문자 정규표준"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81af619",
   "metadata": {},
   "source": [
    "전처리 메소드 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada8c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X_text, remove_stopwords=False):\n",
    "    X_text = BeautifulSoup(X_text, 'lxml').get_text()#마크업언더 정리\n",
    "    X_text = re.sub(\"[^a-zA-Z]\", \" \", X_text)#영어 숫자 말고 제거\n",
    "    words = X_text.lower().split()#소문자화\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words('english'))#불용어 로드\n",
    "        #stops.add(불용어 문자열)#추가 불용어가 필요할 기록<문자열1개>\n",
    "        words = [w for w in words if not w in stops]\n",
    "        clean_text = ' '.join(words)\n",
    "    else:\n",
    "        clean_text = ' '.join(words)\n",
    "        \n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fc68c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('spam.csv',encoding='latin1')[['v1','v2']]\n",
    "data=data.rename(columns = {'v1':'y', 'v2' : 'X'})#데이터 프레임 열이름 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52695bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_X']=data['X'].apply(lambda x : preprocessing(X_text=x, remove_stopwords=True))#만들어진 함수이용 data 1차 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5993d6fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data['y_name']=data['y']#정답 이름 기록\n",
    "data['encoder_y']=LabelEncoder().fit_transform(data['y'])#정답 숫자화\n",
    "data['categorical_y']=list(to_categorical(data['encoder_y']))#정답 다중값 희소행렬정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a9de05a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()#결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d196d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5055, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean_X'].nunique(), data['y'].nunique()#중복 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "610dda41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_7268/835016061.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X'] = data['clean_X'].str.replace(\"[^a-zA-Z0-9 ]\",\"\")\n",
      "C:\\Users\\student\\AppData\\Local\\Temp/ipykernel_7268/835016061.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  data['clean_X'] = data['clean_X'].str.replace('^ +', \"\")\n"
     ]
    }
   ],
   "source": [
    "data=data.drop_duplicates(subset=['X'])#중복 제거\n",
    "data['clean_X'] = data['clean_X'].str.replace(\"[^a-zA-Z0-9 ]\",\"\")#영어 숫자 말고 제거\n",
    "data['clean_X'] = data['clean_X'].str.replace('^ +', \"\")#문장 앞의 공백 제거\n",
    "data['clean_X'].replace('', np.nan, inplace=True)#비어있는 문자열 NaN화\n",
    "data = data.dropna(how = 'any')#NaN_ data 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2360bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.array(data['encoder_y'])#이진 분류\n",
    "#Y=to_categorical(data['encoder_y'])#다중 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9da06721",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data['clean_X'])#입력 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3413d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data,test_x,y_data,test_y = train_test_split(X,Y,test_size=0.3,random_state=0)#태스트 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aca3154",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,val_x,train_y,val_y = train_test_split(x_data,y_data,test_size=0.2,random_state=0)#학습데이터,검증데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52c066f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(train_x)#입력된 데이터 내의 단어모음집 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1314b410",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=len([d for d in sorted(list(tk.word_counts.items()),key=lambda x:x[1]) if d[1]>4])+1#단어모음집중 4번이하 제거 단어갯수기록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c19ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token=Tokenizer(n)#정의한 단어의 수를 기반으로 문서 정리\n",
    "token.fit_on_texts(train_x)#학습 데이터를 이용하여 단어모음집을 가진 장치 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb5f53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_train_x=token.texts_to_sequences(train_x)#같은 사전을 이용하여 같은 범주의 단어들을 가지고있는 단어 표현\n",
    "token_test_x=token.texts_to_sequences(test_x)#같은 사전을 이용하여 같은 범주의 단어들을 가지고있는 단어 표현\n",
    "token_val_x=token.texts_to_sequences(val_x)#같은 사전을 이용하여 같은 범주의 단어들을 가지고있는 단어 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da8db1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_train = [index for index, sentence in enumerate(token_train_x) if len(sentence) < 1]#빈문자열 위치 확인\n",
    "drop_test = [index for index, sentence in enumerate(token_test_x) if len(sentence) < 1]#빈문자열 위치 확인\n",
    "drop_val = [index for index, sentence in enumerate(token_val_x) if len(sentence) < 1]#빈문자열 위치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd34781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "token_train_x = np.delete(token_train_x, drop_train, axis=0)#빈문자열 제거\n",
    "train_y = np.delete(train_y, drop_train, axis=0)#빈문자열 제거\n",
    "token_test_x = np.delete(token_test_x, drop_test, axis=0)#빈문자열 제거\n",
    "test_y = np.delete(test_y, drop_test, axis=0)#빈문자열 제거\n",
    "token_val_x = np.delete(token_val_x, drop_val, axis=0)#빈문자열 제거\n",
    "val_y = np.delete(val_y, drop_val, axis=0)#빈문자열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6e4667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_l=len(pad_sequences(token_train_x)[0])#학습 데이터중 가장 긴 문장 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38631b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = pad_sequences(token_train_x,maxlen=w_l)#모든 문장의 길이가 똑같게 만든다\n",
    "test_inputs = pad_sequences(token_test_x,maxlen=w_l)#모든 문장의 길이가 똑같게 만든다\n",
    "val_inputs = pad_sequences(token_val_x,maxlen=w_l)#모든 문장의 길이가 똑같게 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf1ee0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs=train_y#용어 정리\n",
    "test_outputs=test_y#용어 정리\n",
    "val_outputs=val_y#용어 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "954182e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((3071, 50), (3071,)), ((1640, 50), (1640,)), ((756, 50), (756,)))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_inputs.shape,train_outputs.shape),(test_inputs.shape,test_outputs.shape),(val_inputs.shape,val_outputs.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
