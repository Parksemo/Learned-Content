{
 "cells": [
  {
   "cell_type": "raw",
   "id": "3e28a508",
   "metadata": {},
   "source": [
    "단뱡항 LSTM으로 텍스트 분류를 수행할 수도 있지만 때로는 양방향 LSTM을 사용하는 것이 더 강력합니다. \n",
    "여기에 추가적으로 어텐션 메커니즘을 사용할 수도 있습니다.\n",
    "양방향 LSTM과 어텐션 메커니즘으로 IMDB 리뷰 감성 분류하기를 수행해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e62deb",
   "metadata": {},
   "source": [
    "# 1. IMDB 리뷰 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d606b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f567a999",
   "metadata": {},
   "source": [
    "IMDB 리뷰 데이터는 앞서 텍스트 분류하기 챕터에서 다룬 바 있으므로 데이터에 대한 상세 설명은 생략합니다. \n",
    "최대 단어 개수를 10,000으로 제한하고 훈련 데이터와 테스트 데이터를 받아옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb0ac8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84d22eaa",
   "metadata": {},
   "source": [
    "훈련 데이터와 이에 대한 레이블이 각각 X_train, y_train에 테스트 데이터와 이에 대한 레이블이 각각 X_test, y_test에 저장되었습니다. \n",
    "IMDB 리뷰 데이터는 이미 정수 인코딩이 된 상태므로 남은 전처리는 패딩뿐입니다. \n",
    "\n",
    "리뷰의 최대 길이와 평균 길이를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7328259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 2494\n",
      "리뷰의 평균 길이 : 238.71364\n"
     ]
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
    "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1984210d",
   "metadata": {},
   "source": [
    "리뷰의 최대 길이는 2,494이며 리뷰의 평균 길이는 약 238로 확인됩니다. \n",
    "평균 길이보다는 조금 크게 데이터를 패딩하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11bfdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 500\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6dc72e54",
   "metadata": {},
   "source": [
    "훈련용 리뷰와 테스트용 리뷰의 길이가 둘 다 500이 되었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123bfec",
   "metadata": {},
   "source": [
    "# 2. 바다나우 어텐션(Bahdanau Attention)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2d3aa03",
   "metadata": {},
   "source": [
    "여기서 사용할 어텐션은 바다나우 어텐션(Bahdanau attention)입니다. \n",
    "이를 이해하기 위해 앞서 배운 가장 쉬운 어텐션이었던 닷 프로덕트 어텐션과 어텐션 스코어 함수의 정의를 상기해봅시다.\n",
    "어텐션 스코어 함수란 주어진 query와 모든 key에 대해서 유사도를 측정하는 함수를 말합니다. 그리고 닷 프로덕트 어텐션에서는 query와 key의 유사도를 구하는 방법이 내적(dot product)이었습니다. 다음은 닷 프로덕트 어텐션의 어텐션 스코어 함수를 보여줍니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bb76297",
   "metadata": {},
   "source": [
    "바다나우 어텐션은 아래와 같은 어텐션 스코어 함수를 사용합니다.\n",
    "\n",
    "이 어텐션 스코어 함수를 사용하여 어텐션 메커니즘을 구현하면 됩니다. 그런데 텍스트 분류에서 어텐션 메커니즘을 사용하는 이유는 무엇일까요? RNN의 마지막 은닉 상태는 예측을 위해 사용됩니다. 그런데 이 RNN의 마지막 은닉 상태는 몇 가지 유용한 정보들을 손실한 상태입니다. 그래서 RNN이 time step을 지나며 손실했던 정보들을 다시 참고하고자 합니다.\n",
    "이는 다시 말해 RNN의 모든 은닉 상태들을 다시 한 번 참고하겠다는 것입니다. 그리고 이를 위해서 어텐션 메커니즘을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f7387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ecea095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = Dense(units)\n",
    "        self.W2 = Dense(units)\n",
    "        self.V = Dense(1)\n",
    "\n",
    "    def call(self, values, query): # 단, key와 value는 같음\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # score 계산을 위해 뒤에서 할 덧셈을 위해서 차원을 변경해줍니다.\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f7da53",
   "metadata": {},
   "source": [
    "# 3. 양방향 LSTM + 어텐션 메커니즘(BiLSTM with Attention Mechanism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473ac0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, Dropout\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import optimizers\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57743595",
   "metadata": {},
   "source": [
    "이제 모델을 설계해보겠습니다. 여기서는 케라스의 함수형 API를 사용합니다. 우선 입력층과 임베딩층을 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f959aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
    "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len, mask_zero = True)(sequence_input)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ab56e1c",
   "metadata": {},
   "source": [
    "10,000개의 단어들을 128차원의 벡터로 임베딩하도록 설계하였습니다. \n",
    "이제 양방향 LSTM을 설계합니다. 단, 여기서는 양방향 LSTM을 두 층을 사용하겠습니다. \n",
    "우선, 첫번째 층입니다. 두번째 층을 위에 쌓을 예정이므로 return_sequences를 True로 해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b3d93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = Bidirectional(LSTM(64, dropout=0.5, return_sequences = True))(embedded_sequences)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b3540c6",
   "metadata": {},
   "source": [
    "두번째 층을 설계합니다. 상태를 리턴받아야 하므로 return_state를 True로 해주어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a3951bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional \\\n",
    "  (LSTM(64, dropout=0.5, return_sequences=True, return_state=True))(lstm)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "952bca6b",
   "metadata": {},
   "source": [
    "각 상태의 크기(shape)를 출력해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d34234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 500, 128) (None, 64) (None, 64) (None, 64) (None, 64)\n"
     ]
    }
   ],
   "source": [
    "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834bea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
    "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a6873f69",
   "metadata": {},
   "source": [
    "어텐션 메커니즘에서는 은닉 상태를 사용합니다. \n",
    "이를 입력으로 컨텍스트 벡터(context vector)를 얻습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d33f521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = BahdanauAttention(64) # 가중치 크기 정의\n",
    "context_vector, attention_weights = attention(lstm, state_h)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05812967",
   "metadata": {},
   "source": [
    "컨텍스트 벡터를 밀집층(dense layer)에 통과시키고, 이진 분류이므로 최종 출력층에 1개의 뉴런을 배치하고, 활성화 함수로 시그모이드 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ed4be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense1 = Dense(20, activation=\"relu\")(context_vector)\n",
    "dropout = Dropout(0.5)(dense1)\n",
    "output = Dense(1, activation=\"sigmoid\")(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c72dccb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d639f2",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9975578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 3875s 40s/step - loss: 0.4706 - accuracy: 0.7731 - val_loss: 0.2917 - val_accuracy: 0.8791\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 6795s 70s/step - loss: 0.2427 - accuracy: 0.9157 - val_loss: 0.2793 - val_accuracy: 0.8826\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 5292s 54s/step - loss: 0.1926 - accuracy: 0.9362 - val_loss: 0.3264 - val_accuracy: 0.8735\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터로 테스트 데이터를 사용하여 에포크가 끝날 때마다 테스트 데이터에 대한 정확도를 출력하도록 하였습니다.\n",
    "history = model.fit(X_train, y_train, epochs = 3, batch_size = 256, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a7bb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 276s 353ms/step - loss: 0.3264 - accuracy: 0.8735\n",
      "\n",
      " 테스트 정확도: 0.8735\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a16bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c00d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
